<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>R Syntax | PSQF 6250</title>
    <link>https://psqf6250.brandonlebeau.org/rcode/</link>
      <atom:link href="https://psqf6250.brandonlebeau.org/rcode/index.xml" rel="self" type="application/rss+xml" />
    <description>R Syntax</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><lastBuildDate>Thu, 13 Jan 2022 00:00:00 +0000</lastBuildDate>
    <image>
      <url>https://psqf6250.brandonlebeau.org/media/blue-balloon.jpg</url>
      <title>R Syntax</title>
      <link>https://psqf6250.brandonlebeau.org/rcode/</link>
    </image>
    
    <item>
      <title>Graphics</title>
      <link>https://psqf6250.brandonlebeau.org/rcode/graphics/</link>
      <pubDate>Mon, 01 Feb 2021 00:00:00 +0000</pubDate>
      <guid>https://psqf6250.brandonlebeau.org/rcode/graphics/</guid>
      <description>
&lt;script src=&#34;https://psqf6250.brandonlebeau.org/rmarkdown-libs/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;

&lt;div id=&#34;TOC&#34;&gt;

&lt;/div&gt;

&lt;p&gt;We are going to start by exploring graphics with R using the &lt;code&gt;midwest&lt;/code&gt; data. To access this data, run the following commands:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;install.packages(&amp;quot;tidyverse&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(tidyverse)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Suppose we were interested in exploring the question: How does population density influence the percentage of the population with at least a college degree? Let’s explore these data closer.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;midwest&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 437 × 28
##      PID county  state  area poptotal popdensity popwhite popblack popamerindian
##    &amp;lt;int&amp;gt; &amp;lt;chr&amp;gt;   &amp;lt;chr&amp;gt; &amp;lt;dbl&amp;gt;    &amp;lt;int&amp;gt;      &amp;lt;dbl&amp;gt;    &amp;lt;int&amp;gt;    &amp;lt;int&amp;gt;         &amp;lt;int&amp;gt;
##  1   561 ADAMS   IL    0.052    66090      1271.    63917     1702            98
##  2   562 ALEXAN… IL    0.014    10626       759      7054     3496            19
##  3   563 BOND    IL    0.022    14991       681.    14477      429            35
##  4   564 BOONE   IL    0.017    30806      1812.    29344      127            46
##  5   565 BROWN   IL    0.018     5836       324.     5264      547            14
##  6   566 BUREAU  IL    0.05     35688       714.    35157       50            65
##  7   567 CALHOUN IL    0.017     5322       313.     5298        1             8
##  8   568 CARROLL IL    0.027    16805       622.    16519      111            30
##  9   569 CASS    IL    0.024    13437       560.    13384       16             8
## 10   570 CHAMPA… IL    0.058   173025      2983.   146506    16559           331
## # … with 427 more rows, and 19 more variables: popasian &amp;lt;int&amp;gt;, popother &amp;lt;int&amp;gt;,
## #   percwhite &amp;lt;dbl&amp;gt;, percblack &amp;lt;dbl&amp;gt;, percamerindan &amp;lt;dbl&amp;gt;, percasian &amp;lt;dbl&amp;gt;,
## #   percother &amp;lt;dbl&amp;gt;, popadults &amp;lt;int&amp;gt;, perchsd &amp;lt;dbl&amp;gt;, percollege &amp;lt;dbl&amp;gt;,
## #   percprof &amp;lt;dbl&amp;gt;, poppovertyknown &amp;lt;int&amp;gt;, percpovertyknown &amp;lt;dbl&amp;gt;,
## #   percbelowpoverty &amp;lt;dbl&amp;gt;, percchildbelowpovert &amp;lt;dbl&amp;gt;, percadultpoverty &amp;lt;dbl&amp;gt;,
## #   percelderlypoverty &amp;lt;dbl&amp;gt;, inmetro &amp;lt;int&amp;gt;, category &amp;lt;chr&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This will bring up the first 10 rows of the data (hiding the additional 8,592) rows. A first common step to explore our research question is to plot the data. To do this we are going to use the R package, &lt;code&gt;ggplot2&lt;/code&gt;, which was installed when running the &lt;code&gt;install.packages&lt;/code&gt; command above. You can explore the &lt;code&gt;midwest&lt;/code&gt; data by calling up the help file as well with &lt;code&gt;?midwest&lt;/code&gt;.&lt;/p&gt;
&lt;div id=&#34;create-a-ggplot&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Create a ggplot&lt;/h2&gt;
&lt;p&gt;To plot these two variables from the &lt;code&gt;midwest&lt;/code&gt; data, we will use the function &lt;code&gt;ggplot&lt;/code&gt; and &lt;code&gt;geom_point&lt;/code&gt; to add a layer of points. We will treat &lt;code&gt;popdensity&lt;/code&gt; as the x variable and &lt;code&gt;percollege&lt;/code&gt; as the y variable.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(data = midwest) +
  geom_point(mapping = aes(x = popdensity, y = percollege))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://psqf6250.brandonlebeau.org/rcode/graphics_files/figure-html/plot1-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;div id=&#34;examples&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Examples&lt;/h3&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;Try plotting &lt;code&gt;popdensity&lt;/code&gt; by &lt;code&gt;state&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;Try plotting &lt;code&gt;county&lt;/code&gt; by &lt;code&gt;state&lt;/code&gt;. Does this plot work?&lt;/li&gt;
&lt;li&gt;Bonus: Try just using the &lt;code&gt;ggplot(data = midwest)&lt;/code&gt; from above. What do you get? Does this make sense?&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Note: You should be able to modify the structure of the code above to do this.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;add-aesthetics&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Add Aesthetics&lt;/h2&gt;
&lt;p&gt;Aesthetics are a way to explore more complex interactions within the data. Particularly, from the above example, lets add in the state variable to the plot via an aesthetic.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(data = midwest) +
  geom_point(mapping = aes(x = popdensity, y = percollege, color = state))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://psqf6250.brandonlebeau.org/rcode/graphics_files/figure-html/aesthetic-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;As you can see, we simply colored the points by the state they belong in. Does there appear to be a trend?&lt;/p&gt;
&lt;div id=&#34;examples-1&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Examples&lt;/h3&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;Using the same aesthetic structure as above, instead of using colors, make the shape of the points different for each state.&lt;/li&gt;
&lt;li&gt;Instead of color, use &lt;code&gt;alpha&lt;/code&gt; instead. What does this do to the plot?&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;global-aesthetics&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Global Aesthetics&lt;/h2&gt;
&lt;p&gt;Above, we specified a variable to an aesthetic, which is a common use of aesthetics. However, the aesthetics can also be assigned globally. Here are two examples using the first scatterplot created.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(data = midwest) +
  geom_point(mapping = aes(x = popdensity, y = percollege), color = &amp;#39;pink&amp;#39;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://psqf6250.brandonlebeau.org/rcode/graphics_files/figure-html/global_aes-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(data = midwest) +
  geom_point(mapping = aes(x = popdensity, y = percollege), shape = 15)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://psqf6250.brandonlebeau.org/rcode/graphics_files/figure-html/global_aes2-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;These two plots changed the aesthetics for all of the points. Notice, the suttle difference between the code for these plots and that for the plot above. The placement of the aesthetic is crucial, if it is within the parentheses for &lt;code&gt;aes()&lt;/code&gt; then it should be assigned a variable. If it is outside, as in the last two examples, it will define the aesthetic for all the data.&lt;/p&gt;
&lt;div id=&#34;examples-2&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Examples&lt;/h3&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;Try the following command: &lt;code&gt;colors()&lt;/code&gt;. This will print a vector of all the color names within R, try a few to find your favorites.&lt;/li&gt;
&lt;li&gt;What happens if you use the following code:&lt;/li&gt;
&lt;/ol&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(data = midwest) + 
  geom_point(mapping = aes(x = popdensity, y = percollege, color = &amp;#39;green&amp;#39;))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;What is the problem?&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;facets&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Facets&lt;/h2&gt;
&lt;p&gt;Instead of defining an aesthetic to change the color or shape of points by a third variable, we can also plot each groups data in a single plot and combine them. The process is easy with &lt;code&gt;ggplot2&lt;/code&gt; by using facets.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(data = midwest) +
  geom_point(mapping = aes(x = popdensity, y = percollege)) + 
  facet_grid(. ~ state)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://psqf6250.brandonlebeau.org/rcode/graphics_files/figure-html/facets-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;You can also use &lt;code&gt;facet_wrap&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(data = midwest) +
  geom_point(mapping = aes(x = popdensity, y = percollege)) + 
  facet_wrap(~ state)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://psqf6250.brandonlebeau.org/rcode/graphics_files/figure-html/facet_wrap-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;div id=&#34;examples-3&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Examples&lt;/h3&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;Can you facet with a continuous variable? Try it!&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;geoms&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Geoms&lt;/h2&gt;
&lt;p&gt;&lt;code&gt;ggplot2&lt;/code&gt; uses a grammar of graphics which makes it easy to switch different plot types (called geoms) once you are comfortable with the basic syntax. For example, how does the following plot differ from the scatterplot first generated above? What is similar?&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(data = midwest) +
  geom_smooth(mapping = aes(x = popdensity, y = percollege))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://psqf6250.brandonlebeau.org/rcode/graphics_files/figure-html/smooth-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;We can also do this plot by states&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(data = midwest) +
  geom_smooth(mapping = aes(x = popdensity, y = percollege, linetype = state), 
              se = FALSE)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://psqf6250.brandonlebeau.org/rcode/graphics_files/figure-html/smooth_states-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;What about the code above gave me the different lines for each state? Note, I also removed the standard error shading from the plot as well.&lt;/p&gt;
&lt;div id=&#34;examples-4&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Examples&lt;/h3&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;It is possible to combine geoms, which we will do next, but try it first. Try to recreate this plot.
&lt;img src=&#34;https://psqf6250.brandonlebeau.org/rcode/graphics_files/figure-html/combine-1.png&#34; width=&#34;672&#34; /&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;combining-multiple-geoms&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Combining multiple geoms&lt;/h2&gt;
&lt;p&gt;Combining more than one geom into a single plot is relatively straightforward, but a few considerations are important. Essentially to do the task, we just simply need to combine the two geoms we have used:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(data = midwest) +
  geom_point(aes(x = popdensity, y = percollege, color = state)) +
  geom_smooth(mapping = aes(x = popdensity, y = percollege, color = state), 
              se = FALSE)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://psqf6250.brandonlebeau.org/rcode/graphics_files/figure-html/combine_geoms-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;A couple points about combining geoms, first, the order matters. In the above example, we called &lt;code&gt;geom_point&lt;/code&gt; first, then &lt;code&gt;geom_smooth&lt;/code&gt;. When plotting these data, the points will then be plotted first followed by the lines. Try flipping the order of the two geoms to see how the plot differs.&lt;/p&gt;
&lt;p&gt;We can also simplify this code to not duplicate typing:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(data = midwest, mapping = aes(x = popdensity, y = percollege, color = state)) +
  geom_point() +
  geom_smooth(se = FALSE)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://psqf6250.brandonlebeau.org/rcode/graphics_files/figure-html/two_geoms-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;div id=&#34;examples-5&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Examples&lt;/h3&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;Can you recreate the following figure?
&lt;img src=&#34;https://psqf6250.brandonlebeau.org/rcode/graphics_files/figure-html/differ_aes-1.png&#34; width=&#34;672&#34; /&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;other-geom-examples&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Other geom examples&lt;/h2&gt;
&lt;p&gt;There are many other geoms available to use. To see them all, visit &lt;a href=&#34;https://ggplot2.tidyverse.org/reference/index.html&#34; class=&#34;uri&#34;&gt;https://ggplot2.tidyverse.org/reference/index.html&lt;/a&gt; which gives examples of all the possibilities. This is a handy resource that I keep going back to.&lt;/p&gt;
&lt;div id=&#34;geoms-for-single-variables&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Geoms for single variables&lt;/h3&gt;
&lt;p&gt;The introduction to plotting has been with two variables, but lets take a step back and focus on one variable with a bar chart.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(data = midwest, mapping = aes(x = state)) + 
  geom_bar()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://psqf6250.brandonlebeau.org/rcode/graphics_files/figure-html/bar-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;You can also easily add aesthetics this base plot as shown before.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(data = midwest, mapping = aes(x = state)) + 
  geom_bar(aes(fill = factor(inmetro)))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://psqf6250.brandonlebeau.org/rcode/graphics_files/figure-html/bar_fill-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;A few additions can help interpretation of this plot:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(data = midwest, mapping = aes(x = state)) + 
  geom_bar(aes(fill = factor(inmetro)), position = &amp;#39;fill&amp;#39;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://psqf6250.brandonlebeau.org/rcode/graphics_files/figure-html/bar_fill2-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(data = midwest, mapping = aes(x = state)) + 
  geom_bar(aes(fill = factor(inmetro)), position = &amp;#39;dodge&amp;#39;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://psqf6250.brandonlebeau.org/rcode/graphics_files/figure-html/unnamed-chunk-1-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;It is also possible to do a histrogram of a quantitative variable:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(data = midwest, mapping = aes(x = popdensity)) + 
  geom_histogram()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://psqf6250.brandonlebeau.org/rcode/graphics_files/figure-html/histogram-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;You can adjust the binwidth directly:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(data = midwest, mapping = aes(x = popdensity)) + 
  geom_histogram(binwidth = 1000)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://psqf6250.brandonlebeau.org/rcode/graphics_files/figure-html/binwidth-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;examples-6&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Examples&lt;/h3&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;p&gt;With more than two groups, histograms are difficult to interpret due to overlap. Instead, use the &lt;code&gt;geom_density&lt;/code&gt; to create a density plot for &lt;code&gt;popdensity&lt;/code&gt; for each state. The final plot should look similar to this:
&lt;img src=&#34;https://psqf6250.brandonlebeau.org/rcode/graphics_files/figure-html/density-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Using &lt;code&gt;geom_boxplot&lt;/code&gt;, create boxplots with &lt;code&gt;popdensity&lt;/code&gt; as the y variable and &lt;code&gt;state&lt;/code&gt; as the x variable. Bonus: facet this plot by the variable &lt;code&gt;inmetro&lt;/code&gt;.
&lt;img src=&#34;https://psqf6250.brandonlebeau.org/rcode/graphics_files/figure-html/boxplot-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;plot-customization&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Plot Customization&lt;/h2&gt;
&lt;p&gt;There are many many ways to adjust the look of the plot, I will discuss a few that are common.&lt;/p&gt;
&lt;div id=&#34;change-axes&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Change axes&lt;/h3&gt;
&lt;p&gt;Axes are something that are commonly altered, particularly to give them a good name and also to alter the values shown on the axes. These are generally done with &lt;code&gt;scale_x_*&lt;/code&gt; and &lt;code&gt;scale_y_*&lt;/code&gt; where &lt;code&gt;*&lt;/code&gt; is a filler based on the type of variable on the axes.&lt;/p&gt;
&lt;p&gt;For example:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(data = midwest, mapping = aes(x = popdensity, y = percollege, color = state)) +
  geom_point() + 
  scale_x_continuous(&amp;quot;Population Density&amp;quot;) + 
  scale_y_continuous(&amp;quot;Percent College Graduates&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://psqf6250.brandonlebeau.org/rcode/graphics_files/figure-html/axes_labels-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;To change the legend title, the &lt;code&gt;scale_color_discrete&lt;/code&gt; command can be used to adjust the color aesthetic and the variable is discrete.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(data = midwest, mapping = aes(x = popdensity, y = percollege, color = state)) +
  geom_point() + 
  scale_x_continuous(&amp;quot;Population Density&amp;quot;) + 
  scale_y_continuous(&amp;quot;Percent College Graduates&amp;quot;) + 
  scale_color_discrete(&amp;quot;State&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://psqf6250.brandonlebeau.org/rcode/graphics_files/figure-html/aes_labels-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;we can also alter the breaks showing on the x-axis.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(data = midwest, mapping = aes(x = popdensity, y = percollege, color = state)) +
  geom_point() + 
  scale_x_continuous(&amp;quot;Population Density&amp;quot;, breaks = seq(0, 80000, 20000)) + 
  scale_y_continuous(&amp;quot;Percent College Graduates&amp;quot;) + 
  scale_color_discrete(&amp;quot;State&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://psqf6250.brandonlebeau.org/rcode/graphics_files/figure-html/breaks_x-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;zoom-in-on-plot&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Zoom in on plot&lt;/h2&gt;
&lt;p&gt;You’ll notice that there are outliers in this scatterplot due to larger population density values for some counties. It may be of interest to zoom in on the plot. The plot can be zoomed in by using the &lt;code&gt;coord_cartesian&lt;/code&gt; command as follows.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(data = midwest, mapping = aes(x = popdensity, y = percollege, color = state)) +
  geom_point() + 
  scale_x_continuous(&amp;quot;Population Density&amp;quot;) + 
  scale_y_continuous(&amp;quot;Percent College Graduates&amp;quot;) + 
  scale_color_discrete(&amp;quot;State&amp;quot;) + 
  coord_cartesian(xlim = c(0, 15000))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://psqf6250.brandonlebeau.org/rcode/graphics_files/figure-html/zoom-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Note: This can also be achieved using the &lt;code&gt;xlim&lt;/code&gt; argument to &lt;code&gt;scale_x_continuous&lt;/code&gt; above, however this will cause some points to not be plotted. In this case it would not be a huge deal, however, if we plotted the smooth lines from before you can see the difference.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(data = midwest, mapping = aes(x = popdensity, y = percollege, color = state)) +
  geom_point() + 
  geom_smooth(se = FALSE) +
  scale_x_continuous(&amp;quot;Population Density&amp;quot;) + 
  scale_y_continuous(&amp;quot;Percent College Graduates&amp;quot;) + 
  scale_color_discrete(&amp;quot;State&amp;quot;) + 
  coord_cartesian(xlim = c(0, 15000))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://psqf6250.brandonlebeau.org/rcode/graphics_files/figure-html/zoom2-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(data = midwest, mapping = aes(x = popdensity, y = percollege, color = state)) +
  geom_point() + 
  geom_smooth(se = FALSE) +
  scale_x_continuous(&amp;quot;Population Density&amp;quot;, limits = c(0, 15000)) + 
  scale_y_continuous(&amp;quot;Percent College Graduates&amp;quot;) + 
  scale_color_discrete(&amp;quot;State&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning: Removed 16 rows containing non-finite values (stat_smooth).&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning: Removed 16 rows containing missing values (geom_point).&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://psqf6250.brandonlebeau.org/rcode/graphics_files/figure-html/zoom3-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>R Basics</title>
      <link>https://psqf6250.brandonlebeau.org/rcode/r-basics/</link>
      <pubDate>Mon, 01 Feb 2021 00:00:00 +0000</pubDate>
      <guid>https://psqf6250.brandonlebeau.org/rcode/r-basics/</guid>
      <description>
&lt;script src=&#34;https://psqf6250.brandonlebeau.org/rmarkdown-libs/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;

&lt;div id=&#34;TOC&#34;&gt;

&lt;/div&gt;

&lt;p&gt;In an attempt to get you “doing things” in R quickly, I’ve omitted a lot of discussion surrounding internal R workings. R is an object oriented language, this is much different than many other software languages.&lt;/p&gt;
&lt;div id=&#34;r-works-as-a-calculator&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;R works as a calculator&lt;/h2&gt;
&lt;p&gt;R can be used as a calculator to do any type of addition, subtraction, multiplication, or division (among other things).&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;1 + 2 - 3&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;5 * 7&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 35&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;2/1&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 2&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sqrt(4)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 2&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;2^2&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 4&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Being an object oriented system, values can directly saved within an object to be used later. As an example:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;x &amp;lt;- 1 + 3
x&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 4&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This can then be used later in other calculations:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;x * 3&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 12&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This simplistic example is a bit too simple to show all the benefits of this approach, but will become more apparent when we start reading in data and doing more complicated data munging type tasks.&lt;/p&gt;
&lt;div id=&#34;naming-conventions&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Naming conventions&lt;/h3&gt;
&lt;p&gt;This is a topic in which you will not get a single answer, but rather a different answer for everyone you ask. I prefer something called &lt;strong&gt;snake_case&lt;/strong&gt; using underscores to separate words in an object. Others use &lt;strong&gt;titleCase&lt;/strong&gt; as a way to distinguish words others yet use &lt;strong&gt;period.to.separate&lt;/strong&gt; words in object names.&lt;/p&gt;
&lt;p&gt;The most important thing is to be consistent. Pick a convention that works for you and stick with it through out. Avoiding this &lt;strong&gt;Mixed.TypeOf_conventions&lt;/strong&gt; at all costs.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;r-is-case-sensitive&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;R is case sensitive&lt;/h2&gt;
&lt;p&gt;This can cause problems and make debugging a bit more difficult. Be careful with typos and with case. Here is an example:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;case_sensitive &amp;lt;- 10
Case_sensitive&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Error in eval(expr, envir, enclos) : object &amp;#39;Case_sensitive&amp;#39; not found&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;functions&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Functions&lt;/h2&gt;
&lt;p&gt;We have already been using functions when working through creating graphics with R. A function consists of at least two parts, the &lt;em&gt;function name&lt;/em&gt; and the &lt;em&gt;arguments&lt;/em&gt; as follows: &lt;code&gt;function_name(arg1 = num, arg2 = num)&lt;/code&gt;. The arguments are always inside of parentheses, take on some value, and are always named. To call a function, use the &lt;code&gt;function_name&lt;/code&gt; followed by parentheses with the arguments inside the parentheses. For example, using the &lt;code&gt;rnorm&lt;/code&gt; function to generate values from a random normal distribution:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;set.seed(1)
rnorm(n = 10, mean = 0, sd = 1)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  [1] -0.6264538  0.1836433 -0.8356286  1.5952808  0.3295078 -0.8204684
##  [7]  0.4874291  0.7383247  0.5757814 -0.3053884&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Notice I called the arguments by name directly, this is good practice, however, this code will generate the same values (the values are the same because I’m using &lt;code&gt;set.seed&lt;/code&gt; here):&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;set.seed(1)
rnorm(10, 0, 1)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  [1] -0.6264538  0.1836433 -0.8356286  1.5952808  0.3295078 -0.8204684
##  [7]  0.4874291  0.7383247  0.5757814 -0.3053884&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The key when arguments are not called via their names is the order of the arguments. Look at &lt;code&gt;?rnorm&lt;/code&gt; to see that the first three arguments are indeed &lt;code&gt;n&lt;/code&gt;, &lt;code&gt;mean&lt;/code&gt;, and &lt;code&gt;sd&lt;/code&gt;. When you name arguments, they can be specified in any order (generally bad practice).&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;set.seed(1)
rnorm(sd = 1, n = 10, mean = 0)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  [1] -0.6264538  0.1836433 -0.8356286  1.5952808  0.3295078 -0.8204684
##  [7]  0.4874291  0.7383247  0.5757814 -0.3053884&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;You can save this result to an object to be used later.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;set.seed(1)
norm_values &amp;lt;- rnorm(n = 10, mean = 0, sd = 1)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Notice the result is no longer printed to the screen, but rather is saved to the object &lt;code&gt;norm_values&lt;/code&gt;. To see the result, you could just type &lt;code&gt;norm_values&lt;/code&gt; in the console.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;errors&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Errors&lt;/h2&gt;
&lt;p&gt;Lastly, I want to discuss errors. Errors are going to happen. Even the best programmers encounter errors that they did not anticipate and debugging needs to happen. If you encounter an error I recommend doing the following few things first:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;p&gt;Use &lt;code&gt;?function_name&lt;/code&gt; to explore the details of the function. The examples at the bottom of every R help page can be especially helpful.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;If this does not help, copy and paste the error and search on the internet. Chances are someone else has had this error and has asked how to fix it. This is how I fix most errors I am unable to figure out with the R help.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;If these two steps still do not help, feel free to email me, but take the time to do steps 1 and 2. If you do email me, please include the following things:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The error message directly given from R&lt;/li&gt;
&lt;li&gt;A reproducible example of the code. The reproducible example is one in which I can run the code directly with no modifications. Without this, it is much more difficult if not impossible for me to help without asking for more information.&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>ggplot2 extensions</title>
      <link>https://psqf6250.brandonlebeau.org/rcode/ggplot2_extensions/</link>
      <pubDate>Wed, 03 Feb 2021 00:00:00 +0000</pubDate>
      <guid>https://psqf6250.brandonlebeau.org/rcode/ggplot2_extensions/</guid>
      <description>
&lt;script src=&#34;https://psqf6250.brandonlebeau.org/rmarkdown-libs/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;

&lt;div id=&#34;TOC&#34;&gt;

&lt;/div&gt;

&lt;p&gt;The &lt;em&gt;ggplot2&lt;/em&gt; package has a robust ecosystem of many other packages that extend the functionality of &lt;em&gt;ggplot2&lt;/em&gt;. This week, we are going to explore some of these packages in more detail, highlighting a few packages that give you additional ways to create stunning visualizations. You can see all of the extensions packages in the following &lt;a href=&#34;https://exts.ggplot2.tidyverse.org/gallery/&#34;&gt;&lt;em&gt;ggplot2&lt;/em&gt; extension website&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;We are going to spend some time with the following packages:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://ggrepel.slowkow.com/&#34;&gt;&lt;em&gt;ggrepel&lt;/em&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://ggforce.data-imaginist.com/&#34;&gt;&lt;em&gt;ggforce&lt;/em&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://patchwork.data-imaginist.com/&#34;&gt;&lt;em&gt;patchwork&lt;/em&gt;&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;I also plan to discuss, &lt;a href=&#34;https://gganimate.com/&#34;&gt;&lt;em&gt;gganimate&lt;/em&gt;&lt;/a&gt;, but we are going to come back to this later in the course when talking about interactive graphics.&lt;/p&gt;
&lt;p&gt;All of these packages are on CRAN and you can install with the following command:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;install.packages(c(&amp;quot;ggrepel&amp;quot;, &amp;quot;ggforce&amp;quot;, &amp;quot;patchwork&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;div id=&#34;ggrepel&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;&lt;em&gt;ggrepel&lt;/em&gt;&lt;/h1&gt;
&lt;p&gt;Let’s start by exploring the &lt;em&gt;ggrepel&lt;/em&gt; package. This package is particularly useful when working with text labels and provides some algorithms to help with text label placement automatically. One challenge when placing text labels in a figure is that they often overlap and they also often are placed on top of the data too. &lt;em&gt;ggrepel&lt;/em&gt; helps to solve this problem.&lt;/p&gt;
&lt;p&gt;To show a motivating example, we are going to use data in this section based on penguins. To do this, we first need to install this data package.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;install.packages(&amp;quot;palmerpenguins&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The data include three different species of penguins originally collected by Dr. Kristen Gorman at the Palmer Station in Antarctica. There are a total of 344 penguins collected from 3 islands in Antarctica and include information about the species, which island, penguin measurements, and the sex of the penguin. More information about the data including artwork about the species and penguin measurements are on this &lt;a href=&#34;https://github.com/allisonhorst/palmerpenguins&#34;&gt;page&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Here are the penguin &lt;a href=&#34;https://github.com/allisonhorst/palmerpenguins/blob/master/man/figures/lter_penguins.png&#34;&gt;species&lt;/a&gt; and what the &lt;a href=&#34;https://github.com/allisonhorst/palmerpenguins/blob/master/man/figures/culmen_depth.png&#34;&gt;measurements mean&lt;/a&gt;, “artwork by &lt;span class=&#34;citation&#34;&gt;@allison_horst&lt;/span&gt;”.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(palmerpenguins)
library(ggplot2)

penguins&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 344 × 8
##    species island    bill_length_mm bill_depth_mm flipper_length_mm body_mass_g
##    &amp;lt;fct&amp;gt;   &amp;lt;fct&amp;gt;              &amp;lt;dbl&amp;gt;         &amp;lt;dbl&amp;gt;             &amp;lt;int&amp;gt;       &amp;lt;int&amp;gt;
##  1 Adelie  Torgersen           39.1          18.7               181        3750
##  2 Adelie  Torgersen           39.5          17.4               186        3800
##  3 Adelie  Torgersen           40.3          18                 195        3250
##  4 Adelie  Torgersen           NA            NA                  NA          NA
##  5 Adelie  Torgersen           36.7          19.3               193        3450
##  6 Adelie  Torgersen           39.3          20.6               190        3650
##  7 Adelie  Torgersen           38.9          17.8               181        3625
##  8 Adelie  Torgersen           39.2          19.6               195        4675
##  9 Adelie  Torgersen           34.1          18.1               193        3475
## 10 Adelie  Torgersen           42            20.2               190        4250
## # … with 334 more rows, and 2 more variables: sex &amp;lt;fct&amp;gt;, year &amp;lt;int&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Suppose we wanted to explore the bill length and flipper length with a scatter plot. We can do that with &lt;em&gt;ggplot2&lt;/em&gt; using the &lt;code&gt;geom_point()&lt;/code&gt; function. I’m also using the &lt;code&gt;theme_set()&lt;/code&gt; function to set the theme to be &lt;code&gt;theme_bw()&lt;/code&gt; for the remainder of the notebook. I’ve also altered the theme settings by increasing the base font size from 12 to 16 so hopefully it is a bit easier to read the figure.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;theme_set(theme_bw(base_size = 16))

ggplot(penguins, aes(x = flipper_length_mm, y = bill_length_mm)) + 
  geom_point(size = 4) + 
  xlab(&amp;quot;Penguin Flipper Length (in mm)&amp;quot;) +
  ylab(&amp;quot;Penguin Bill Length (in mm)&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://psqf6250.brandonlebeau.org/rcode/ggplot2_extensions_files/figure-html/length-depth-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Suppose we wished to add the species to this figure. More specifically, we want to add the species information to the points in the figure to label which points below to each penguin species. There are a few ways we could do this, we could do this by color, shape, or both.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(penguins, aes(x = flipper_length_mm, y = bill_length_mm)) + 
  geom_point(size = 4, aes(color = species, shape = species)) + 
  xlab(&amp;quot;Penguin Flipper Length (in mm)&amp;quot;) +
  ylab(&amp;quot;Penguin Bill Length (in mm)&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://psqf6250.brandonlebeau.org/rcode/ggplot2_extensions_files/figure-html/penguin-color-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Another potential option would be to add the text labels directly to the figure and not use color. Adding text to a figure is typically done with the &lt;code&gt;geom_text()&lt;/code&gt; function.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(penguins, aes(x = flipper_length_mm, y = bill_length_mm)) + 
  geom_point(size = 4, aes(shape = species)) + 
  geom_text(aes(label = species)) +
  xlab(&amp;quot;Penguin Flipper Length (in mm)&amp;quot;) +
  ylab(&amp;quot;Penguin Bill Length (in mm)&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://psqf6250.brandonlebeau.org/rcode/ggplot2_extensions_files/figure-html/text-labels-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Notice how the text labels overlap and the word is centered with the data point? This makes the plot unusable. We could fiddle with some settings to the &lt;code&gt;geom_text()&lt;/code&gt; function, but the &lt;em&gt;ggrepel&lt;/em&gt; package helps to fix this issue for us without having to guess and test. The primary difference in the code below is to use &lt;code&gt;geom_text_repel()&lt;/code&gt; instead of &lt;code&gt;geom_text()&lt;/code&gt;. Note, I shrunk the data point slightly in the following figure.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(ggrepel)

ggplot(penguins, aes(x = flipper_length_mm, y = bill_length_mm)) + 
  geom_point(size = 3, aes(shape = species)) + 
  geom_text_repel(aes(label = species)) +
  xlab(&amp;quot;Penguin Flipper Length (in mm)&amp;quot;) +
  ylab(&amp;quot;Penguin Bill Length (in mm)&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://psqf6250.brandonlebeau.org/rcode/ggplot2_extensions_files/figure-html/ggrepel-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;This isn’t actually better, but you can see the points were moved away. The issue here is that there are too many text labels to show in a single plot. I’m going to plot only 30 points, 10 from each species.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(dplyr)
set.seed(100)

penguins %&amp;gt;% 
  group_by(species) %&amp;gt;% 
  sample_n(10) %&amp;gt;%
  ggplot(., aes(x = flipper_length_mm, y = bill_length_mm)) + 
  geom_point(size = 3, aes(shape = species)) + 
  geom_text_repel(aes(label = species)) +
  xlab(&amp;quot;Penguin Flipper Length (in mm)&amp;quot;) +
  ylab(&amp;quot;Penguin Bill Length (in mm)&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://psqf6250.brandonlebeau.org/rcode/ggplot2_extensions_files/figure-html/ggrepel-one-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;To see exactly what was done, I’m going to generate the same figure using &lt;code&gt;geom_text()&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;set.seed(100)

penguins %&amp;gt;% 
  group_by(species) %&amp;gt;% 
  sample_n(10) %&amp;gt;%
  ggplot(., aes(x = flipper_length_mm, y = bill_length_mm)) + 
  geom_point(size = 3, aes(shape = species)) + 
  geom_text(aes(label = species)) +
  xlab(&amp;quot;Penguin Flipper Length (in mm)&amp;quot;) +
  ylab(&amp;quot;Penguin Bill Length (in mm)&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://psqf6250.brandonlebeau.org/rcode/ggplot2_extensions_files/figure-html/text-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;div id=&#34;geom_label_repel&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;&lt;code&gt;geom_label_repel()&lt;/code&gt;&lt;/h3&gt;
&lt;p&gt;The &lt;em&gt;ggrepel&lt;/em&gt; package only has two functions, the first we saw, &lt;code&gt;geom_text_repel()&lt;/code&gt;. The second is &lt;code&gt;geom_label_repel()&lt;/code&gt;. This works the same as &lt;code&gt;geom_text_repel()&lt;/code&gt;, but creates a box around the text attribute.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;set.seed(100)

penguins %&amp;gt;% 
  group_by(species) %&amp;gt;% 
  sample_n(10) %&amp;gt;%
  ggplot(., aes(x = flipper_length_mm, y = bill_length_mm)) + 
  geom_point(size = 3, aes(shape = species)) + 
  geom_label_repel(aes(label = species)) +
  xlab(&amp;quot;Penguin Flipper Length (in mm)&amp;quot;) +
  ylab(&amp;quot;Penguin Bill Length (in mm)&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://psqf6250.brandonlebeau.org/rcode/ggplot2_extensions_files/figure-html/label-repel-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ggforce&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;&lt;em&gt;ggforce&lt;/em&gt;&lt;/h3&gt;
&lt;p&gt;The &lt;em&gt;ggforce&lt;/em&gt; package has a few powerful additions. One of these helps to solve the problem of too many text labels when using the entire penguin data and is the problem I’d like to start with.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(penguins, aes(x = flipper_length_mm, y = bill_length_mm)) + 
  geom_point(size = 3, aes(shape = species)) + 
  geom_text_repel(aes(label = species)) +
  xlab(&amp;quot;Penguin Flipper Length (in mm)&amp;quot;) +
  ylab(&amp;quot;Penguin Bill Length (in mm)&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://psqf6250.brandonlebeau.org/rcode/ggplot2_extensions_files/figure-html/ggrepel-toomany-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Way too many text labels and for this example, there would be too many duplicate text labels. Since there are only three species, other ways of showing the text and groups would be helpful. &lt;em&gt;ggforce&lt;/em&gt; helps with this problem using a series of functions that enclose data within different shapes. These functions are &lt;code&gt;geom_mark_rect()&lt;/code&gt;, &lt;code&gt;geom_mark_circle()&lt;/code&gt;, &lt;code&gt;geom_mark_ellipse()&lt;/code&gt;, and &lt;code&gt;geom_mark_hull()&lt;/code&gt; for rectangle, circle, ellipse, and hulls respectively. For an example, let’s try &lt;code&gt;geom_mark_ellipse()&lt;/code&gt; instead of the text labels.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(ggforce)
library(tidyr)

penguins %&amp;gt;%
  drop_na(flipper_length_mm, bill_length_mm) %&amp;gt;%
ggplot(., aes(x = flipper_length_mm, y = bill_length_mm)) + 
  geom_mark_ellipse(aes(fill = species)) +
  geom_point(size = 3, aes(shape = species)) + 
  xlab(&amp;quot;Penguin Flipper Length (in mm)&amp;quot;) +
  ylab(&amp;quot;Penguin Bill Length (in mm)&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://psqf6250.brandonlebeau.org/rcode/ggplot2_extensions_files/figure-html/ggforce-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;To take this one step further, we can add a text label to this figure by setting a label aesthetic to &lt;code&gt;geom_mark_ellipse()&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;penguins %&amp;gt;%
  drop_na(flipper_length_mm, bill_length_mm) %&amp;gt;%
  ggplot(., aes(x = flipper_length_mm, y = bill_length_mm)) + 
  geom_mark_ellipse(aes(fill = species, label = species)) +
  geom_point(size = 3, aes(shape = species)) + 
  scale_x_continuous(&amp;quot;Penguin Flipper Length (in mm)&amp;quot;) +
  scale_y_continuous(&amp;quot;Penguin Bill Length (in mm)&amp;quot;, 
                     limits = c(25, 70))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://psqf6250.brandonlebeau.org/rcode/ggplot2_extensions_files/figure-html/ggforce-label-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Another cool feature of &lt;em&gt;ggforce&lt;/em&gt; is the ability to use something called facet zoom. Essentially, this will create a zoomed in element of a portion of your figure. For example, suppose we wanted to zoom in on the Gentoo penguins to explore their relationship between bill length and flipper length. This creates a picture in picture plotting effect.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(penguins, aes(x = flipper_length_mm, y = bill_length_mm)) + 
  geom_point(size = 3, aes(shape = species, color = species)) + 
  xlab(&amp;quot;Penguin Flipper Length (in mm)&amp;quot;) +
  ylab(&amp;quot;Penguin Bill Length (in mm)&amp;quot;) + 
  facet_zoom(x = species == &amp;#39;Gentoo&amp;#39;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://psqf6250.brandonlebeau.org/rcode/ggplot2_extensions_files/figure-html/facet-zoom-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;patchwork&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;&lt;em&gt;patchwork&lt;/em&gt;&lt;/h1&gt;
&lt;p&gt;The &lt;em&gt;patchwork&lt;/em&gt; package is particularly helpful to combine multiple &lt;em&gt;ggplot2&lt;/em&gt; figures into a single figure, but you don’t want to facet. This can be useful to show multiple different relationships of attributes and combine these into a single figure element to include in a document to share.&lt;/p&gt;
&lt;p&gt;To combine figure elements, basic math notation is used, including &lt;code&gt;+&lt;/code&gt;, &lt;code&gt;/&lt;/code&gt;, or &lt;code&gt;|&lt;/code&gt;. There are other operators as well, but these are the primary ones we will explore and will also use parentheses to group plots together.&lt;/p&gt;
&lt;p&gt;First, let’s create a few plots that we may want to combine.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;p1 &amp;lt;- ggplot(penguins, aes(x = flipper_length_mm, y = bill_length_mm)) + 
  geom_point(size = 4, aes(color = species, shape = species)) + 
  xlab(&amp;quot;Penguin Flipper Length (in mm)&amp;quot;) +
  ylab(&amp;quot;Penguin Bill Length (in mm)&amp;quot;)

p1 &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://psqf6250.brandonlebeau.org/rcode/ggplot2_extensions_files/figure-html/patchwork-plots-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;p2 &amp;lt;- ggplot(penguins, aes(x = flipper_length_mm, y = bill_depth_mm)) + 
  geom_point(size = 4, aes(color = species, shape = species)) + 
  xlab(&amp;quot;Penguin Flipper Length (in mm)&amp;quot;) +
  ylab(&amp;quot;Penguin Bill Depth (in mm)&amp;quot;)
p2&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://psqf6250.brandonlebeau.org/rcode/ggplot2_extensions_files/figure-html/patchwork2-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Now, we will start by using the &lt;code&gt;+&lt;/code&gt; operator to combine plots.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(patchwork)

p1 + p2&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://psqf6250.brandonlebeau.org/rcode/ggplot2_extensions_files/figure-html/patchwork-combine-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;As you can see, the plots are combined directly as generated. In the above example, we’d likely want to only have one legend instead of two. We can do this by modifying the first figure to remove the legend.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;p1 &amp;lt;- ggplot(penguins, aes(x = flipper_length_mm, y = bill_length_mm)) + 
  geom_point(size = 4, aes(color = species, shape = species)) + 
  xlab(&amp;quot;Penguin Flipper Length (in mm)&amp;quot;) +
  ylab(&amp;quot;Penguin Bill Length (in mm)&amp;quot;) + 
  theme(legend.position = &amp;#39;none&amp;#39;)

p1 &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://psqf6250.brandonlebeau.org/rcode/ggplot2_extensions_files/figure-html/no-legend-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;p1 + p2&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://psqf6250.brandonlebeau.org/rcode/ggplot2_extensions_files/figure-html/combine-nolegend-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;We can use the &lt;code&gt;/&lt;/code&gt; operator to stack plots into multiple rows.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;p1 / p2&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://psqf6250.brandonlebeau.org/rcode/ggplot2_extensions_files/figure-html/patchwork-ontop-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;The &lt;code&gt;+&lt;/code&gt; operator has one issue with it, it tries to keep things in a square grid, similar to how &lt;code&gt;facet_wrap()&lt;/code&gt; works. For more advanced layout, the &lt;code&gt;|&lt;/code&gt; operator separates columns whereas we saw above that the &lt;code&gt;/&lt;/code&gt; operator will stack plots. Combined with parentheses, you can get more advanced layouts. First, let’s add one more figure.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;p3 &amp;lt;- ggplot(drop_na(penguins, sex), 
             aes(x = sex, y = body_mass_g)) + 
  geom_violin(aes(fill = species), draw_quantiles = c(0.1, .5, 0.9)) + 
  xlab(&amp;quot;Penguin Sex&amp;quot;) + 
  ylab(&amp;quot;Penguin Body Mass (in g)&amp;quot;) + 
  theme(legend.position = &amp;#39;none&amp;#39;)

p3&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://psqf6250.brandonlebeau.org/rcode/ggplot2_extensions_files/figure-html/patch-box-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;p3 | (p1 / p2)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://psqf6250.brandonlebeau.org/rcode/ggplot2_extensions_files/figure-html/patchwork-combined-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Note, without parentheses, the figures may not turn out as you want.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;p1 | p2 / p3&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://psqf6250.brandonlebeau.org/rcode/ggplot2_extensions_files/figure-html/patchwork-error-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;(p1 + p2) / p3&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://psqf6250.brandonlebeau.org/rcode/ggplot2_extensions_files/figure-html/patchwork-correct-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Graphics Tips</title>
      <link>https://psqf6250.brandonlebeau.org/rcode/graphics-tips/</link>
      <pubDate>Wed, 03 Feb 2021 00:00:00 +0000</pubDate>
      <guid>https://psqf6250.brandonlebeau.org/rcode/graphics-tips/</guid>
      <description>
&lt;script src=&#34;https://psqf6250.brandonlebeau.org/rmarkdown-libs/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;

&lt;div id=&#34;TOC&#34;&gt;

&lt;/div&gt;

&lt;div id=&#34;graphics-basics&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Graphics Basics&lt;/h1&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;What is the story you want to tell?&lt;/li&gt;
&lt;li&gt;Is the figure misleading?&lt;/li&gt;
&lt;li&gt;Could other figure types be more effective?&lt;/li&gt;
&lt;li&gt;Does the figure show variation?&lt;/li&gt;
&lt;li&gt;Is the figure self-contained?&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;div id=&#34;misleading-graphs&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Misleading Graphs&lt;/h1&gt;
&lt;p&gt;Data visualization is hard and it is easy to mislead, intentionally or unintentionally.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://psqf6250.brandonlebeau.org/rcode/graphics-tips_files/figure-html/mislead-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;better-approach&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Better Approach&lt;/h1&gt;
&lt;p&gt;&lt;img src=&#34;https://psqf6250.brandonlebeau.org/rcode/graphics-tips_files/figure-html/better-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;axis-labels&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Axis Labels&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;Axis labels are often placed on the x-axis, but for long labels this can be less effective.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://psqf6250.brandonlebeau.org/rcode/graphics-tips_files/figure-html/Axis-labels-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;axis-labels-2&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Axis Labels 2&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;Often, the labels are rotated. Works, but is ugly and difficult to read in my opinion.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://psqf6250.brandonlebeau.org/rcode/graphics-tips_files/figure-html/labels-rotate-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;axis-labels-3&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Axis Labels 3&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;The solution, flip x and y axis using &lt;code&gt;coord_flip()&lt;/code&gt;!&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://psqf6250.brandonlebeau.org/rcode/graphics-tips_files/figure-html/flip-axes-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;showing-variation&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Showing Variation&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;Figures depicting statistics, should show variation.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://psqf6250.brandonlebeau.org/rcode/graphics-tips_files/figure-html/mean-plot-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;showing-variation-2&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Showing Variation 2&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;There are multiple values for each major category, the mean is useful, but simplifies too much and could mislead.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://psqf6250.brandonlebeau.org/rcode/graphics-tips_files/figure-html/violin-plot-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Data Manipulation</title>
      <link>https://psqf6250.brandonlebeau.org/rcode/data_munging/</link>
      <pubDate>Mon, 08 Feb 2021 00:00:00 +0000</pubDate>
      <guid>https://psqf6250.brandonlebeau.org/rcode/data_munging/</guid>
      <description>
&lt;script src=&#34;https://psqf6250.brandonlebeau.org/rmarkdown-libs/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;

&lt;div id=&#34;TOC&#34;&gt;

&lt;/div&gt;

&lt;p&gt;Data munging (i.e. data transformations, variable creation, filtering) is a common task that is often overlooked in traditional statistics textbooks and courses. Even though it is omitted, the task of cleaning and organizing the data (coming in week 5 of the course)&lt;/p&gt;
&lt;p&gt;Data from the &lt;code&gt;fivethirtyeight&lt;/code&gt; package is used in this set of notes to show the use of the &lt;code&gt;dplyr&lt;/code&gt; verbs for data munging. This package can be installed with the following command:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;install.packages(&amp;quot;fivethirtyeight&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;To get started with this set of notes, you will need the following packages loaded:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(fivethirtyeight)
library(tidyverse)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We are going to explore the &lt;code&gt;congress_age&lt;/code&gt; data set in more detail. Take a few minutes to familiarize yourself with the data.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;View(congress_age)
?congress_age&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;congress_age&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 18,635 × 13
##    congress chamber bioguide firstname middlename lastname  suffix birthday  
##       &amp;lt;int&amp;gt; &amp;lt;chr&amp;gt;   &amp;lt;chr&amp;gt;    &amp;lt;chr&amp;gt;     &amp;lt;chr&amp;gt;      &amp;lt;chr&amp;gt;     &amp;lt;chr&amp;gt;  &amp;lt;date&amp;gt;    
##  1       80 house   M000112  Joseph    Jefferson  Mansfield &amp;lt;NA&amp;gt;   1861-02-09
##  2       80 house   D000448  Robert    Lee        Doughton  &amp;lt;NA&amp;gt;   1863-11-07
##  3       80 house   S000001  Adolph    Joachim    Sabath    &amp;lt;NA&amp;gt;   1866-04-04
##  4       80 house   E000023  Charles   Aubrey     Eaton     &amp;lt;NA&amp;gt;   1868-03-29
##  5       80 house   L000296  William   &amp;lt;NA&amp;gt;       Lewis     &amp;lt;NA&amp;gt;   1868-09-22
##  6       80 house   G000017  James     A.         Gallagher &amp;lt;NA&amp;gt;   1869-01-16
##  7       80 house   W000265  Richard   Joseph     Welch     &amp;lt;NA&amp;gt;   1869-02-13
##  8       80 house   B000565  Sol       &amp;lt;NA&amp;gt;       Bloom     &amp;lt;NA&amp;gt;   1870-03-09
##  9       80 house   H000943  Merlin    &amp;lt;NA&amp;gt;       Hull      &amp;lt;NA&amp;gt;   1870-12-18
## 10       80 house   G000169  Charles   Laceille   Gifford   &amp;lt;NA&amp;gt;   1871-03-15
## # … with 18,625 more rows, and 5 more variables: state &amp;lt;chr&amp;gt;, party &amp;lt;chr&amp;gt;,
## #   incumbent &amp;lt;lgl&amp;gt;, termstart &amp;lt;date&amp;gt;, age &amp;lt;dbl&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;div id=&#34;using-dplyr-for-data-munging&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Using &lt;code&gt;dplyr&lt;/code&gt; for data munging&lt;/h2&gt;
&lt;p&gt;The &lt;code&gt;dplyr&lt;/code&gt; package uses verbs for common data manipulation tasks. These include:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;filter()&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;arrange()&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;select()&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;mutate()&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;summarise()&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The great aspect of these verbs are that they all take a similar data structure, the first argument is always the data, the other arguments are unquoted column names. These functions also always return a data frame in which the rows are observations and the columns are variables.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;examples-with-filter&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Examples with &lt;code&gt;filter()&lt;/code&gt;&lt;/h2&gt;
&lt;p&gt;The &lt;code&gt;filter&lt;/code&gt; function selects rows that match a specified condition(s). For example, suppose we wanted to select only the rows in the data that are a part of the 80th congress. The following code will do this action:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;filter(congress_age, congress == 80)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 555 × 13
##    congress chamber bioguide firstname middlename lastname  suffix birthday  
##       &amp;lt;int&amp;gt; &amp;lt;chr&amp;gt;   &amp;lt;chr&amp;gt;    &amp;lt;chr&amp;gt;     &amp;lt;chr&amp;gt;      &amp;lt;chr&amp;gt;     &amp;lt;chr&amp;gt;  &amp;lt;date&amp;gt;    
##  1       80 house   M000112  Joseph    Jefferson  Mansfield &amp;lt;NA&amp;gt;   1861-02-09
##  2       80 house   D000448  Robert    Lee        Doughton  &amp;lt;NA&amp;gt;   1863-11-07
##  3       80 house   S000001  Adolph    Joachim    Sabath    &amp;lt;NA&amp;gt;   1866-04-04
##  4       80 house   E000023  Charles   Aubrey     Eaton     &amp;lt;NA&amp;gt;   1868-03-29
##  5       80 house   L000296  William   &amp;lt;NA&amp;gt;       Lewis     &amp;lt;NA&amp;gt;   1868-09-22
##  6       80 house   G000017  James     A.         Gallagher &amp;lt;NA&amp;gt;   1869-01-16
##  7       80 house   W000265  Richard   Joseph     Welch     &amp;lt;NA&amp;gt;   1869-02-13
##  8       80 house   B000565  Sol       &amp;lt;NA&amp;gt;       Bloom     &amp;lt;NA&amp;gt;   1870-03-09
##  9       80 house   H000943  Merlin    &amp;lt;NA&amp;gt;       Hull      &amp;lt;NA&amp;gt;   1870-12-18
## 10       80 house   G000169  Charles   Laceille   Gifford   &amp;lt;NA&amp;gt;   1871-03-15
## # … with 545 more rows, and 5 more variables: state &amp;lt;chr&amp;gt;, party &amp;lt;chr&amp;gt;,
## #   incumbent &amp;lt;lgl&amp;gt;, termstart &amp;lt;date&amp;gt;, age &amp;lt;dbl&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Notice from above two things, first, the function returned a new data frame. Therefore, if this subsetted data is to be saved, we need to save it to an object, for example, as follows:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;congress_80 &amp;lt;- filter(congress_age, congress == 80)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Notice now that the data were not automatically printed, instead it was saved into the object called &lt;code&gt;congress_80&lt;/code&gt;. If you wish to preview the data and save it to an object in a single step, you need to wrap the command above in parentheses. Take a second to try this yourself.&lt;/p&gt;
&lt;p&gt;Secondly, notice from the above commands that equality in R is done with &lt;code&gt;==&lt;/code&gt; not just a single &lt;code&gt;=&lt;/code&gt;. The single &lt;code&gt;=&lt;/code&gt; is used for named arguments, therefore when testing for equality you need to be sure to use &lt;code&gt;==&lt;/code&gt;, this is a common frustration and source of bugs when getting started with R.&lt;/p&gt;
&lt;p&gt;Selecting values based on a character vector are similar to numeric values. For example, suppose we wanted to select only those rows pertaining to those from the senate. The following code will do that:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;senate &amp;lt;- filter(congress_age, chamber == &amp;#39;senate&amp;#39;)&lt;/code&gt;&lt;/pre&gt;
&lt;div id=&#34;combining-logical-operations&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Combining Logical Operations&lt;/h3&gt;
&lt;p&gt;The &lt;code&gt;filter&lt;/code&gt; function becomes much more useful with more complex operations. For example, suppose we were interested in selecting the rows that belong to the 80th senate.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;filter(congress_age, congress == 80, chamber == &amp;#39;senate&amp;#39;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 102 × 13
##    congress chamber bioguide firstname middlename lastname suffix birthday  
##       &amp;lt;int&amp;gt; &amp;lt;chr&amp;gt;   &amp;lt;chr&amp;gt;    &amp;lt;chr&amp;gt;     &amp;lt;chr&amp;gt;      &amp;lt;chr&amp;gt;    &amp;lt;chr&amp;gt;  &amp;lt;date&amp;gt;    
##  1       80 senate  C000133  Arthur    &amp;lt;NA&amp;gt;       Capper   &amp;lt;NA&amp;gt;   1865-07-14
##  2       80 senate  G000418  Theodore  Francis    Green    &amp;lt;NA&amp;gt;   1867-10-02
##  3       80 senate  M000499  Kenneth   Douglas    McKellar &amp;lt;NA&amp;gt;   1869-01-29
##  4       80 senate  R000112  Clyde     Martin     Reed     &amp;lt;NA&amp;gt;   1871-10-19
##  5       80 senate  M000895  Edward    Hall       Moore    &amp;lt;NA&amp;gt;   1871-11-19
##  6       80 senate  O000146  John      Holmes     Overton  &amp;lt;NA&amp;gt;   1875-09-17
##  7       80 senate  M001108  James     Edward     Murray   &amp;lt;NA&amp;gt;   1876-05-03
##  8       80 senate  M000308  Patrick   Anthony    McCarran &amp;lt;NA&amp;gt;   1876-08-08
##  9       80 senate  T000165  Elmer     &amp;lt;NA&amp;gt;       Thomas   &amp;lt;NA&amp;gt;   1876-09-08
## 10       80 senate  W000021  Robert    Ferdinand  Wagner   &amp;lt;NA&amp;gt;   1877-06-08
## # … with 92 more rows, and 5 more variables: state &amp;lt;chr&amp;gt;, party &amp;lt;chr&amp;gt;,
## #   incumbent &amp;lt;lgl&amp;gt;, termstart &amp;lt;date&amp;gt;, age &amp;lt;dbl&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;By default, the &lt;code&gt;filter&lt;/code&gt; function uses AND when combining multiple arguments. Therefore, the above command returned only the 102 rows belonging to senators from the 80th congress. The figure on &lt;a href=&#34;https://r4ds.had.co.nz/transform.html#logical-operators&#34;&gt;section 5.2.2&lt;/a&gt; of R for Data Science shows all the possible boolean operators.&lt;/p&gt;
&lt;p&gt;Using an example of the OR operator using &lt;code&gt;|&lt;/code&gt; to select the 80th and 81st congress:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;filter(congress_age, congress == 80 | congress == 81)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 1,112 × 13
##    congress chamber bioguide firstname middlename lastname  suffix birthday  
##       &amp;lt;int&amp;gt; &amp;lt;chr&amp;gt;   &amp;lt;chr&amp;gt;    &amp;lt;chr&amp;gt;     &amp;lt;chr&amp;gt;      &amp;lt;chr&amp;gt;     &amp;lt;chr&amp;gt;  &amp;lt;date&amp;gt;    
##  1       80 house   M000112  Joseph    Jefferson  Mansfield &amp;lt;NA&amp;gt;   1861-02-09
##  2       80 house   D000448  Robert    Lee        Doughton  &amp;lt;NA&amp;gt;   1863-11-07
##  3       80 house   S000001  Adolph    Joachim    Sabath    &amp;lt;NA&amp;gt;   1866-04-04
##  4       80 house   E000023  Charles   Aubrey     Eaton     &amp;lt;NA&amp;gt;   1868-03-29
##  5       80 house   L000296  William   &amp;lt;NA&amp;gt;       Lewis     &amp;lt;NA&amp;gt;   1868-09-22
##  6       80 house   G000017  James     A.         Gallagher &amp;lt;NA&amp;gt;   1869-01-16
##  7       80 house   W000265  Richard   Joseph     Welch     &amp;lt;NA&amp;gt;   1869-02-13
##  8       80 house   B000565  Sol       &amp;lt;NA&amp;gt;       Bloom     &amp;lt;NA&amp;gt;   1870-03-09
##  9       80 house   H000943  Merlin    &amp;lt;NA&amp;gt;       Hull      &amp;lt;NA&amp;gt;   1870-12-18
## 10       80 house   G000169  Charles   Laceille   Gifford   &amp;lt;NA&amp;gt;   1871-03-15
## # … with 1,102 more rows, and 5 more variables: state &amp;lt;chr&amp;gt;, party &amp;lt;chr&amp;gt;,
## #   incumbent &amp;lt;lgl&amp;gt;, termstart &amp;lt;date&amp;gt;, age &amp;lt;dbl&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Note that to do the OR operator, you need to name the variable twice. When selecting multiple values in the same variable, a handy shortcut is &lt;code&gt;%in%&lt;/code&gt;. The same command can be run with the following shorthand: handy shortcut is &lt;code&gt;%in%&lt;/code&gt;. The same command can be run with the following shorthard&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;filter(congress_age, congress %in% c(80, 81))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 1,112 × 13
##    congress chamber bioguide firstname middlename lastname  suffix birthday  
##       &amp;lt;int&amp;gt; &amp;lt;chr&amp;gt;   &amp;lt;chr&amp;gt;    &amp;lt;chr&amp;gt;     &amp;lt;chr&amp;gt;      &amp;lt;chr&amp;gt;     &amp;lt;chr&amp;gt;  &amp;lt;date&amp;gt;    
##  1       80 house   M000112  Joseph    Jefferson  Mansfield &amp;lt;NA&amp;gt;   1861-02-09
##  2       80 house   D000448  Robert    Lee        Doughton  &amp;lt;NA&amp;gt;   1863-11-07
##  3       80 house   S000001  Adolph    Joachim    Sabath    &amp;lt;NA&amp;gt;   1866-04-04
##  4       80 house   E000023  Charles   Aubrey     Eaton     &amp;lt;NA&amp;gt;   1868-03-29
##  5       80 house   L000296  William   &amp;lt;NA&amp;gt;       Lewis     &amp;lt;NA&amp;gt;   1868-09-22
##  6       80 house   G000017  James     A.         Gallagher &amp;lt;NA&amp;gt;   1869-01-16
##  7       80 house   W000265  Richard   Joseph     Welch     &amp;lt;NA&amp;gt;   1869-02-13
##  8       80 house   B000565  Sol       &amp;lt;NA&amp;gt;       Bloom     &amp;lt;NA&amp;gt;   1870-03-09
##  9       80 house   H000943  Merlin    &amp;lt;NA&amp;gt;       Hull      &amp;lt;NA&amp;gt;   1870-12-18
## 10       80 house   G000169  Charles   Laceille   Gifford   &amp;lt;NA&amp;gt;   1871-03-15
## # … with 1,102 more rows, and 5 more variables: state &amp;lt;chr&amp;gt;, party &amp;lt;chr&amp;gt;,
## #   incumbent &amp;lt;lgl&amp;gt;, termstart &amp;lt;date&amp;gt;, age &amp;lt;dbl&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;not-operator&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Not Operator&lt;/h3&gt;
&lt;p&gt;Another useful operator that deserves a bit more discussion is the not operator, &lt;code&gt;!&lt;/code&gt;. For example, suppose we wanted to omit the 80th congress:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;filter(congress_age, congress != 80)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 18,080 × 13
##    congress chamber bioguide firstname middlename lastname suffix birthday  
##       &amp;lt;int&amp;gt; &amp;lt;chr&amp;gt;   &amp;lt;chr&amp;gt;    &amp;lt;chr&amp;gt;     &amp;lt;chr&amp;gt;      &amp;lt;chr&amp;gt;    &amp;lt;chr&amp;gt;  &amp;lt;date&amp;gt;    
##  1       81 house   D000448  Robert    Lee        Doughton &amp;lt;NA&amp;gt;   1863-11-07
##  2       81 house   S000001  Adolph    Joachim    Sabath   &amp;lt;NA&amp;gt;   1866-04-04
##  3       81 house   E000023  Charles   Aubrey     Eaton    &amp;lt;NA&amp;gt;   1868-03-29
##  4       81 house   W000265  Richard   Joseph     Welch    &amp;lt;NA&amp;gt;   1869-02-13
##  5       81 house   B000565  Sol       &amp;lt;NA&amp;gt;       Bloom    &amp;lt;NA&amp;gt;   1870-03-09
##  6       81 house   H000943  Merlin    &amp;lt;NA&amp;gt;       Hull     &amp;lt;NA&amp;gt;   1870-12-18
##  7       81 house   B000545  Schuyler  Otis       Bland    &amp;lt;NA&amp;gt;   1872-05-04
##  8       81 house   K000138  John      Hosea      Kerr     &amp;lt;NA&amp;gt;   1873-12-31
##  9       81 house   C000932  Robert    &amp;lt;NA&amp;gt;       Crosser  &amp;lt;NA&amp;gt;   1874-06-07
## 10       81 house   K000039  John      &amp;lt;NA&amp;gt;       Kee      &amp;lt;NA&amp;gt;   1874-08-22
## # … with 18,070 more rows, and 5 more variables: state &amp;lt;chr&amp;gt;, party &amp;lt;chr&amp;gt;,
## #   incumbent &amp;lt;lgl&amp;gt;, termstart &amp;lt;date&amp;gt;, age &amp;lt;dbl&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;It is also possible to do not with an AND operator as follows:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;filter(congress_age, congress == 80 &amp;amp; !chamber == &amp;#39;senate&amp;#39;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 453 × 13
##    congress chamber bioguide firstname middlename lastname  suffix birthday  
##       &amp;lt;int&amp;gt; &amp;lt;chr&amp;gt;   &amp;lt;chr&amp;gt;    &amp;lt;chr&amp;gt;     &amp;lt;chr&amp;gt;      &amp;lt;chr&amp;gt;     &amp;lt;chr&amp;gt;  &amp;lt;date&amp;gt;    
##  1       80 house   M000112  Joseph    Jefferson  Mansfield &amp;lt;NA&amp;gt;   1861-02-09
##  2       80 house   D000448  Robert    Lee        Doughton  &amp;lt;NA&amp;gt;   1863-11-07
##  3       80 house   S000001  Adolph    Joachim    Sabath    &amp;lt;NA&amp;gt;   1866-04-04
##  4       80 house   E000023  Charles   Aubrey     Eaton     &amp;lt;NA&amp;gt;   1868-03-29
##  5       80 house   L000296  William   &amp;lt;NA&amp;gt;       Lewis     &amp;lt;NA&amp;gt;   1868-09-22
##  6       80 house   G000017  James     A.         Gallagher &amp;lt;NA&amp;gt;   1869-01-16
##  7       80 house   W000265  Richard   Joseph     Welch     &amp;lt;NA&amp;gt;   1869-02-13
##  8       80 house   B000565  Sol       &amp;lt;NA&amp;gt;       Bloom     &amp;lt;NA&amp;gt;   1870-03-09
##  9       80 house   H000943  Merlin    &amp;lt;NA&amp;gt;       Hull      &amp;lt;NA&amp;gt;   1870-12-18
## 10       80 house   G000169  Charles   Laceille   Gifford   &amp;lt;NA&amp;gt;   1871-03-15
## # … with 443 more rows, and 5 more variables: state &amp;lt;chr&amp;gt;, party &amp;lt;chr&amp;gt;,
## #   incumbent &amp;lt;lgl&amp;gt;, termstart &amp;lt;date&amp;gt;, age &amp;lt;dbl&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;div id=&#34;exercises&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Exercises&lt;/h4&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;Using the congress data, select the rows belonging to the democrats (party = D) from the senate of the 100th congress.&lt;/li&gt;
&lt;li&gt;Select all congress members who are older than 80 years old.&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;note-on-missing-data&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Note on Missing Data&lt;/h3&gt;
&lt;p&gt;Missing data within R are represented with &lt;code&gt;NA&lt;/code&gt; which stands for not available.&lt;/p&gt;
&lt;p&gt;There are no missing data in the congress data, however, by default the &lt;code&gt;filter&lt;/code&gt; function will not return any missing values. In order to select missing data, you need to use the &lt;code&gt;is.na&lt;/code&gt; function.&lt;/p&gt;
&lt;div id=&#34;exercise&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Exercise&lt;/h4&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;Given the following simple vector, run one filter that selects all values greater than 100. Write a second filter command that selects all the rows greater than 100 and also the NA value.&lt;/li&gt;
&lt;/ol&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;df &amp;lt;- tibble(x = c(200, 30, NA, 45, 212))&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;examples-with-arrange&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Examples with &lt;code&gt;arrange()&lt;/code&gt;&lt;/h2&gt;
&lt;p&gt;The &lt;code&gt;arrange&lt;/code&gt; function is used for ordering rows in the data. For example, suppose we wanted to order the rows in the congress data by the state the members of congress lived in. This can be done using the &lt;code&gt;arrange&lt;/code&gt; function as follows:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;arrange(congress_age, state)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 18,635 × 13
##    congress chamber bioguide firstname middlename lastname suffix birthday  
##       &amp;lt;int&amp;gt; &amp;lt;chr&amp;gt;   &amp;lt;chr&amp;gt;    &amp;lt;chr&amp;gt;     &amp;lt;chr&amp;gt;      &amp;lt;chr&amp;gt;    &amp;lt;chr&amp;gt;  &amp;lt;date&amp;gt;    
##  1       80 house   B000201  Edward    Lewis      Bartlett &amp;lt;NA&amp;gt;   1904-04-20
##  2       81 house   B000201  Edward    Lewis      Bartlett &amp;lt;NA&amp;gt;   1904-04-20
##  3       82 house   B000201  Edward    Lewis      Bartlett &amp;lt;NA&amp;gt;   1904-04-20
##  4       83 house   B000201  Edward    Lewis      Bartlett &amp;lt;NA&amp;gt;   1904-04-20
##  5       84 house   B000201  Edward    Lewis      Bartlett &amp;lt;NA&amp;gt;   1904-04-20
##  6       85 house   B000201  Edward    Lewis      Bartlett &amp;lt;NA&amp;gt;   1904-04-20
##  7       86 house   R000282  Ralph     Julian     Rivers   &amp;lt;NA&amp;gt;   1903-05-23
##  8       86 senate  G000508  Ernest    &amp;lt;NA&amp;gt;       Gruening &amp;lt;NA&amp;gt;   1887-02-06
##  9       86 senate  B000201  Edward    Lewis      Bartlett &amp;lt;NA&amp;gt;   1904-04-20
## 10       87 house   R000282  Ralph     Julian     Rivers   &amp;lt;NA&amp;gt;   1903-05-23
## # … with 18,625 more rows, and 5 more variables: state &amp;lt;chr&amp;gt;, party &amp;lt;chr&amp;gt;,
## #   incumbent &amp;lt;lgl&amp;gt;, termstart &amp;lt;date&amp;gt;, age &amp;lt;dbl&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Similar to the filter function, additional arguments can be added to add more layers to the ordering. For example, if we were interested in ordering the rows by state and then by party affiliation.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;arrange(congress_age, state, party)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 18,635 × 13
##    congress chamber bioguide firstname middlename lastname suffix birthday  
##       &amp;lt;int&amp;gt; &amp;lt;chr&amp;gt;   &amp;lt;chr&amp;gt;    &amp;lt;chr&amp;gt;     &amp;lt;chr&amp;gt;      &amp;lt;chr&amp;gt;    &amp;lt;chr&amp;gt;  &amp;lt;date&amp;gt;    
##  1       80 house   B000201  Edward    Lewis      Bartlett &amp;lt;NA&amp;gt;   1904-04-20
##  2       81 house   B000201  Edward    Lewis      Bartlett &amp;lt;NA&amp;gt;   1904-04-20
##  3       82 house   B000201  Edward    Lewis      Bartlett &amp;lt;NA&amp;gt;   1904-04-20
##  4       83 house   B000201  Edward    Lewis      Bartlett &amp;lt;NA&amp;gt;   1904-04-20
##  5       84 house   B000201  Edward    Lewis      Bartlett &amp;lt;NA&amp;gt;   1904-04-20
##  6       85 house   B000201  Edward    Lewis      Bartlett &amp;lt;NA&amp;gt;   1904-04-20
##  7       86 house   R000282  Ralph     Julian     Rivers   &amp;lt;NA&amp;gt;   1903-05-23
##  8       86 senate  G000508  Ernest    &amp;lt;NA&amp;gt;       Gruening &amp;lt;NA&amp;gt;   1887-02-06
##  9       86 senate  B000201  Edward    Lewis      Bartlett &amp;lt;NA&amp;gt;   1904-04-20
## 10       87 house   R000282  Ralph     Julian     Rivers   &amp;lt;NA&amp;gt;   1903-05-23
## # … with 18,625 more rows, and 5 more variables: state &amp;lt;chr&amp;gt;, party &amp;lt;chr&amp;gt;,
## #   incumbent &amp;lt;lgl&amp;gt;, termstart &amp;lt;date&amp;gt;, age &amp;lt;dbl&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;More variables can easily be added to the &lt;code&gt;arrange&lt;/code&gt; function. Notice from the above two commands that the ordering of the rows is in ascending order, if descending order is desired, the &lt;code&gt;desc&lt;/code&gt; function. For example, to order the data starting with the latest congress first:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;arrange(congress_age, desc(congress))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 18,635 × 13
##    congress chamber bioguide firstname middlename lastname  suffix birthday  
##       &amp;lt;int&amp;gt; &amp;lt;chr&amp;gt;   &amp;lt;chr&amp;gt;    &amp;lt;chr&amp;gt;     &amp;lt;chr&amp;gt;      &amp;lt;chr&amp;gt;     &amp;lt;chr&amp;gt;  &amp;lt;date&amp;gt;    
##  1      113 house   H000067  Ralph     M.         Hall      &amp;lt;NA&amp;gt;   1923-05-03
##  2      113 house   D000355  John      D.         Dingell   &amp;lt;NA&amp;gt;   1926-07-08
##  3      113 house   C000714  John      &amp;lt;NA&amp;gt;       Conyers   Jr.    1929-05-16
##  4      113 house   S000480  Louise    McIntosh   Slaughter &amp;lt;NA&amp;gt;   1929-08-14
##  5      113 house   R000053  Charles   B.         Rangel    &amp;lt;NA&amp;gt;   1930-06-11
##  6      113 house   J000174  Sam       Robert     Johnson   &amp;lt;NA&amp;gt;   1930-10-11
##  7      113 house   Y000031  C.        W. Bill    Young     &amp;lt;NA&amp;gt;   1930-12-16
##  8      113 house   C000556  Howard    &amp;lt;NA&amp;gt;       Coble     &amp;lt;NA&amp;gt;   1931-03-18
##  9      113 house   L000263  Sander    M.         Levin     &amp;lt;NA&amp;gt;   1931-09-06
## 10      113 house   Y000033  Don       E.         Young     &amp;lt;NA&amp;gt;   1933-06-09
## # … with 18,625 more rows, and 5 more variables: state &amp;lt;chr&amp;gt;, party &amp;lt;chr&amp;gt;,
## #   incumbent &amp;lt;lgl&amp;gt;, termstart &amp;lt;date&amp;gt;, age &amp;lt;dbl&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;examples-with-select&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Examples with &lt;code&gt;select()&lt;/code&gt;&lt;/h2&gt;
&lt;p&gt;The &lt;code&gt;select&lt;/code&gt; function is used to select columns (i.e. variables) from the data but keep all the rows. For example, maybe we only needed the congress number, the chamber, the party affiliation, and the age of the members of congress. We can reduce the data to just these variables using &lt;code&gt;select&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;select(congress_age, congress, chamber, party, age)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 18,635 × 4
##    congress chamber party   age
##       &amp;lt;int&amp;gt; &amp;lt;chr&amp;gt;   &amp;lt;chr&amp;gt; &amp;lt;dbl&amp;gt;
##  1       80 house   D      85.9
##  2       80 house   D      83.2
##  3       80 house   D      80.7
##  4       80 house   R      78.8
##  5       80 house   R      78.3
##  6       80 house   R      78  
##  7       80 house   R      77.9
##  8       80 house   D      76.8
##  9       80 house   R      76  
## 10       80 house   R      75.8
## # … with 18,625 more rows&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Similar to the &lt;code&gt;arrange&lt;/code&gt; functions, the variables that you wish to keep are separated by commas and come after the data argument.&lt;/p&gt;
&lt;p&gt;For more complex selection, the &lt;code&gt;dplyr&lt;/code&gt; package has additional functions that are helpful for variable selection. These include:
- &lt;code&gt;starts_with()&lt;/code&gt;
- &lt;code&gt;ends_with()&lt;/code&gt;
- &lt;code&gt;contains()&lt;/code&gt;
- &lt;code&gt;matches()&lt;/code&gt;
- &lt;code&gt;num_range()&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;These helper functions can be useful for selecting many variables that match a specific pattern. For example, suppose we were interested in selecting all the name variables, this can be accomplished using the &lt;code&gt;contains&lt;/code&gt; function as follows:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;select(congress_age, contains(&amp;#39;name&amp;#39;))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 18,635 × 3
##    firstname middlename lastname 
##    &amp;lt;chr&amp;gt;     &amp;lt;chr&amp;gt;      &amp;lt;chr&amp;gt;    
##  1 Joseph    Jefferson  Mansfield
##  2 Robert    Lee        Doughton 
##  3 Adolph    Joachim    Sabath   
##  4 Charles   Aubrey     Eaton    
##  5 William   &amp;lt;NA&amp;gt;       Lewis    
##  6 James     A.         Gallagher
##  7 Richard   Joseph     Welch    
##  8 Sol       &amp;lt;NA&amp;gt;       Bloom    
##  9 Merlin    &amp;lt;NA&amp;gt;       Hull     
## 10 Charles   Laceille   Gifford  
## # … with 18,625 more rows&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Another useful shorthand to select multiple columns in succession is the &lt;code&gt;:&lt;/code&gt; operator. For example, suppose we wanted to select all the variables between congress and bithday.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;select(congress_age, congress:birthday)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 18,635 × 8
##    congress chamber bioguide firstname middlename lastname  suffix birthday  
##       &amp;lt;int&amp;gt; &amp;lt;chr&amp;gt;   &amp;lt;chr&amp;gt;    &amp;lt;chr&amp;gt;     &amp;lt;chr&amp;gt;      &amp;lt;chr&amp;gt;     &amp;lt;chr&amp;gt;  &amp;lt;date&amp;gt;    
##  1       80 house   M000112  Joseph    Jefferson  Mansfield &amp;lt;NA&amp;gt;   1861-02-09
##  2       80 house   D000448  Robert    Lee        Doughton  &amp;lt;NA&amp;gt;   1863-11-07
##  3       80 house   S000001  Adolph    Joachim    Sabath    &amp;lt;NA&amp;gt;   1866-04-04
##  4       80 house   E000023  Charles   Aubrey     Eaton     &amp;lt;NA&amp;gt;   1868-03-29
##  5       80 house   L000296  William   &amp;lt;NA&amp;gt;       Lewis     &amp;lt;NA&amp;gt;   1868-09-22
##  6       80 house   G000017  James     A.         Gallagher &amp;lt;NA&amp;gt;   1869-01-16
##  7       80 house   W000265  Richard   Joseph     Welch     &amp;lt;NA&amp;gt;   1869-02-13
##  8       80 house   B000565  Sol       &amp;lt;NA&amp;gt;       Bloom     &amp;lt;NA&amp;gt;   1870-03-09
##  9       80 house   H000943  Merlin    &amp;lt;NA&amp;gt;       Hull      &amp;lt;NA&amp;gt;   1870-12-18
## 10       80 house   G000169  Charles   Laceille   Gifford   &amp;lt;NA&amp;gt;   1871-03-15
## # … with 18,625 more rows&lt;/code&gt;&lt;/pre&gt;
&lt;div id=&#34;rename-variables&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Rename variables&lt;/h3&gt;
&lt;p&gt;The select function does allow you to rename variables, however, using the select function to rename variables is not usually advised as you may end up missing a variable that you wish to keep during the renaming operation. Instead, using the &lt;code&gt;rename&lt;/code&gt; function is better practice.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;rename(congress_age, first_name = firstname, last_name = lastname)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 18,635 × 13
##    congress chamber bioguide first_name middlename last_name suffix birthday  
##       &amp;lt;int&amp;gt; &amp;lt;chr&amp;gt;   &amp;lt;chr&amp;gt;    &amp;lt;chr&amp;gt;      &amp;lt;chr&amp;gt;      &amp;lt;chr&amp;gt;     &amp;lt;chr&amp;gt;  &amp;lt;date&amp;gt;    
##  1       80 house   M000112  Joseph     Jefferson  Mansfield &amp;lt;NA&amp;gt;   1861-02-09
##  2       80 house   D000448  Robert     Lee        Doughton  &amp;lt;NA&amp;gt;   1863-11-07
##  3       80 house   S000001  Adolph     Joachim    Sabath    &amp;lt;NA&amp;gt;   1866-04-04
##  4       80 house   E000023  Charles    Aubrey     Eaton     &amp;lt;NA&amp;gt;   1868-03-29
##  5       80 house   L000296  William    &amp;lt;NA&amp;gt;       Lewis     &amp;lt;NA&amp;gt;   1868-09-22
##  6       80 house   G000017  James      A.         Gallagher &amp;lt;NA&amp;gt;   1869-01-16
##  7       80 house   W000265  Richard    Joseph     Welch     &amp;lt;NA&amp;gt;   1869-02-13
##  8       80 house   B000565  Sol        &amp;lt;NA&amp;gt;       Bloom     &amp;lt;NA&amp;gt;   1870-03-09
##  9       80 house   H000943  Merlin     &amp;lt;NA&amp;gt;       Hull      &amp;lt;NA&amp;gt;   1870-12-18
## 10       80 house   G000169  Charles    Laceille   Gifford   &amp;lt;NA&amp;gt;   1871-03-15
## # … with 18,625 more rows, and 5 more variables: state &amp;lt;chr&amp;gt;, party &amp;lt;chr&amp;gt;,
## #   incumbent &amp;lt;lgl&amp;gt;, termstart &amp;lt;date&amp;gt;, age &amp;lt;dbl&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;By default, the rename function will not save changes to the object, if you wish to save the name differences (very likely), be sure to save this new step to an object.&lt;/p&gt;
&lt;div id=&#34;exercises-1&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Exercises&lt;/h4&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;Using the &lt;code&gt;dplyr&lt;/code&gt; helper functions, select all the variables that start with the letter ‘c’.&lt;/li&gt;
&lt;li&gt;Rename the first three variables in the congress data to ‘x1’, ‘x2’, ‘x3’.&lt;/li&gt;
&lt;li&gt;After renaming the first three variables, use this new data (ensure you saved the previous step to an object) to select these three variables with the &lt;code&gt;num_range&lt;/code&gt; function.&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;examples-with-mutate&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Examples with &lt;code&gt;mutate()&lt;/code&gt;&lt;/h2&gt;
&lt;p&gt;&lt;code&gt;mutate&lt;/code&gt; is a useful verb that allows you to add new columns to the existing data set. Actions done with &lt;code&gt;mutate&lt;/code&gt; include adding a column of means, counts, or other transformations of existing variables. Suppose for example, we wished to convert the party affiliation of the members of congress into a dummy (indicator) variable. This may be useful to more easily compute a proportion or count for instance.&lt;/p&gt;
&lt;p&gt;This can be done with the &lt;code&gt;mutate&lt;/code&gt; function. Below, I’m first going to use &lt;code&gt;select&lt;/code&gt; to reduce the number of columns to make it easier to see the operation.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;congress_red &amp;lt;- select(congress_age, congress, chamber, state, party)

mutate(congress_red, 
       democrat = ifelse(party == &amp;#39;D&amp;#39;, 1, 0),
       num_democrat = sum(democrat)
       )&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 18,635 × 6
##    congress chamber state party democrat num_democrat
##       &amp;lt;int&amp;gt; &amp;lt;chr&amp;gt;   &amp;lt;chr&amp;gt; &amp;lt;chr&amp;gt;    &amp;lt;dbl&amp;gt;        &amp;lt;dbl&amp;gt;
##  1       80 house   TX    D            1        10290
##  2       80 house   NC    D            1        10290
##  3       80 house   IL    D            1        10290
##  4       80 house   NJ    R            0        10290
##  5       80 house   KY    R            0        10290
##  6       80 house   PA    R            0        10290
##  7       80 house   CA    R            0        10290
##  8       80 house   NY    D            1        10290
##  9       80 house   WI    R            0        10290
## 10       80 house   MA    R            0        10290
## # … with 18,625 more rows&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;You’ll notice that the number of rows in the data are the same (18635) as it was previously, but now the two new columns have been added to the data. One converted the party affiliation to a series of 0/1 values and the other variable counted up the number of democrats elected since the 80th congress. Notice how this last variable is simply repeated for all values in the data. The operation done here is not too exciting, however, we will learn another utility later that allows us to group the data to calculate different values for each group.&lt;/p&gt;
&lt;p&gt;Lastly, from the output above, notice that I was able to reference a variable that I created previously in the mutate command. This is unique to the &lt;code&gt;dplyr&lt;/code&gt; package and allows you to create a single &lt;code&gt;mutate&lt;/code&gt; command to add many variables, even those that depend on prior calculations. Obviously, if you need to reference a calculation in another calculation, they need to be done in the proper order.&lt;/p&gt;
&lt;div id=&#34;creation-functions&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Creation Functions&lt;/h3&gt;
&lt;p&gt;There are many useful operators to use when creating additional variables. The R for Data Science text has many examples shown in &lt;a href=&#34;http://r4ds.had.co.nz/transform.html&#34;&gt;section 5.5.1&lt;/a&gt;. In general useful operators include addition, subtraction, multiplication, division, descriptive statistics (we will talk more about these in week 4), ranks, logical comparisons, and many more. The exercises will have you explore some of these operations in more detail.&lt;/p&gt;
&lt;div id=&#34;exercises-2&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Exercises&lt;/h4&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;Using the &lt;code&gt;diamonds&lt;/code&gt; data, use &lt;code&gt;?diamonds&lt;/code&gt; for more information on the data, use the &lt;code&gt;mutate&lt;/code&gt; function to calculate the price per carat. Hint, this operation would involve standardizing the price variable so that all are comparable at 1 carat.&lt;/li&gt;
&lt;li&gt;Calculate the rank of the original price variable and the new price variable calculated above using the &lt;code&gt;min_rank&lt;/code&gt; function. Are there differences in the ranking of the prices? Hint, it may be useful to test if the two ranks are equal to explore this.&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;examples-with-summarise&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Examples with &lt;code&gt;summarise()&lt;/code&gt;&lt;/h2&gt;
&lt;p&gt;&lt;code&gt;summarise&lt;/code&gt; is very similar to the &lt;code&gt;mutate&lt;/code&gt; function, except instead of adding additional columns to the data, it collapses data down to a single row. For instance, doing the same operation as the example with &lt;code&gt;mutate&lt;/code&gt; above:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;congress_2 &amp;lt;- mutate(congress_age, 
       democrat = ifelse(party == &amp;#39;D&amp;#39;, 1, 0)
       )

summarise(congress_2, 
          num_democrat = sum(democrat)
          )&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 1 × 1
##   num_democrat
##          &amp;lt;dbl&amp;gt;
## 1        10290&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Notice now, instead of repeating the same value for all the rows as with &lt;code&gt;mutate&lt;/code&gt;, &lt;code&gt;summarise&lt;/code&gt; collapsed the data into a single numeric summary. Normally this is not a very interesting data activity, however, used in tandem with another function, &lt;code&gt;group_by&lt;/code&gt;, interesting summary statistics can be calculated.&lt;/p&gt;
&lt;p&gt;Suppose we were interested in calculating the number of democrats in each congress. This can be achieved with similar code to above, but first by grouping the data as follows:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;congress_grp &amp;lt;- group_by(congress_2, congress)

summarise(congress_grp, 
          num_democrat = sum(democrat),
          total = n(),
          prop_democrat = num_democrat / total
)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 34 × 4
##    congress num_democrat total prop_democrat
##       &amp;lt;int&amp;gt;        &amp;lt;dbl&amp;gt; &amp;lt;int&amp;gt;         &amp;lt;dbl&amp;gt;
##  1       80          247   555         0.445
##  2       81          330   557         0.592
##  3       82          292   555         0.526
##  4       83          274   557         0.492
##  5       84          288   544         0.529
##  6       85          295   547         0.539
##  7       86          356   554         0.643
##  8       87          339   559         0.606
##  9       88          332   552         0.601
## 10       89          371   548         0.677
## # … with 24 more rows&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Notice above, the use of the &lt;code&gt;group_by&lt;/code&gt; function to group the data first by congress. Then this new grouped data is passed to the &lt;code&gt;summarise&lt;/code&gt; command. As you can see from the output, the operations performed with the &lt;code&gt;summarise&lt;/code&gt; function are done for each unique level of the congress variable. You could now easily plot these to see the trend in proportion of democrats has changed over time.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(ggplot2)
num_dem &amp;lt;- summarise(congress_grp, 
                     num_democrat = sum(democrat),
                     total = n(),
                     prop_democrat = num_democrat / total
)
ggplot(num_dem, aes(x = congress, y = prop_democrat)) + 
  geom_line()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://psqf6250.brandonlebeau.org/rcode/data_munging_files/figure-html/trend-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;div id=&#34;exercises-3&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Exercises&lt;/h4&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;Suppose we wanted to calculate the number and proportion of republicans instead of democrats, assuming these are the only two parties, edit the &lt;code&gt;summarise&lt;/code&gt; command above to calculate these values.&lt;/li&gt;
&lt;li&gt;Suppose instead of using &lt;code&gt;sum(democrat)&lt;/code&gt; above, we used &lt;code&gt;mean(democrat)&lt;/code&gt;, what does this value return? Why does it return this value?&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;div id=&#34;extending-group_by-in-other-places&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Extending &lt;code&gt;group_by()&lt;/code&gt; in other places&lt;/h3&gt;
&lt;p&gt;The &lt;code&gt;group_by&lt;/code&gt; function is also useful with the &lt;code&gt;mutate&lt;/code&gt; function and works in a similar way as &lt;code&gt;summarise&lt;/code&gt; above. For example, if we wanted to keep the values calculated above in the original data, we could use &lt;code&gt;mutate&lt;/code&gt; instead of &lt;code&gt;summarise&lt;/code&gt;. This would look like the following:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;mutate(congress_grp, 
       num_democrat = sum(democrat),
       total = n(),
       prop_democrat = num_democrat / total
)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 18,635 × 17
## # Groups:   congress [34]
##    congress chamber bioguide firstname middlename lastname  suffix birthday  
##       &amp;lt;int&amp;gt; &amp;lt;chr&amp;gt;   &amp;lt;chr&amp;gt;    &amp;lt;chr&amp;gt;     &amp;lt;chr&amp;gt;      &amp;lt;chr&amp;gt;     &amp;lt;chr&amp;gt;  &amp;lt;date&amp;gt;    
##  1       80 house   M000112  Joseph    Jefferson  Mansfield &amp;lt;NA&amp;gt;   1861-02-09
##  2       80 house   D000448  Robert    Lee        Doughton  &amp;lt;NA&amp;gt;   1863-11-07
##  3       80 house   S000001  Adolph    Joachim    Sabath    &amp;lt;NA&amp;gt;   1866-04-04
##  4       80 house   E000023  Charles   Aubrey     Eaton     &amp;lt;NA&amp;gt;   1868-03-29
##  5       80 house   L000296  William   &amp;lt;NA&amp;gt;       Lewis     &amp;lt;NA&amp;gt;   1868-09-22
##  6       80 house   G000017  James     A.         Gallagher &amp;lt;NA&amp;gt;   1869-01-16
##  7       80 house   W000265  Richard   Joseph     Welch     &amp;lt;NA&amp;gt;   1869-02-13
##  8       80 house   B000565  Sol       &amp;lt;NA&amp;gt;       Bloom     &amp;lt;NA&amp;gt;   1870-03-09
##  9       80 house   H000943  Merlin    &amp;lt;NA&amp;gt;       Hull      &amp;lt;NA&amp;gt;   1870-12-18
## 10       80 house   G000169  Charles   Laceille   Gifford   &amp;lt;NA&amp;gt;   1871-03-15
## # … with 18,625 more rows, and 9 more variables: state &amp;lt;chr&amp;gt;, party &amp;lt;chr&amp;gt;,
## #   incumbent &amp;lt;lgl&amp;gt;, termstart &amp;lt;date&amp;gt;, age &amp;lt;dbl&amp;gt;, democrat &amp;lt;dbl&amp;gt;,
## #   num_democrat &amp;lt;dbl&amp;gt;, total &amp;lt;int&amp;gt;, prop_democrat &amp;lt;dbl&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;useful-summary-functions&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Useful summary functions&lt;/h3&gt;
&lt;p&gt;There are many useful summary functions, many of which we will explore in more detail in week 4 of the course during exploratory data analysis (EDA). However, I want to show a few here with the &lt;code&gt;summarise&lt;/code&gt; function to ease you in. Suppose for instance we were interested in the knowing the youngest and oldest member of congress for each congress. There are actually two ways of doing this, one is using the &lt;code&gt;min&lt;/code&gt; and &lt;code&gt;max&lt;/code&gt; functions on the grouped data.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;summarise(congress_grp,
          youngest = min(age),
          oldest = max(age)
)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 34 × 3
##    congress youngest oldest
##       &amp;lt;int&amp;gt;    &amp;lt;dbl&amp;gt;  &amp;lt;dbl&amp;gt;
##  1       80     25.9   85.9
##  2       81     27.2   85.2
##  3       82     27.9   87.2
##  4       83     26.7   85.3
##  5       84     28.5   87.3
##  6       85     30.5   89.3
##  7       86     31     91.3
##  8       87     28.9   86  
##  9       88     29     85.3
## 10       89     25     87.3
## # … with 24 more rows&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This could also be done by using the &lt;code&gt;first&lt;/code&gt; and &lt;code&gt;last&lt;/code&gt; functions after arranging the data:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;summarise(arrange(congress_grp, age),
          youngest = first(age),
          oldest = last(age)
)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 34 × 3
##    congress youngest oldest
##       &amp;lt;int&amp;gt;    &amp;lt;dbl&amp;gt;  &amp;lt;dbl&amp;gt;
##  1       80     25.9   85.9
##  2       81     27.2   85.2
##  3       82     27.9   87.2
##  4       83     26.7   85.3
##  5       84     28.5   87.3
##  6       85     30.5   89.3
##  7       86     31     91.3
##  8       87     28.9   86  
##  9       88     29     85.3
## 10       89     25     87.3
## # … with 24 more rows&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This goes to show that there are commonly many different ways to calculate descriptive statistics. I would argue two strong virtues when writing code is to make it as clear, expressive, and ensure accuracy. Speed and grace in writing code can come later.&lt;/p&gt;
&lt;div id=&#34;exercises-4&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Exercises&lt;/h4&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;For each congress, calculate a summary using the following command: &lt;code&gt;n_distinct(state)&lt;/code&gt;. What does this value return?&lt;/li&gt;
&lt;li&gt;What happens when you use a logical expression within a &lt;code&gt;sum&lt;/code&gt; function call? For example, what do you get in a summarise when you do: &lt;code&gt;sum(age &amp;gt; 75)&lt;/code&gt;?&lt;/li&gt;
&lt;li&gt;What happens when you try to use &lt;code&gt;sum&lt;/code&gt; or &lt;code&gt;mean&lt;/code&gt; on the variable incumbent?&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;chaining-together-multiple-operations&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Chaining together multiple operations&lt;/h2&gt;
&lt;p&gt;Now that you have seen all of the basic &lt;code&gt;dplyr&lt;/code&gt; data manipulation verbs, it is useful to chain these together to create more complex operations. So far, I have shown you how to do it by saving intermediate steps, for example, saving the grouped data after using the &lt;code&gt;group_by&lt;/code&gt; function. In many instances, these intermediate steps are not useful to us. In these cases you can chain operations together.&lt;/p&gt;
&lt;p&gt;Suppose we are interested in calculating the proportion of democrats for each chamber of congress, but only since the 100th congress? There are two ways to do this, the difficult to read and the easier to read. I first shown the difficult to read.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;summarise(
  group_by(
    mutate(
      filter(
        congress_age, congress &amp;gt;= 100
      ), 
      democrat = ifelse(party == &amp;#39;D&amp;#39;, 1, 0)
    ),
    congress, chamber
  ),
  num_democrat = sum(democrat),
  total = n(),
  prop_democrat = num_democrat / total
)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## `summarise()` has grouped output by &amp;#39;congress&amp;#39;. You can override using the
## `.groups` argument.&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 28 × 5
## # Groups:   congress [14]
##    congress chamber num_democrat total prop_democrat
##       &amp;lt;int&amp;gt; &amp;lt;chr&amp;gt;          &amp;lt;dbl&amp;gt; &amp;lt;int&amp;gt;         &amp;lt;dbl&amp;gt;
##  1      100 house            263   443         0.594
##  2      100 senate            55   101         0.545
##  3      101 house            266   445         0.598
##  4      101 senate            56   101         0.554
##  5      102 house            272   443         0.614
##  6      102 senate            59   104         0.567
##  7      103 house            261   443         0.589
##  8      103 senate            58   105         0.552
##  9      104 house            206   441         0.467
## 10      104 senate            47   103         0.456
## # … with 18 more rows&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;How difficult do you find the code above to read? This is valid R code, but the first operation done is nested in the middle (it is the &lt;code&gt;filter&lt;/code&gt; function that is run first). This makes for difficult code to debug and write in my opinion. In my opinion, the better way to write code is through the pipe operator, &lt;code&gt;%&amp;gt;%&lt;/code&gt;. The same code above can be achieved with the following much easier to read code:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;congress_age %&amp;gt;%
  filter(congress &amp;gt;= 100) %&amp;gt;%
  mutate(democrat = ifelse(party == &amp;#39;D&amp;#39;, 1, 0)) %&amp;gt;%
  group_by(congress, chamber) %&amp;gt;%
  summarise(
    num_democrat = sum(democrat),
    total = n(),
    prop_democrat = num_democrat / total
  )&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## `summarise()` has grouped output by &amp;#39;congress&amp;#39;. You can override using the
## `.groups` argument.&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 28 × 5
## # Groups:   congress [14]
##    congress chamber num_democrat total prop_democrat
##       &amp;lt;int&amp;gt; &amp;lt;chr&amp;gt;          &amp;lt;dbl&amp;gt; &amp;lt;int&amp;gt;         &amp;lt;dbl&amp;gt;
##  1      100 house            263   443         0.594
##  2      100 senate            55   101         0.545
##  3      101 house            266   445         0.598
##  4      101 senate            56   101         0.554
##  5      102 house            272   443         0.614
##  6      102 senate            59   104         0.567
##  7      103 house            261   443         0.589
##  8      103 senate            58   105         0.552
##  9      104 house            206   441         0.467
## 10      104 senate            47   103         0.456
## # … with 18 more rows&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The pipe allows for more readable code by humans and progresses from top to bottom, left to right. The best word to substitute when translating the &lt;code&gt;%&amp;gt;%&lt;/code&gt; code above is ‘then’. So the code above says, using the &lt;code&gt;congress_age&lt;/code&gt; data, then &lt;code&gt;filter&lt;/code&gt;, then &lt;code&gt;mutate&lt;/code&gt;, then &lt;code&gt;group_by&lt;/code&gt;, then &lt;code&gt;summarise&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;This is much easier to read and follow the chain of commands. I highly recommend using the pipe in your code. For more details on what is actually happening, the R for Data Science book has a good explanation in Section 5.6.1.&lt;/p&gt;
&lt;div id=&#34;exercises-5&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Exercises&lt;/h4&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;Look at the following nested code and determine what is being done. Then translate this code to use the pipe operator.&lt;/li&gt;
&lt;/ol&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;summarise(
  group_by(
    mutate(
      filter(
        diamonds, 
        color %in% c(&amp;#39;D&amp;#39;, &amp;#39;E&amp;#39;, &amp;#39;F&amp;#39;) &amp;amp; cut %in% c(&amp;#39;Fair&amp;#39;, &amp;#39;Good&amp;#39;, &amp;#39;Very Good&amp;#39;)
      ),
      f_color = ifelse(color == &amp;#39;F&amp;#39;, 1, 0),
      vg_cut = ifelse(cut == &amp;#39;Very Good&amp;#39;, 1, 0)
    ),
    clarity
  ),
  avg = mean(carat),
  sd = sd(carat),
  avg_p = mean(price),
  num = n(),
  summary_f_color = mean(f_color),
  summary_vg_cut = mean(vg_cut)
)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>R Scripts</title>
      <link>https://psqf6250.brandonlebeau.org/rcode/r_scripts/</link>
      <pubDate>Mon, 08 Feb 2021 00:00:00 +0000</pubDate>
      <guid>https://psqf6250.brandonlebeau.org/rcode/r_scripts/</guid>
      <description>
&lt;script src=&#34;https://psqf6250.brandonlebeau.org/rmarkdown-libs/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;

&lt;div id=&#34;TOC&#34;&gt;

&lt;/div&gt;

&lt;p&gt;I want to talk very briefly about R scripts. You may have been using these already within your workflow for this course, but these are best practice instead of simply running code in the console. Creating R scripts are a crucial step to ensure the data analyses are reproducible, the script will act as a log of all the things that are done to the data to go from data import to any outputs (model results, tables, figures, etc.).&lt;/p&gt;
&lt;p&gt;To create an R script with RStudio, the short cut is CTRL/CMD + SHIFT + N. You can also create a new script by going to File &amp;gt; New File &amp;gt; R Script. Both of these commands will open up a blank script window.&lt;/p&gt;
&lt;p&gt;In this script window, I would recommend loading any R packages first at the top of the file. Then proceed with the analysis. Commands can be sent to the console using CRTL/CMD + ENTER. By default RStudio will run any commands that span more than one line with a single CRTL/CMD + ENTER call.&lt;/p&gt;
&lt;p&gt;For more details about R Scripts, the R for Data Science text has detail with screenshots in &lt;a href=&#34;http://r4ds.had.co.nz/workflow-scripts.html&#34;&gt;Chapter 6&lt;/a&gt;. I recommend trying to create a simple script and sending these commands from the script to the console to be run with R.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Exploratory Data Analysis</title>
      <link>https://psqf6250.brandonlebeau.org/rcode/eda/</link>
      <pubDate>Mon, 15 Feb 2021 00:00:00 +0000</pubDate>
      <guid>https://psqf6250.brandonlebeau.org/rcode/eda/</guid>
      <description>
&lt;script src=&#34;https://psqf6250.brandonlebeau.org/rmarkdown-libs/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;

&lt;div id=&#34;TOC&#34;&gt;

&lt;/div&gt;

&lt;p&gt;Exploratory data analysis (EDA) is an important step in exploring and understanding your data. In addition, EDA does not suffer from problems with inferential statistics related to multiple (correlated) models on the same data. Instead, EDA is a great way to visualize, summarize, and prod your data without any consequences.&lt;/p&gt;
&lt;p&gt;For this set of notes, we are going to use the following packages:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(nycflights13)
library(tidyverse)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We will use a few different data sets, but the one we are going to start with is the &lt;code&gt;flights&lt;/code&gt; data from the &lt;code&gt;nycflights13&lt;/code&gt; package. Below is the first 10 rows of the data.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;flights&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 336,776 × 19
##     year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time
##    &amp;lt;int&amp;gt; &amp;lt;int&amp;gt; &amp;lt;int&amp;gt;    &amp;lt;int&amp;gt;          &amp;lt;int&amp;gt;     &amp;lt;dbl&amp;gt;    &amp;lt;int&amp;gt;          &amp;lt;int&amp;gt;
##  1  2013     1     1      517            515         2      830            819
##  2  2013     1     1      533            529         4      850            830
##  3  2013     1     1      542            540         2      923            850
##  4  2013     1     1      544            545        -1     1004           1022
##  5  2013     1     1      554            600        -6      812            837
##  6  2013     1     1      554            558        -4      740            728
##  7  2013     1     1      555            600        -5      913            854
##  8  2013     1     1      557            600        -3      709            723
##  9  2013     1     1      557            600        -3      838            846
## 10  2013     1     1      558            600        -2      753            745
## # … with 336,766 more rows, and 11 more variables: arr_delay &amp;lt;dbl&amp;gt;,
## #   carrier &amp;lt;chr&amp;gt;, flight &amp;lt;int&amp;gt;, tailnum &amp;lt;chr&amp;gt;, origin &amp;lt;chr&amp;gt;, dest &amp;lt;chr&amp;gt;,
## #   air_time &amp;lt;dbl&amp;gt;, distance &amp;lt;dbl&amp;gt;, hour &amp;lt;dbl&amp;gt;, minute &amp;lt;dbl&amp;gt;, time_hour &amp;lt;dttm&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This data contains information on all flights that departed from the three airports in NYC in 2013. As you can see, the data has a total of 336776 rows and 19. For additional information use &lt;code&gt;?flights&lt;/code&gt;.&lt;/p&gt;
&lt;div id=&#34;exploratory-data-analysis&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Exploratory Data Analysis&lt;/h2&gt;
&lt;p&gt;The general process for proceeding with exploratory data analysis as summarized in the R for Data Science text are:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;Ask questions about your data&lt;/li&gt;
&lt;li&gt;Search for answers&lt;/li&gt;
&lt;li&gt;Refine or ask new questions about the data.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;There are no bad questions when performing EDA, but some common questions worth exploring are:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Missing Data&lt;/li&gt;
&lt;li&gt;Variation&lt;/li&gt;
&lt;li&gt;Covariation&lt;/li&gt;
&lt;li&gt;Rare cases&lt;/li&gt;
&lt;li&gt;Common cases&lt;/li&gt;
&lt;li&gt;Distributions&lt;/li&gt;
&lt;/ul&gt;
&lt;div id=&#34;missing-data&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Missing Data&lt;/h3&gt;
&lt;p&gt;A first step in exploring the data is to explore if there are any missing data present in the data (likely). This is not an easy step, but determining the amount of missing data and, if possible, why these values are missing are important first steps. One quick way to get a view of this information for the entire data is to use the &lt;code&gt;summary&lt;/code&gt; command. An example is given with the &lt;code&gt;flights&lt;/code&gt; data below.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;summary(flights)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##       year          month             day           dep_time    sched_dep_time
##  Min.   :2013   Min.   : 1.000   Min.   : 1.00   Min.   :   1   Min.   : 106  
##  1st Qu.:2013   1st Qu.: 4.000   1st Qu.: 8.00   1st Qu.: 907   1st Qu.: 906  
##  Median :2013   Median : 7.000   Median :16.00   Median :1401   Median :1359  
##  Mean   :2013   Mean   : 6.549   Mean   :15.71   Mean   :1349   Mean   :1344  
##  3rd Qu.:2013   3rd Qu.:10.000   3rd Qu.:23.00   3rd Qu.:1744   3rd Qu.:1729  
##  Max.   :2013   Max.   :12.000   Max.   :31.00   Max.   :2400   Max.   :2359  
##                                                  NA&amp;#39;s   :8255                 
##    dep_delay          arr_time    sched_arr_time   arr_delay       
##  Min.   : -43.00   Min.   :   1   Min.   :   1   Min.   : -86.000  
##  1st Qu.:  -5.00   1st Qu.:1104   1st Qu.:1124   1st Qu.: -17.000  
##  Median :  -2.00   Median :1535   Median :1556   Median :  -5.000  
##  Mean   :  12.64   Mean   :1502   Mean   :1536   Mean   :   6.895  
##  3rd Qu.:  11.00   3rd Qu.:1940   3rd Qu.:1945   3rd Qu.:  14.000  
##  Max.   :1301.00   Max.   :2400   Max.   :2359   Max.   :1272.000  
##  NA&amp;#39;s   :8255      NA&amp;#39;s   :8713                  NA&amp;#39;s   :9430      
##    carrier              flight       tailnum             origin         
##  Length:336776      Min.   :   1   Length:336776      Length:336776     
##  Class :character   1st Qu.: 553   Class :character   Class :character  
##  Mode  :character   Median :1496   Mode  :character   Mode  :character  
##                     Mean   :1972                                        
##                     3rd Qu.:3465                                        
##                     Max.   :8500                                        
##                                                                         
##      dest              air_time        distance         hour      
##  Length:336776      Min.   : 20.0   Min.   :  17   Min.   : 1.00  
##  Class :character   1st Qu.: 82.0   1st Qu.: 502   1st Qu.: 9.00  
##  Mode  :character   Median :129.0   Median : 872   Median :13.00  
##                     Mean   :150.7   Mean   :1040   Mean   :13.18  
##                     3rd Qu.:192.0   3rd Qu.:1389   3rd Qu.:17.00  
##                     Max.   :695.0   Max.   :4983   Max.   :23.00  
##                     NA&amp;#39;s   :9430                                  
##      minute        time_hour                  
##  Min.   : 0.00   Min.   :2013-01-01 05:00:00  
##  1st Qu.: 8.00   1st Qu.:2013-04-04 13:00:00  
##  Median :29.00   Median :2013-07-03 10:00:00  
##  Mean   :26.23   Mean   :2013-07-03 05:22:54  
##  3rd Qu.:44.00   3rd Qu.:2013-10-01 07:00:00  
##  Max.   :59.00   Max.   :2013-12-31 23:00:00  
## &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This summary can be a bit difficult to digest at first, but can give some useful insight into the variables, including the amount of missing data for each variable.&lt;/p&gt;
&lt;p&gt;You can dive into looking at specific rows that are missing with the &lt;code&gt;filter&lt;/code&gt; command and the &lt;code&gt;is.na&lt;/code&gt; function. An example pulling out rows with a missing dep_time values is illustrated:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;filter(flights, is.na(dep_time))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 8,255 × 19
##     year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time
##    &amp;lt;int&amp;gt; &amp;lt;int&amp;gt; &amp;lt;int&amp;gt;    &amp;lt;int&amp;gt;          &amp;lt;int&amp;gt;     &amp;lt;dbl&amp;gt;    &amp;lt;int&amp;gt;          &amp;lt;int&amp;gt;
##  1  2013     1     1       NA           1630        NA       NA           1815
##  2  2013     1     1       NA           1935        NA       NA           2240
##  3  2013     1     1       NA           1500        NA       NA           1825
##  4  2013     1     1       NA            600        NA       NA            901
##  5  2013     1     2       NA           1540        NA       NA           1747
##  6  2013     1     2       NA           1620        NA       NA           1746
##  7  2013     1     2       NA           1355        NA       NA           1459
##  8  2013     1     2       NA           1420        NA       NA           1644
##  9  2013     1     2       NA           1321        NA       NA           1536
## 10  2013     1     2       NA           1545        NA       NA           1910
## # … with 8,245 more rows, and 11 more variables: arr_delay &amp;lt;dbl&amp;gt;,
## #   carrier &amp;lt;chr&amp;gt;, flight &amp;lt;int&amp;gt;, tailnum &amp;lt;chr&amp;gt;, origin &amp;lt;chr&amp;gt;, dest &amp;lt;chr&amp;gt;,
## #   air_time &amp;lt;dbl&amp;gt;, distance &amp;lt;dbl&amp;gt;, hour &amp;lt;dbl&amp;gt;, minute &amp;lt;dbl&amp;gt;, time_hour &amp;lt;dttm&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We can also build more complex operations to look at data that is missing for one variable, but not another. For instance, if you look at the summary information above, you may notice there are more missing values for the arr_delay variable compared to the arr_time variable. To look at these values you can use the following command:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;filter(flights, is.na(arr_delay) &amp;amp; !is.na(arr_time))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 717 × 19
##     year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time
##    &amp;lt;int&amp;gt; &amp;lt;int&amp;gt; &amp;lt;int&amp;gt;    &amp;lt;int&amp;gt;          &amp;lt;int&amp;gt;     &amp;lt;dbl&amp;gt;    &amp;lt;int&amp;gt;          &amp;lt;int&amp;gt;
##  1  2013     1     1     1525           1530        -5     1934           1805
##  2  2013     1     1     1528           1459        29     2002           1647
##  3  2013     1     1     1740           1745        -5     2158           2020
##  4  2013     1     1     1807           1738        29     2251           2103
##  5  2013     1     1     1939           1840        59       29           2151
##  6  2013     1     1     1952           1930        22     2358           2207
##  7  2013     1     2      905            822        43     1313           1045
##  8  2013     1     2     1125            925       120     1445           1146
##  9  2013     1     2     1848           1840         8     2333           2151
## 10  2013     1     2     1849           1724        85     2235           1938
## # … with 707 more rows, and 11 more variables: arr_delay &amp;lt;dbl&amp;gt;, carrier &amp;lt;chr&amp;gt;,
## #   flight &amp;lt;int&amp;gt;, tailnum &amp;lt;chr&amp;gt;, origin &amp;lt;chr&amp;gt;, dest &amp;lt;chr&amp;gt;, air_time &amp;lt;dbl&amp;gt;,
## #   distance &amp;lt;dbl&amp;gt;, hour &amp;lt;dbl&amp;gt;, minute &amp;lt;dbl&amp;gt;, time_hour &amp;lt;dttm&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This may actually be a data error, as there is an arr_time value, a scheduled_arr_time value, but no arr_delay value. This could then be calculated manually to reduce the number of missing values with this variable.&lt;/p&gt;
&lt;div id=&#34;viewing-missing-data-graphically&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Viewing missing data graphically&lt;/h4&gt;
&lt;p&gt;It may be useful to view missing data graphically. This may be useful to see if there are specific trends in the data in relation to the missing values. A few ways to plot these data may be useful.&lt;/p&gt;
&lt;p&gt;First, it is always a good rule to explore missing data in relation to other variables in the data. If there is evidence that another variable is influencing whether a value is missing, additional statistical controls are needed to adjust for these concerns.&lt;/p&gt;
&lt;p&gt;For example, we could explore if the scheduled arrival time is related to whether the actual arrival flight time is missing.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;flights %&amp;gt;%
  mutate(
    miss_arrival = is.na(arr_time)
  ) %&amp;gt;%
  ggplot(mapping = aes(sched_arr_time)) + 
  geom_freqpoly(aes(color = miss_arrival)) + 
  theme_bw()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://psqf6250.brandonlebeau.org/rcode/eda_files/figure-html/arrival_missing-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Notice that the count metric masks much of what is being visualized here as there are many more flights that arrived compared to those with missing times. To adjust this, we simply need to change the y-axis from counts to density.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;flights %&amp;gt;%
  mutate(
    miss_arrival = is.na(arr_time)
  ) %&amp;gt;%
  ggplot(mapping = aes(x = sched_arr_time, y = ..density..)) + 
  geom_freqpoly(aes(color = miss_arrival)) +
  theme_bw()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://psqf6250.brandonlebeau.org/rcode/eda_files/figure-html/miss_density-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;The two curves are now standardized so that the area under each curve equals 1, which in turn makes comparison between the two groups easier.&lt;/p&gt;
&lt;p&gt;One other special note, for EDA internally, there is no need to spend much time worrying about formatting of the graphics. However, if this plot above would be included in a report or manuscript, this figure would need additional polish to be included.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;variation&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Variation&lt;/h3&gt;
&lt;p&gt;Another common EDA question is related to variation. Variation is important for statistics, without variation there is no need to do statistics. The best way to explore variation of any type of variable is through visulization. This section will be broken into two sub areas, one that explores qualitative and another that explores quantitative.&lt;/p&gt;
&lt;div id=&#34;qualitative-variables&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Qualitative Variables&lt;/h4&gt;
&lt;p&gt;Bar graphs (frequency tables) are commonly used to explore variation in qualitative variables. For example, if we wished to explore the number of flights that took off for each month of the year from NYC:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(flights, aes(factor(month))) + 
  geom_bar() + 
  theme_bw()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://psqf6250.brandonlebeau.org/rcode/eda_files/figure-html/count_flights-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;One special note about the above code, I used the &lt;code&gt;factor()&lt;/code&gt; function so that ggplot specifically added all the values of the variable to the x-axis. By default since the month variable is being treated as an integer (a number), it would not show all the values for month.&lt;/p&gt;
&lt;p&gt;These counts could be calculated manually with the use of dplyr using the &lt;code&gt;count&lt;/code&gt; function. The &lt;code&gt;count&lt;/code&gt; function basically creates a frequency table. More complex tables can be created by passing additional variables to the &lt;code&gt;count&lt;/code&gt; function.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;flights %&amp;gt;%
  count(month)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 12 × 2
##    month     n
##    &amp;lt;int&amp;gt; &amp;lt;int&amp;gt;
##  1     1 27004
##  2     2 24951
##  3     3 28834
##  4     4 28330
##  5     5 28796
##  6     6 28243
##  7     7 29425
##  8     8 29327
##  9     9 27574
## 10    10 28889
## 11    11 27268
## 12    12 28135&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;exercises&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Exercises&lt;/h4&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;Copy the code from the bar graph above, but instead of wrapping the month variable in factor, try it without it. What is different? Extra, using the &lt;code&gt;scale_x_continuous&lt;/code&gt; function, can you manually add each of the 12 numeric month values to the plot?&lt;/li&gt;
&lt;li&gt;Using dplyr, manually calculate the number of flights that took off for every day of every month. In other words, how many flights took off everyday of the year. Which day had the most flights?&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;div id=&#34;quantitative-variables&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Quantitative Variables&lt;/h4&gt;
&lt;p&gt;Histrograms, frequency polygons, or density curves are three common options to explore variation with quantitative variables. Within the flights data, suppose we were interested in exploring the variation in the distance traveled, this could easily be done with a histrogram.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(flights, aes(distance)) + 
  geom_histogram() + 
  theme_bw()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://psqf6250.brandonlebeau.org/rcode/eda_files/figure-html/distance_hist-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;We could also use a frequency polygon:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(flights, aes(distance)) + 
  geom_freqpoly() + 
  theme_bw()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://psqf6250.brandonlebeau.org/rcode/eda_files/figure-html/distance_freqpoly-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;We could also use a density curve:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(flights, aes(distance)) + 
  geom_density() + 
  theme_bw()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://psqf6250.brandonlebeau.org/rcode/eda_files/figure-html/distance_density-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;When exploring the variation for a single variable overall, I tend to use histograms. However, when attempting to see if the variation changes across values of a categorical variable, histograms are difficult as the groups likely overlap. These are instances when using the frequency polygon or density curves are useful. Here are examples of both when exploring variation differences by month.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(flights, aes(distance)) + 
  geom_freqpoly(aes(color = factor(month))) + 
  theme_bw()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://psqf6250.brandonlebeau.org/rcode/eda_files/figure-html/distance_month-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(flights, aes(distance)) + 
  geom_density(aes(color = factor(month))) + 
  theme_bw()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://psqf6250.brandonlebeau.org/rcode/eda_files/figure-html/distance_month-2.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;You can also calculate the counts plotted in the histograms and frequency polygons using the &lt;code&gt;count&lt;/code&gt; as with qualitative variables. We just now need to use the &lt;code&gt;cut_width&lt;/code&gt; function to specify bins.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;flights %&amp;gt;%
  count(cut_width(distance, 100))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 28 × 2
##    `cut_width(distance, 100)`     n
##    &amp;lt;fct&amp;gt;                      &amp;lt;int&amp;gt;
##  1 [-50,50]                       1
##  2 (50,150]                    2514
##  3 (150,250]                  36839
##  4 (250,350]                  18442
##  5 (350,450]                  15233
##  6 (450,550]                  29149
##  7 (550,650]                  11688
##  8 (650,750]                  33482
##  9 (750,850]                  19482
## 10 (850,950]                  19644
## # … with 18 more rows&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Note, these counts may differ from above as the binwidth was not specifically stated when creating the histrogram or frequency polygon.&lt;/p&gt;
&lt;p&gt;It may also be useful to calculate the variance, standard deviation, or the range. These can be calculated using the &lt;code&gt;summarize&lt;/code&gt; function.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;flights %&amp;gt;%
  summarize(
    var_dist = var(distance, na.rm = TRUE),
    sd_dist = sd(distance, na.rm = TRUE),
    min_dist = min(distance, na.rm = TRUE),
    max_dist = max(distance, na.rm = TRUE)
  )&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 1 × 4
##   var_dist sd_dist min_dist max_dist
##      &amp;lt;dbl&amp;gt;   &amp;lt;dbl&amp;gt;    &amp;lt;dbl&amp;gt;    &amp;lt;dbl&amp;gt;
## 1  537631.    733.       17     4983&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;You could pair this with the &lt;code&gt;group_by&lt;/code&gt; function to calculate these values for different groups (e.g. by month).&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;exercises-1&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Exercises&lt;/h4&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;Explore variation in the air_time variable.&lt;/li&gt;
&lt;li&gt;Does the variation in the air_time variable differ by month?&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;distributions&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Distributions&lt;/h3&gt;
&lt;p&gt;Exploring distributions for variables is a very similar process to exploring the variation, the question is just different. Most often we are interested in exploring if the shape of the distribution is approximately normal. This will become more interesting when we start fitting models to explore potential assumption violations in the residuals. We leave these discussions until then.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;covariation&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Covariation&lt;/h3&gt;
&lt;p&gt;Covariation is the process of comparing how two (or more) variables are related. The most common method for exploring covariation is through scatterplots. However, these are most natural for two continuous variables. Other plots are useful for a mixture of variable types or for two qualitative variables. We will explore each in turn.&lt;/p&gt;
&lt;div id=&#34;two-qualitative-variables&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Two Qualitative Variables&lt;/h4&gt;
&lt;p&gt;Covariation in two qualitative variables is more difficult to view visually due to the restricted possible values in each variable. Suppose for example, we wished to explore covariation in the origin of the flight and the carrier.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(flights, aes(origin, carrier)) + 
  geom_count()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://psqf6250.brandonlebeau.org/rcode/eda_files/figure-html/carrier_origin-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;This plot is okay, however, I think a more useful plot is to use a tile plot to explore these differences with color.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;flights %&amp;gt;%
  count(origin, carrier) %&amp;gt;%
  ggplot(aes(origin, carrier)) + 
  geom_tile(aes(fill = n)) + 
  theme_bw()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://psqf6250.brandonlebeau.org/rcode/eda_files/figure-html/origin_carrier_tile-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Note, that holes mean missing values (i.e. no flights from that airport from that carrier).&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;exercises-2&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Exercises&lt;/h4&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;Explore the covariation between the month and day variables. Note, these are treated as continuous in the data, but in reality they are likely best represented as qualitative.&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;div id=&#34;two-quantitative-variables&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Two Quantitative Variables&lt;/h4&gt;
&lt;p&gt;Scatterplots are useful for two quantitative variables. Suppose for example that we wish to explore the relationship between the air_time variable and the arr_delay variable. This could be done with a scatterplot.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(flights, aes(air_time, arr_delay)) + 
  geom_point() + 
  theme_bw()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning: Removed 9430 rows containing missing values (geom_point).&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://psqf6250.brandonlebeau.org/rcode/eda_files/figure-html/quant_cov-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;One problem with the plot above, is overplotting. There are two fixes for this, one is to use transparent points using the &lt;code&gt;alpha&lt;/code&gt; argument to the &lt;code&gt;geom_point&lt;/code&gt; function.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(flights, aes(air_time, arr_delay)) + 
  geom_point(alpha = .05) + 
  theme_bw()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning: Removed 9430 rows containing missing values (geom_point).&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://psqf6250.brandonlebeau.org/rcode/eda_files/figure-html/transparency-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Another approach that will simplify the exploration is to use boxplots. This will involve grouping the air_time variable into “bins.”&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(flights, aes(x = air_time, y = arr_delay)) + 
  geom_boxplot(aes(group = cut_width(air_time, 50))) + 
  theme_bw()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning: Removed 9430 rows containing missing values (stat_boxplot).&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://psqf6250.brandonlebeau.org/rcode/eda_files/figure-html/boxplot_twoquant-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Even another more sophisticated graphic is to do the quantitative alternative to &lt;code&gt;geom_tile&lt;/code&gt;. Note, the code below uses the hexbin package, but a similar function is &lt;code&gt;geom_bin2d&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# install.packages(&amp;quot;hexbin&amp;quot;)
library(hexbin)
ggplot(flights, aes(x = air_time, y = arr_delay)) + 
  geom_hex()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning: Removed 9430 rows containing non-finite values (stat_binhex).&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://psqf6250.brandonlebeau.org/rcode/eda_files/figure-html/hex_twoquant-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;adding-a-third-variable&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Adding a Third Variable&lt;/h4&gt;
&lt;p&gt;Adding a third variable is often useful, but can be difficult to think about procedurally. The type of plot that is useful depends on the type the third variable is. For example, if the third variable is also quantitative, the visualization is more difficult, however, if the third variable is qualitative, there are two main options. These will be explored in more detail below.&lt;/p&gt;
&lt;p&gt;The main two approaches for adding a third variable when it is qualitative is to use a different color/shape for the values of this variable or to facet the plot. Suppose we wished to explore the covariation between the following three variables: air_time, arr_delay, and origin. The two different options are shown below.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(flights, aes(air_time, arr_delay)) + 
  geom_hex() + 
  facet_grid(. ~ origin) + 
  theme_bw()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning: Removed 9430 rows containing non-finite values (stat_binhex).&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://psqf6250.brandonlebeau.org/rcode/eda_files/figure-html/three_vars-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(flights, aes(air_time, arr_delay)) + 
  geom_point(aes(color = origin), alpha = .05) + 
  theme_bw()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning: Removed 9430 rows containing missing values (geom_point).&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://psqf6250.brandonlebeau.org/rcode/eda_files/figure-html/three_vars-2.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Plotting three quantitative variables commonly involves binning one one the variables to turn it into an ordinal variable with different levels. For example, see the example with two variables and the boxplot, a similar approach could be used to facet by this third variable. Below is a simple example:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(flights, aes(x = air_time, y = arr_delay)) + 
  geom_hex() + 
  theme_bw() + 
  facet_wrap(~ cut_width(dep_time, 250))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning: Removed 9430 rows containing non-finite values (stat_binhex).&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://psqf6250.brandonlebeau.org/rcode/eda_files/figure-html/three_quant-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;one-quantitative-one-qualitative&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;One Quantitative, One Qualitative&lt;/h4&gt;
&lt;p&gt;This was actually already discussed in the discussion of variation by exploring differences in variation for different levels of a qualitative variable (see above). If the variation differs by groups, there is then evidence of covariation.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;correlations&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Correlations&lt;/h4&gt;
&lt;p&gt;It is also useful to calculate and visualize raw correlations. To calculate raw correlations (assuming only quantitative variables), the &lt;code&gt;cor&lt;/code&gt; function is useful.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;flights %&amp;gt;%
  select(air_time, arr_delay, dep_time) %&amp;gt;%
  cor(use = &amp;#39;pairwise.complete.obs&amp;#39;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##              air_time   arr_delay    dep_time
## air_time   1.00000000 -0.03529709 -0.01461948
## arr_delay -0.03529709  1.00000000  0.23230573
## dep_time  -0.01461948  0.23230573  1.00000000&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;To visualize a correlation matrix, the GGally package is useful. Note, the &lt;code&gt;ggpairs&lt;/code&gt; function can take some time to run.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# install.package(&amp;quot;GGally&amp;quot;)
library(GGally)
flights %&amp;gt;%
  select(air_time, arr_delay, dep_time) %&amp;gt;%
  na.omit() %&amp;gt;%
  sample_n(1000) %&amp;gt;%
  ggpairs()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://psqf6250.brandonlebeau.org/rcode/eda_files/figure-html/ggally-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;exercises-3&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Exercises&lt;/h4&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;Explore covariation in the dep_delay and arr_delay variables. What type of relationship, if any, appears to be present?&lt;/li&gt;
&lt;li&gt;Explore the relationship between dep_delay, arr_delay, and origin. What type of relationship is present. Does the relationship between dep_delay and arr_delay differ by origin?&lt;/li&gt;
&lt;li&gt;Finally, calculate the correlation matrix for dep_delay, arr_delay, and dep_time.&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;rarecommon-cases&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Rare/Common Cases&lt;/h3&gt;
&lt;p&gt;The last question of use to explore when performing EDA is looking for the presence of rare or common cases. In other words, an exploration of any outliers and the central tendency of the distribution.&lt;/p&gt;
&lt;p&gt;When we explored variation in the distance variable earlier, there may have been extreme values we’d want to explore in more detail.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(flights, aes(distance)) + 
  geom_histogram() +
  theme_bw()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://psqf6250.brandonlebeau.org/rcode/eda_files/figure-html/distance_extreme-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Notice the large distance value, to get a better view of how many there are here, we can use &lt;code&gt;coord_cartesian&lt;/code&gt; to zoom in.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(flights, aes(distance)) + 
  geom_histogram() + 
  theme_bw() + 
  coord_cartesian(ylim = c(0, 5000))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://psqf6250.brandonlebeau.org/rcode/eda_files/figure-html/distance_coord-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Note, that in the above plot, &lt;code&gt;coord_cartesian&lt;/code&gt; does not remove any points, simply changes the coordinates that are plotted. We could also pull these out using filter as well.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;flights %&amp;gt;%
  filter(distance &amp;gt; 3000) %&amp;gt;%
  arrange(distance)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 715 × 19
##     year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time
##    &amp;lt;int&amp;gt; &amp;lt;int&amp;gt; &amp;lt;int&amp;gt;    &amp;lt;int&amp;gt;          &amp;lt;int&amp;gt;     &amp;lt;dbl&amp;gt;    &amp;lt;int&amp;gt;          &amp;lt;int&amp;gt;
##  1  2013     7     6     1629           1615        14     1954           1953
##  2  2013     7    13     1618           1615         3     1955           1953
##  3  2013     7    20     1618           1615         3     2003           1953
##  4  2013     7    27     1617           1615         2     1906           1953
##  5  2013     8     3     1615           1615         0     2003           1953
##  6  2013     8    10     1613           1615        -2     1922           1953
##  7  2013     8    17     1740           1625        75     2042           2003
##  8  2013     8    24     1633           1625         8     1959           2003
##  9  2013     1     1     1344           1344         0     2005           1944
## 10  2013     1     2     1344           1344         0     1940           1944
## # … with 705 more rows, and 11 more variables: arr_delay &amp;lt;dbl&amp;gt;, carrier &amp;lt;chr&amp;gt;,
## #   flight &amp;lt;int&amp;gt;, tailnum &amp;lt;chr&amp;gt;, origin &amp;lt;chr&amp;gt;, dest &amp;lt;chr&amp;gt;, air_time &amp;lt;dbl&amp;gt;,
## #   distance &amp;lt;dbl&amp;gt;, hour &amp;lt;dbl&amp;gt;, minute &amp;lt;dbl&amp;gt;, time_hour &amp;lt;dttm&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;div id=&#34;measures-of-central-tendency&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Measures of Central Tendency&lt;/h4&gt;
&lt;p&gt;Exploring measures of central tendency or simply common values/repeated of common values can also be important.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(flights, aes(arr_time)) +
  geom_histogram(binwidth = 50) +
  theme_bw()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning: Removed 8713 rows containing non-finite values (stat_bin).&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://psqf6250.brandonlebeau.org/rcode/eda_files/figure-html/common_values-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Measures of central tendency can be directly calculated using the &lt;code&gt;summarise&lt;/code&gt; function. For example, exploring central tendency of the arr_delay variable.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;flights %&amp;gt;%
  summarise(
    avg_arrdelay = mean(arr_delay, na.rm = TRUE),
    med_arrdelay = median(arr_delay, na.rm = TRUE)
  )&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 1 × 2
##   avg_arrdelay med_arrdelay
##          &amp;lt;dbl&amp;gt;        &amp;lt;dbl&amp;gt;
## 1         6.90           -5&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;More interesting computations can be performed by using adding in the &lt;code&gt;group_by&lt;/code&gt; function.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;exercises-4&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Exercises&lt;/h4&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;Using the &lt;code&gt;txhousing&lt;/code&gt; data, explore rare/common cases in the median sale price for the following 3 cities: Austin, Dallas, and Houston.&lt;/li&gt;
&lt;li&gt;Using the data from #1, explore measures of central tendency in the median sale price of these three cities. How have these changed over time (year)?&lt;/li&gt;
&lt;li&gt;Create an effective visualization that explores differences in the median sale price over time for these three cities.&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>R Projects -  RStudio</title>
      <link>https://psqf6250.brandonlebeau.org/rcode/projects/</link>
      <pubDate>Mon, 15 Feb 2021 00:00:00 +0000</pubDate>
      <guid>https://psqf6250.brandonlebeau.org/rcode/projects/</guid>
      <description>
&lt;script src=&#34;https://psqf6250.brandonlebeau.org/rmarkdown-libs/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;

&lt;div id=&#34;TOC&#34;&gt;

&lt;/div&gt;

&lt;p&gt;I want to talk briefly about RStudio projects. These are a great way to structure each individual project. Chapter 8 in the R for Data Science text will provide a more thorough discussion of RStudio projects: &lt;a href=&#34;http://r4ds.had.co.nz/workflow-projects.html&#34; class=&#34;uri&#34;&gt;http://r4ds.had.co.nz/workflow-projects.html&lt;/a&gt;&lt;/p&gt;
&lt;div id=&#34;working-directory&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Working Directory&lt;/h2&gt;
&lt;p&gt;As we move into reading in data files, the idea of a working directory will become even more important. RStudio projects makes this discussion much easier as the root of the project directory is treated as the working directory. The nice aspect of this is that all paths to data files are in reference to this root project directory (more on this coming soon).&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;project-structure&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Project Structure&lt;/h2&gt;
&lt;p&gt;The last aspect I want to share is a common project directory structure. Everyone can have slightly different versions, but I want to share what I have come to commonly use. The following structure is how I tend to structure most or my projects.&lt;/p&gt;
&lt;div class=&#34;figure&#34;&gt;
&lt;img src=&#34;https://psqf6250.brandonlebeau.org/img/project_structure.png&#34; alt=&#34;&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;Project Structure&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;Another way to visualize this structure is as follows:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Project Root:
&lt;ul&gt;
&lt;li&gt;Data&lt;/li&gt;
&lt;li&gt;example&lt;/li&gt;
&lt;li&gt;paper&lt;/li&gt;
&lt;li&gt;R&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Data Import</title>
      <link>https://psqf6250.brandonlebeau.org/rcode/data_import/</link>
      <pubDate>Thu, 18 Feb 2021 00:00:00 +0000</pubDate>
      <guid>https://psqf6250.brandonlebeau.org/rcode/data_import/</guid>
      <description>
&lt;script src=&#34;https://psqf6250.brandonlebeau.org/rmarkdown-libs/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;

&lt;div id=&#34;TOC&#34;&gt;

&lt;/div&gt;

&lt;p&gt;So far we have solely used data that is already found within R by way of packages. Obviously, we will want to use our own data and this involves importing data directly into R. We are going to focus on two types of data structures to read in, text files and excel files.&lt;/p&gt;
&lt;p&gt;The following two packages will be used in this section.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(tidyverse)
# install.packages(&amp;quot;readxl&amp;quot;)
library(readxl)&lt;/code&gt;&lt;/pre&gt;
&lt;div id=&#34;text-files&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Text Files&lt;/h2&gt;
&lt;p&gt;Through the use of the &lt;code&gt;readr&lt;/code&gt; package, we are going to read in flat text files. In many cases, these text files are saved as csv files. The csv stands for comma separated values files meaning that columns in the data are separated by columns. As a side note, this is the most common way that I save data and read in data. The nice aspect of csv files is that if needed, they can be opened in programs like Excel for viewing, but are still just text files which are simple and lightweight.&lt;/p&gt;
&lt;p&gt;To read in a csv file, we are going to use the &lt;code&gt;read_csv&lt;/code&gt; function from the &lt;code&gt;readr&lt;/code&gt; package. We are going to read in some UFO data (the data can be found on the &lt;a href=&#34;https://psqf6250.brandonlebeau.org/data/&#34;&gt;course website&lt;/a&gt;). The code below is going to read the data directly from the GitHub where the data are currently being stored.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ufo &amp;lt;- read_csv(&amp;quot;https://raw.githubusercontent.com/lebebr01/psqf-6250-blogdown/main/data/ufo.csv&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Rows: 8031 Columns: 7
## ── Column specification ────────────────────────────────────────────────────────
## Delimiter: &amp;quot;,&amp;quot;
## chr (7): Date / Time, City, State, Shape, Duration, Summary, Posted
## 
## ℹ Use `spec()` to retrieve the full column specification for this data.
## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;A special note here, if you downloaded the data, I recommend putting the downloaded data within an RStudio project in a folder named “Data” or “data”. The updated code (not run here), would look like (assuming the data are in the “data” folder within an RStudio project):&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ufo &amp;lt;- read_csv(&amp;#39;data/ufo.csv&amp;#39;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Note again, similar to dplyr, when saving the data to an object, it will not be printed. We can now view the first 10 rows by typing the object name.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ufo&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 8,031 × 7
##    `Date / Time`  City                     State Shape   Duration Summary Posted
##    &amp;lt;chr&amp;gt;          &amp;lt;chr&amp;gt;                    &amp;lt;chr&amp;gt; &amp;lt;chr&amp;gt;   &amp;lt;chr&amp;gt;    &amp;lt;chr&amp;gt;   &amp;lt;chr&amp;gt; 
##  1 12/12/14 17:30 North Wales              PA    Triang… 5 minut… &amp;quot;I hea… &amp;lt;NA&amp;gt;  
##  2 12/12/14 12:40 Cartersville             GA    Unknown 3.6 min… &amp;quot;Looki… 12/12…
##  3 12/12/14 06:30 Isle of Man (UK/England) &amp;lt;NA&amp;gt;  Light   2 secon… &amp;quot;Over … 12/12…
##  4 12/12/14 01:00 Miamisburg               OH    Changi… &amp;lt;NA&amp;gt;     &amp;quot;Brigh… 12/12…
##  5 12/12/14 00:00 Spotsylvania             VA    Unknown 1 minute &amp;quot;White… 12/12…
##  6 12/11/14 23:25 Kenner                   LA    Chevron ~1 minu… &amp;quot;Stran… 12/12…
##  7 12/11/14 23:15 Eugene                   OR    Disk    2 minut… &amp;quot;Dual … 12/12…
##  8 12/11/14 20:04 Phoenix                  AZ    Chevron 3 minut… &amp;quot;4 Ora… 12/12…
##  9 12/11/14 20:00 Franklin                 NC    Disk    5 minut… &amp;quot;There… 12/12…
## 10 12/11/14 18:30 Longview                 WA    Cylind… 10 seco… &amp;quot;Two c… 12/12…
## # … with 8,021 more rows&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;By default, the &lt;code&gt;read_csv&lt;/code&gt; function uses the first row of the data file as the names of the variables. To override this behavior, set &lt;code&gt;col_names = FALSE&lt;/code&gt; or better yet, specify the names with the &lt;code&gt;col_names&lt;/code&gt; argument. In addition, if the file has header metadata, rows of the data can be skipped with the &lt;code&gt;skip&lt;/code&gt; argument. For example, reading in the same data as above, but skipping the first row and specifying the names manually would look as follows:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;read_csv(&amp;quot;https://raw.githubusercontent.com/lebebr01/psqf-6250-blogdown/main/data/ufo.csv&amp;quot;, skip = 1, 
         col_names = c(&amp;#39;Date/Time&amp;#39;, &amp;#39;City&amp;#39;, &amp;#39;State&amp;#39;, 
                       &amp;#39;Shape&amp;#39;, &amp;#39;Duration&amp;#39;, &amp;#39;Summary&amp;#39;,
                       &amp;#39;Posted&amp;#39;))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Rows: 8031 Columns: 7
## ── Column specification ────────────────────────────────────────────────────────
## Delimiter: &amp;quot;,&amp;quot;
## chr (7): Date/Time, City, State, Shape, Duration, Summary, Posted
## 
## ℹ Use `spec()` to retrieve the full column specification for this data.
## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 8,031 × 7
##    `Date/Time`    City                     State Shape   Duration Summary Posted
##    &amp;lt;chr&amp;gt;          &amp;lt;chr&amp;gt;                    &amp;lt;chr&amp;gt; &amp;lt;chr&amp;gt;   &amp;lt;chr&amp;gt;    &amp;lt;chr&amp;gt;   &amp;lt;chr&amp;gt; 
##  1 12/12/14 17:30 North Wales              PA    Triang… 5 minut… &amp;quot;I hea… &amp;lt;NA&amp;gt;  
##  2 12/12/14 12:40 Cartersville             GA    Unknown 3.6 min… &amp;quot;Looki… 12/12…
##  3 12/12/14 06:30 Isle of Man (UK/England) &amp;lt;NA&amp;gt;  Light   2 secon… &amp;quot;Over … 12/12…
##  4 12/12/14 01:00 Miamisburg               OH    Changi… &amp;lt;NA&amp;gt;     &amp;quot;Brigh… 12/12…
##  5 12/12/14 00:00 Spotsylvania             VA    Unknown 1 minute &amp;quot;White… 12/12…
##  6 12/11/14 23:25 Kenner                   LA    Chevron ~1 minu… &amp;quot;Stran… 12/12…
##  7 12/11/14 23:15 Eugene                   OR    Disk    2 minut… &amp;quot;Dual … 12/12…
##  8 12/11/14 20:04 Phoenix                  AZ    Chevron 3 minut… &amp;quot;4 Ora… 12/12…
##  9 12/11/14 20:00 Franklin                 NC    Disk    5 minut… &amp;quot;There… 12/12…
## 10 12/11/14 18:30 Longview                 WA    Cylind… 10 seco… &amp;quot;Two c… 12/12…
## # … with 8,021 more rows&lt;/code&gt;&lt;/pre&gt;
&lt;div id=&#34;manually-specifying-column-types&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Manually Specifying Column Types&lt;/h3&gt;
&lt;p&gt;You may have noticed above that we just needed to give the &lt;code&gt;read_csv&lt;/code&gt; function the path to the data file, we did not need to tell the function the types of columns. Instead, the function guessed the type from the first 1000 rows. This can be useful for interactive work, but for truly reproducible code, it is best to specify these manually. There are two ways to specify the column types, one is verbose and the other is simpler, but both use the argument &lt;code&gt;col_types&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;First the verbose solution:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;read_csv(&amp;quot;https://raw.githubusercontent.com/lebebr01/psqf-6250-blogdown/main/data/ufo.csv&amp;quot;, 
         col_types = c(
           &amp;#39;Date/Time&amp;#39; = col_character(),
           City = col_character(),
           State = col_character(),
           Shape = col_character(),
           Duration = col_character(),
           Summary = col_character(),
           Posted = col_character()
         ))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 8,031 × 7
##    `Date / Time`  City                     State Shape   Duration Summary Posted
##    &amp;lt;chr&amp;gt;          &amp;lt;chr&amp;gt;                    &amp;lt;chr&amp;gt; &amp;lt;chr&amp;gt;   &amp;lt;chr&amp;gt;    &amp;lt;chr&amp;gt;   &amp;lt;chr&amp;gt; 
##  1 12/12/14 17:30 North Wales              PA    Triang… 5 minut… &amp;quot;I hea… &amp;lt;NA&amp;gt;  
##  2 12/12/14 12:40 Cartersville             GA    Unknown 3.6 min… &amp;quot;Looki… 12/12…
##  3 12/12/14 06:30 Isle of Man (UK/England) &amp;lt;NA&amp;gt;  Light   2 secon… &amp;quot;Over … 12/12…
##  4 12/12/14 01:00 Miamisburg               OH    Changi… &amp;lt;NA&amp;gt;     &amp;quot;Brigh… 12/12…
##  5 12/12/14 00:00 Spotsylvania             VA    Unknown 1 minute &amp;quot;White… 12/12…
##  6 12/11/14 23:25 Kenner                   LA    Chevron ~1 minu… &amp;quot;Stran… 12/12…
##  7 12/11/14 23:15 Eugene                   OR    Disk    2 minut… &amp;quot;Dual … 12/12…
##  8 12/11/14 20:04 Phoenix                  AZ    Chevron 3 minut… &amp;quot;4 Ora… 12/12…
##  9 12/11/14 20:00 Franklin                 NC    Disk    5 minut… &amp;quot;There… 12/12…
## 10 12/11/14 18:30 Longview                 WA    Cylind… 10 seco… &amp;quot;Two c… 12/12…
## # … with 8,021 more rows&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;As all variables are being read in as characters, there is a simple shortcut to use.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;read_csv(&amp;quot;https://raw.githubusercontent.com/lebebr01/psqf-6250-blogdown/main/data/ufo.csv&amp;quot;, 
         col_types = c(&amp;#39;ccccccc&amp;#39;))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 8,031 × 7
##    `Date / Time`  City                     State Shape   Duration Summary Posted
##    &amp;lt;chr&amp;gt;          &amp;lt;chr&amp;gt;                    &amp;lt;chr&amp;gt; &amp;lt;chr&amp;gt;   &amp;lt;chr&amp;gt;    &amp;lt;chr&amp;gt;   &amp;lt;chr&amp;gt; 
##  1 12/12/14 17:30 North Wales              PA    Triang… 5 minut… &amp;quot;I hea… &amp;lt;NA&amp;gt;  
##  2 12/12/14 12:40 Cartersville             GA    Unknown 3.6 min… &amp;quot;Looki… 12/12…
##  3 12/12/14 06:30 Isle of Man (UK/England) &amp;lt;NA&amp;gt;  Light   2 secon… &amp;quot;Over … 12/12…
##  4 12/12/14 01:00 Miamisburg               OH    Changi… &amp;lt;NA&amp;gt;     &amp;quot;Brigh… 12/12…
##  5 12/12/14 00:00 Spotsylvania             VA    Unknown 1 minute &amp;quot;White… 12/12…
##  6 12/11/14 23:25 Kenner                   LA    Chevron ~1 minu… &amp;quot;Stran… 12/12…
##  7 12/11/14 23:15 Eugene                   OR    Disk    2 minut… &amp;quot;Dual … 12/12…
##  8 12/11/14 20:04 Phoenix                  AZ    Chevron 3 minut… &amp;quot;4 Ora… 12/12…
##  9 12/11/14 20:00 Franklin                 NC    Disk    5 minut… &amp;quot;There… 12/12…
## 10 12/11/14 18:30 Longview                 WA    Cylind… 10 seco… &amp;quot;Two c… 12/12…
## # … with 8,021 more rows&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;To show the reason the more verbose is useful, suppose we wished to convert the ‘Data/Time’ variable to the correct type, a date time variable.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;read_csv(&amp;quot;https://raw.githubusercontent.com/lebebr01/psqf-6250-blogdown/main/data/ufo.csv&amp;quot;, 
         col_types = c(
           &amp;#39;Date / Time&amp;#39; = col_datetime(),
           City = col_character(),
           State = col_character(),
           Shape = col_character(),
           Duration = col_character(),
           Summary = col_character(),
           Posted = col_character()
         ))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Error: Unknown shortcut:&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Here we get an error, which is caused by the fact that the date time variable specification needs a format statement. We can directly specify this.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ufo_date &amp;lt;- read_csv(&amp;quot;https://raw.githubusercontent.com/lebebr01/psqf-6250-blogdown/main/data/ufo.csv&amp;quot;, 
         col_types = list(
           &amp;#39;Date / Time&amp;#39; = col_datetime(format = &amp;quot;%m/%d/%y %H:%M&amp;quot;),
           City = col_character(),
           State = col_character(),
           Shape = col_character(),
           Duration = col_character(),
           Summary = col_character(),
           Posted = col_character()
         ))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning: One or more parsing issues, see `problems()` for details&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ufo_date&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 8,031 × 7
##    `Date / Time`       City                  State Shape Duration Summary Posted
##    &amp;lt;dttm&amp;gt;              &amp;lt;chr&amp;gt;                 &amp;lt;chr&amp;gt; &amp;lt;chr&amp;gt; &amp;lt;chr&amp;gt;    &amp;lt;chr&amp;gt;   &amp;lt;chr&amp;gt; 
##  1 2014-12-12 17:30:00 North Wales           PA    Tria… 5 minut… &amp;quot;I hea… &amp;lt;NA&amp;gt;  
##  2 2014-12-12 12:40:00 Cartersville          GA    Unkn… 3.6 min… &amp;quot;Looki… 12/12…
##  3 2014-12-12 06:30:00 Isle of Man (UK/Engl… &amp;lt;NA&amp;gt;  Light 2 secon… &amp;quot;Over … 12/12…
##  4 2014-12-12 01:00:00 Miamisburg            OH    Chan… &amp;lt;NA&amp;gt;     &amp;quot;Brigh… 12/12…
##  5 2014-12-12 00:00:00 Spotsylvania          VA    Unkn… 1 minute &amp;quot;White… 12/12…
##  6 2014-12-11 23:25:00 Kenner                LA    Chev… ~1 minu… &amp;quot;Stran… 12/12…
##  7 2014-12-11 23:15:00 Eugene                OR    Disk  2 minut… &amp;quot;Dual … 12/12…
##  8 2014-12-11 20:04:00 Phoenix               AZ    Chev… 3 minut… &amp;quot;4 Ora… 12/12…
##  9 2014-12-11 20:00:00 Franklin              NC    Disk  5 minut… &amp;quot;There… 12/12…
## 10 2014-12-11 18:30:00 Longview              WA    Cyli… 10 seco… &amp;quot;Two c… 12/12…
## # … with 8,021 more rows&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Notice even though I was careful in the column specification, there was still issues when parsing this column as a date/time column. The data is still returned, but there are issues. These issues can be viewed using the &lt;code&gt;problems&lt;/code&gt; function.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;problems(ufo_date)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 56 × 5
##      row   col expected                 actual   file 
##    &amp;lt;int&amp;gt; &amp;lt;int&amp;gt; &amp;lt;chr&amp;gt;                    &amp;lt;chr&amp;gt;    &amp;lt;chr&amp;gt;
##  1   120     1 date like %m/%d/%y %H:%M 12/1/14  &amp;quot;&amp;quot;   
##  2   195     1 date like %m/%d/%y %H:%M 11/27/14 &amp;quot;&amp;quot;   
##  3   237     1 date like %m/%d/%y %H:%M 11/24/14 &amp;quot;&amp;quot;   
##  4   408     1 date like %m/%d/%y %H:%M 11/15/14 &amp;quot;&amp;quot;   
##  5   666     1 date like %m/%d/%y %H:%M 10/31/14 &amp;quot;&amp;quot;   
##  6   798     1 date like %m/%d/%y %H:%M 10/25/14 &amp;quot;&amp;quot;   
##  7   947     1 date like %m/%d/%y %H:%M 10/19/14 &amp;quot;&amp;quot;   
##  8  1082     1 date like %m/%d/%y %H:%M 10/14/14 &amp;quot;&amp;quot;   
##  9  1123     1 date like %m/%d/%y %H:%M 10/12/14 &amp;quot;&amp;quot;   
## 10  1124     1 date like %m/%d/%y %H:%M 10/12/14 &amp;quot;&amp;quot;   
## # … with 46 more rows&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;other-text-formats&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Other Text Formats&lt;/h3&gt;
&lt;p&gt;There are other text formats used to read in data. They are listed below with the function used to read in that type. Note, that the function calls are identical to those specified above.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;tsv - tab separated files - &lt;code&gt;read_tsv&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;fixed width files - &lt;code&gt;read_fwf&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;white space generally - &lt;code&gt;read_table&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;delimiter generally - &lt;code&gt;read_delim&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;div id=&#34;exercises&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Exercises&lt;/h4&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;There is a tsv file posted on icon called “lotr_clean.tsv”. Download this and read this data file into R.&lt;/li&gt;
&lt;li&gt;Instead of specifying the path, use the function &lt;code&gt;file.choose()&lt;/code&gt;. For example, &lt;code&gt;read_tsv(file.choose())&lt;/code&gt;. What does this function use? Would you recommend this to be used in a reproducible document?&lt;/li&gt;
&lt;li&gt;Run the &lt;code&gt;getwd()&lt;/code&gt; function from the R console. What does this function return?&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;excel-files&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Excel Files&lt;/h2&gt;
&lt;p&gt;Although I commonly use text files (e.g. csv) files, reality is that many people still use Excel for storing of data files. There are good and bad aspects of this, but reading in Excel files may be needed. The &lt;code&gt;readxl&lt;/code&gt; package is useful for this task.&lt;/p&gt;
&lt;p&gt;Suppose we wished to read in the Excel file found on the US Census Bureau website related to Education: &lt;a href=&#34;https://www.census.gov/support/USACdataDownloads.html&#34; class=&#34;uri&#34;&gt;https://www.census.gov/support/USACdataDownloads.html&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;To do this, we can do this directly with the &lt;code&gt;read_excel&lt;/code&gt; function with the data already downloaded and posted to the &lt;a href=&#34;https://psqf6250.brandonlebeau.org/data/&#34;&gt;course website&lt;/a&gt;. Note, the &lt;code&gt;read_excel()&lt;/code&gt; function does not allow for reading in data from the web, instead the data need to be downloaded to a temp file, then this file is loaded into R. If you downloaded the data, I recommend placing it within a “Data” or “data” folder.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;tf &amp;lt;- tempfile(fileext = &amp;quot;.xls&amp;quot;)
curl::curl_download(&amp;quot;https://github.com/lebebr01/psqf-6250-blogdown/blob/main/data/EDU01.xls?raw=true&amp;quot;, tf)

read_excel(tf)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 3,198 × 42
##    Area_name     STCOU EDU010187F EDU010187D EDU010187N1 EDU010187N2 EDU010188F
##    &amp;lt;chr&amp;gt;         &amp;lt;chr&amp;gt;      &amp;lt;dbl&amp;gt;      &amp;lt;dbl&amp;gt; &amp;lt;chr&amp;gt;       &amp;lt;chr&amp;gt;            &amp;lt;dbl&amp;gt;
##  1 UNITED STATES 00000          0   40024299 0000        0000                 0
##  2 ALABAMA       01000          0     733735 0000        0000                 0
##  3 Autauga, AL   01001          0       6829 0000        0000                 0
##  4 Baldwin, AL   01003          0      16417 0000        0000                 0
##  5 Barbour, AL   01005          0       5071 0000        0000                 0
##  6 Bibb, AL      01007          0       3557 0000        0000                 0
##  7 Blount, AL    01009          0       7319 0000        0000                 0
##  8 Bullock, AL   01011          0       2014 0000        0000                 0
##  9 Butler, AL    01013          0       4640 0000        0000                 0
## 10 Calhoun, AL   01015          0      20939 0000        0000                 0
## # … with 3,188 more rows, and 35 more variables: EDU010188D &amp;lt;dbl&amp;gt;,
## #   EDU010188N1 &amp;lt;chr&amp;gt;, EDU010188N2 &amp;lt;chr&amp;gt;, EDU010189F &amp;lt;dbl&amp;gt;, EDU010189D &amp;lt;dbl&amp;gt;,
## #   EDU010189N1 &amp;lt;chr&amp;gt;, EDU010189N2 &amp;lt;chr&amp;gt;, EDU010190F &amp;lt;dbl&amp;gt;, EDU010190D &amp;lt;dbl&amp;gt;,
## #   EDU010190N1 &amp;lt;chr&amp;gt;, EDU010190N2 &amp;lt;chr&amp;gt;, EDU010191F &amp;lt;dbl&amp;gt;, EDU010191D &amp;lt;dbl&amp;gt;,
## #   EDU010191N1 &amp;lt;chr&amp;gt;, EDU010191N2 &amp;lt;chr&amp;gt;, EDU010192F &amp;lt;dbl&amp;gt;, EDU010192D &amp;lt;dbl&amp;gt;,
## #   EDU010192N1 &amp;lt;chr&amp;gt;, EDU010192N2 &amp;lt;chr&amp;gt;, EDU010193F &amp;lt;dbl&amp;gt;, EDU010193D &amp;lt;dbl&amp;gt;,
## #   EDU010193N1 &amp;lt;chr&amp;gt;, EDU010193N2 &amp;lt;chr&amp;gt;, EDU010194F &amp;lt;dbl&amp;gt;, EDU010194D &amp;lt;dbl&amp;gt;, …&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;By default, the function will read in the first sheet and will treat the first row as the column names. If you wish to read in another sheet, you can use the &lt;code&gt;sheet&lt;/code&gt; argument. For example:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;read_excel(tf, sheet = 2)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 3,198 × 42
##    Area_name     STCOU EDU010197F EDU010197D EDU010197N1 EDU010197N2 EDU010198F
##    &amp;lt;chr&amp;gt;         &amp;lt;chr&amp;gt;      &amp;lt;dbl&amp;gt;      &amp;lt;dbl&amp;gt; &amp;lt;chr&amp;gt;       &amp;lt;chr&amp;gt;            &amp;lt;dbl&amp;gt;
##  1 UNITED STATES 00000          0   44534459 0000        0000                 0
##  2 ALABAMA       01000          0     737386 0000        0000                 0
##  3 Autauga, AL   01001          0       8099 0000        0000                 0
##  4 Baldwin, AL   01003          0      21410 0000        0000                 0
##  5 Barbour, AL   01005          0       5100 0000        0000                 0
##  6 Bibb, AL      01007          0       3717 0000        0000                 0
##  7 Blount, AL    01009          0       7816 0000        0000                 0
##  8 Bullock, AL   01011          0       2010 0000        0000                 0
##  9 Butler, AL    01013          0       4119 0000        0000                 0
## 10 Calhoun, AL   01015          0      19721 0000        0000                 0
## # … with 3,188 more rows, and 35 more variables: EDU010198D &amp;lt;dbl&amp;gt;,
## #   EDU010198N1 &amp;lt;chr&amp;gt;, EDU010198N2 &amp;lt;chr&amp;gt;, EDU010199F &amp;lt;dbl&amp;gt;, EDU010199D &amp;lt;dbl&amp;gt;,
## #   EDU010199N1 &amp;lt;chr&amp;gt;, EDU010199N2 &amp;lt;chr&amp;gt;, EDU010200F &amp;lt;dbl&amp;gt;, EDU010200D &amp;lt;dbl&amp;gt;,
## #   EDU010200N1 &amp;lt;chr&amp;gt;, EDU010200N2 &amp;lt;chr&amp;gt;, EDU010201F &amp;lt;dbl&amp;gt;, EDU010201D &amp;lt;dbl&amp;gt;,
## #   EDU010201N1 &amp;lt;chr&amp;gt;, EDU010201N2 &amp;lt;chr&amp;gt;, EDU010202F &amp;lt;dbl&amp;gt;, EDU010202D &amp;lt;dbl&amp;gt;,
## #   EDU010202N1 &amp;lt;chr&amp;gt;, EDU010202N2 &amp;lt;chr&amp;gt;, EDU015203F &amp;lt;dbl&amp;gt;, EDU015203D &amp;lt;dbl&amp;gt;,
## #   EDU015203N1 &amp;lt;chr&amp;gt;, EDU015203N2 &amp;lt;chr&amp;gt;, EDU015204F &amp;lt;dbl&amp;gt;, EDU015204D &amp;lt;dbl&amp;gt;, …&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;read_excel(tf, sheet = &amp;#39;EDU01B&amp;#39;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 3,198 × 42
##    Area_name     STCOU EDU010197F EDU010197D EDU010197N1 EDU010197N2 EDU010198F
##    &amp;lt;chr&amp;gt;         &amp;lt;chr&amp;gt;      &amp;lt;dbl&amp;gt;      &amp;lt;dbl&amp;gt; &amp;lt;chr&amp;gt;       &amp;lt;chr&amp;gt;            &amp;lt;dbl&amp;gt;
##  1 UNITED STATES 00000          0   44534459 0000        0000                 0
##  2 ALABAMA       01000          0     737386 0000        0000                 0
##  3 Autauga, AL   01001          0       8099 0000        0000                 0
##  4 Baldwin, AL   01003          0      21410 0000        0000                 0
##  5 Barbour, AL   01005          0       5100 0000        0000                 0
##  6 Bibb, AL      01007          0       3717 0000        0000                 0
##  7 Blount, AL    01009          0       7816 0000        0000                 0
##  8 Bullock, AL   01011          0       2010 0000        0000                 0
##  9 Butler, AL    01013          0       4119 0000        0000                 0
## 10 Calhoun, AL   01015          0      19721 0000        0000                 0
## # … with 3,188 more rows, and 35 more variables: EDU010198D &amp;lt;dbl&amp;gt;,
## #   EDU010198N1 &amp;lt;chr&amp;gt;, EDU010198N2 &amp;lt;chr&amp;gt;, EDU010199F &amp;lt;dbl&amp;gt;, EDU010199D &amp;lt;dbl&amp;gt;,
## #   EDU010199N1 &amp;lt;chr&amp;gt;, EDU010199N2 &amp;lt;chr&amp;gt;, EDU010200F &amp;lt;dbl&amp;gt;, EDU010200D &amp;lt;dbl&amp;gt;,
## #   EDU010200N1 &amp;lt;chr&amp;gt;, EDU010200N2 &amp;lt;chr&amp;gt;, EDU010201F &amp;lt;dbl&amp;gt;, EDU010201D &amp;lt;dbl&amp;gt;,
## #   EDU010201N1 &amp;lt;chr&amp;gt;, EDU010201N2 &amp;lt;chr&amp;gt;, EDU010202F &amp;lt;dbl&amp;gt;, EDU010202D &amp;lt;dbl&amp;gt;,
## #   EDU010202N1 &amp;lt;chr&amp;gt;, EDU010202N2 &amp;lt;chr&amp;gt;, EDU015203F &amp;lt;dbl&amp;gt;, EDU015203D &amp;lt;dbl&amp;gt;,
## #   EDU015203N1 &amp;lt;chr&amp;gt;, EDU015203N2 &amp;lt;chr&amp;gt;, EDU015204F &amp;lt;dbl&amp;gt;, EDU015204D &amp;lt;dbl&amp;gt;, …&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;If there is metadata or no column names, these can be added in the same fashion as discussed above with the &lt;code&gt;read_csv&lt;/code&gt; function. Finally, it should be noted, to use these data within R, you would want to save these data to an object within R.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;edu_data &amp;lt;- read_excel(tf)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;writing-files&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Writing Files&lt;/h2&gt;
&lt;p&gt;Most of the &lt;code&gt;read_*&lt;/code&gt; functions also come with functions that allow you to write out files as well. I’m only going to cover the &lt;code&gt;write_csv&lt;/code&gt; function, however, there are others that may be of use. Similarly to reading in files, the functionality is the same across the &lt;code&gt;write_*&lt;/code&gt; functions.&lt;/p&gt;
&lt;p&gt;Suppose we created a new column with the &lt;code&gt;ufo&lt;/code&gt; data and wished to save this data to a csv file, this can be accomplished with the following series of commands.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ufo_count &amp;lt;- ufo %&amp;gt;%
  group_by(State) %&amp;gt;%
  mutate(num_state = n())
write_csv(ufo_count, path = &amp;#39;path/to/save/file.csv&amp;#39;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Notice there are two arguments to the &lt;code&gt;write_csv&lt;/code&gt; function, the first argument is the object you wish to save. The second is the path to the location to save the object. You must specify &lt;code&gt;path =&lt;/code&gt; otherwise the &lt;code&gt;write_csv&lt;/code&gt; function will look for that object in the R session.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;other-data-formats&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Other Data Formats&lt;/h2&gt;
&lt;p&gt;There are still other data formats, particularly from proprietary statistical software such as Stata, SAS, or SPSS. To read these files in the &lt;code&gt;haven&lt;/code&gt; function would be useful. I leave this as an exercise for you if you have these types of files to read into R.&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Data Restructuring</title>
      <link>https://psqf6250.brandonlebeau.org/rcode/data_restructuring/</link>
      <pubDate>Thu, 18 Feb 2021 00:00:00 +0000</pubDate>
      <guid>https://psqf6250.brandonlebeau.org/rcode/data_restructuring/</guid>
      <description>
&lt;script src=&#34;https://psqf6250.brandonlebeau.org/rmarkdown-libs/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;

&lt;div id=&#34;TOC&#34;&gt;

&lt;/div&gt;

&lt;p&gt;Data restructuring is often a useful tool to have. By data restructuring, I mean transforming data from long to wide format or vice versa. For the most part, long format is much easier to use when plotting and computing summary statistics. A related topic, called tidy data, can be read about in more detail here: &lt;a href=&#34;http://www.jstatsoft.org/v59/i10/paper&#34; class=&#34;uri&#34;&gt;http://www.jstatsoft.org/v59/i10/paper&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;The data we are going to use for this section of notes is called “LongitudinalEx.csv” and can be found on the &lt;a href=&#34;https://psqf6250.brandonlebeau.org/data/&#34;&gt;course website&lt;/a&gt;. The data are loaded directly from the web, but these could be loaded from a downloaded data file (see )&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(tidyverse)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## ── Attaching packages ─────────────────────────────────────── tidyverse 1.3.1 ──&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## ✓ ggplot2 3.3.5     ✓ purrr   0.3.4
## ✓ tibble  3.1.6     ✓ dplyr   1.0.7
## ✓ tidyr   1.2.0     ✓ stringr 1.4.0
## ✓ readr   2.1.2     ✓ forcats 0.5.1&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──
## x dplyr::filter() masks stats::filter()
## x dplyr::lag()    masks stats::lag()&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;long_data &amp;lt;- read_csv(&amp;quot;https://raw.githubusercontent.com/lebebr01/psqf-6250-blogdown/main/data/LongitudinalEx.csv&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Rows: 27 Columns: 7&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## ── Column specification ────────────────────────────────────────────────────────
## Delimiter: &amp;quot;,&amp;quot;
## dbl (7): id, wave, agegrp, age, piat, agegrp.c, age.c
## 
## ℹ Use `spec()` to retrieve the full column specification for this data.
## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.&lt;/code&gt;&lt;/pre&gt;
&lt;div id=&#34;longstacked-data&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Long/Stacked Data&lt;/h2&gt;
&lt;p&gt;The data read in above is in a format that is commonly referred to as long or stacked data.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;long_data&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 27 × 7
##       id  wave agegrp   age  piat agegrp.c  age.c
##    &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;  &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;    &amp;lt;dbl&amp;gt;  &amp;lt;dbl&amp;gt;
##  1     4     1    6.5  6       18        0 -0.5  
##  2     4     2    8.5  8.5     31        2  2    
##  3     4     3   10.5 10.7     50        4  4.17 
##  4    27     1    6.5  6.25    19        0 -0.25 
##  5    27     2    8.5  9.17    36        2  2.67 
##  6    27     3   10.5 10.9     57        4  4.42 
##  7    31     1    6.5  6.33    18        0 -0.167
##  8    31     2    8.5  8.83    31        2  2.33 
##  9    31     3   10.5 10.9     51        4  4.42 
## 10    33     1    6.5  6.33    18        0 -0.167
## # … with 17 more rows&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;These data do not have one individual per row, instead each row is a individual by wave combination and are stacked for each individual (notice the three rows for id = 4). The variables in this case each have there own column in the data and all of them are time varying (change for each wave of data within an individual). This is also an example of “tidy data” from the paper linked to above, where each row is a unique observation (id, wave pair), variables are in the columns, and each cell of the data is a value.&lt;/p&gt;
&lt;p&gt;The primary functions within the tidyr package are the following:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;pivot_longer()&lt;/code&gt;: for making the data longer, this replaces the &lt;code&gt;gather()&lt;/code&gt; function from tidyr.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;pivot_wider()&lt;/code&gt;: for making the data wider, this replaces the &lt;code&gt;spread()&lt;/code&gt; function from tidyr.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;These two functions are relatively new and they still may change as they continue to be developed. I believe the old functions will be deprecated, but not removed entirely. This means they will not be actively developed any longer, but will remain in the tidyr package for the forseeable future.&lt;/p&gt;
&lt;p&gt;It should also be noted there are mutiple R packages for data restructuring, including reshape and reshape2. The syntax for these has always been difficult for me to fully process and internalize, but they are incredibly powerful. I believe almost every data restructuring task can be accomplished by &lt;code&gt;pivot_longer()&lt;/code&gt; and &lt;code&gt;pivot_wider()&lt;/code&gt; (with some companion functions), but it may take a few extra steps to get to the desired structure.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;extra-long-data&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Extra Long Data&lt;/h2&gt;
&lt;p&gt;To progress through data restructuring, we first need to transform this data is extra long format. This format is not entirely useful by itself, however it will help use show the use of a few functions from the &lt;code&gt;tidyr&lt;/code&gt; package. To go to extra long data, we will make use of the &lt;code&gt;pivot_longer()&lt;/code&gt; and &lt;code&gt;unite&lt;/code&gt; functions.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;extra_long &amp;lt;- long_data %&amp;gt;%
  pivot_longer(agegrp:age.c, names_to = &amp;#39;variable&amp;#39;, values_to = &amp;#39;value&amp;#39;) %&amp;gt;%
  unite(var_wave, variable, wave)
extra_long &lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 135 × 3
##       id var_wave   value
##    &amp;lt;dbl&amp;gt; &amp;lt;chr&amp;gt;      &amp;lt;dbl&amp;gt;
##  1     4 agegrp_1     6.5
##  2     4 age_1        6  
##  3     4 piat_1      18  
##  4     4 agegrp.c_1   0  
##  5     4 age.c_1     -0.5
##  6     4 agegrp_2     8.5
##  7     4 age_2        8.5
##  8     4 piat_2      31  
##  9     4 agegrp.c_2   2  
## 10     4 age.c_2      2  
## # … with 125 more rows&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;You’ll notice now that there are only three columns in the data and that there are now 135 rows in data. This extra long data format gathered all of the variables into two columns, one that identify the variable and wave and the other that simply lists the value.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;wide-data&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Wide Data&lt;/h2&gt;
&lt;p&gt;We can now take the extra long data and turn this into wide data. Wide data is characterized by one row per individual with columns representing the variable and wave combinations.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;wide &amp;lt;- extra_long %&amp;gt;% 
  pivot_wider(names_from = var_wave, values_from = value)
wide&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 9 × 16
##      id agegrp_1 age_1 piat_1 agegrp.c_1 age.c_1 agegrp_2 age_2 piat_2
##   &amp;lt;dbl&amp;gt;    &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;  &amp;lt;dbl&amp;gt;      &amp;lt;dbl&amp;gt;   &amp;lt;dbl&amp;gt;    &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;  &amp;lt;dbl&amp;gt;
## 1     4      6.5  6        18          0  -0.5        8.5  8.5      31
## 2    27      6.5  6.25     19          0  -0.25       8.5  9.17     36
## 3    31      6.5  6.33     18          0  -0.167      8.5  8.83     31
## 4    33      6.5  6.33     18          0  -0.167      8.5  8.92     34
## 5    41      6.5  6.33     18          0  -0.167      8.5  8.75     28
## 6    49      6.5  6.5      19          0   0          8.5  8.75     32
## 7    69      6.5  6.67     26          0   0.167      8.5  9.17     47
## 8    77      6.5  6.83     17          0   0.333      8.5  8.08     19
## 9    87      6.5  6.92     22          0   0.417      8.5  9.42     49
## # … with 7 more variables: agegrp.c_2 &amp;lt;dbl&amp;gt;, age.c_2 &amp;lt;dbl&amp;gt;, agegrp_3 &amp;lt;dbl&amp;gt;,
## #   age_3 &amp;lt;dbl&amp;gt;, piat_3 &amp;lt;dbl&amp;gt;, agegrp.c_3 &amp;lt;dbl&amp;gt;, age.c_3 &amp;lt;dbl&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;You’ll notice from the data above, there are now only 9 rows, but now 16 columns in the data. Each variable except for id now also has a number appended to it to represent the wave of the data.&lt;/p&gt;
&lt;p&gt;This data structure is common, particularly for users of SPSS or Excel for data entry or processing. Unfortunately, when working with data in R (and in general), data in wide format is often difficult to work with. Therefore it is common to need to restructure the data from wide to long format.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;back-to-long-format&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Back to Long Format&lt;/h2&gt;
&lt;p&gt;Fortunately, we can use the same functions as we used above, but now in inverse to get from wide to long format.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;wide %&amp;gt;% 
  pivot_longer(-id, names_to = &amp;quot;variable&amp;quot;, values_to = &amp;quot;value&amp;quot;) %&amp;gt;%
  separate(variable, into = c(&amp;#39;variable&amp;#39;, &amp;#39;wave&amp;#39;), 
           sep = &amp;quot;_&amp;quot;) %&amp;gt;%
  arrange(id, wave) %&amp;gt;%
  pivot_wider(names_from = variable, values_from = value)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 27 × 7
##       id wave  agegrp   age  piat agegrp.c  age.c
##    &amp;lt;dbl&amp;gt; &amp;lt;chr&amp;gt;  &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;    &amp;lt;dbl&amp;gt;  &amp;lt;dbl&amp;gt;
##  1     4 1        6.5  6       18        0 -0.5  
##  2     4 2        8.5  8.5     31        2  2    
##  3     4 3       10.5 10.7     50        4  4.17 
##  4    27 1        6.5  6.25    19        0 -0.25 
##  5    27 2        8.5  9.17    36        2  2.67 
##  6    27 3       10.5 10.9     57        4  4.42 
##  7    31 1        6.5  6.33    18        0 -0.167
##  8    31 2        8.5  8.83    31        2  2.33 
##  9    31 3       10.5 10.9     51        4  4.42 
## 10    33 1        6.5  6.33    18        0 -0.167
## # … with 17 more rows&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This now is identical to the first data that we had. I would recommend working through the steps above to see what the data structure looks like in each intermediate step along the way. In addition, it is often not of interest to save the extra long data format, below is the code that would go directly from long to wide.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;long_data %&amp;gt;%
  pivot_longer(agegrp:age.c, names_to = &amp;#39;variable&amp;#39;, values_to = &amp;#39;value&amp;#39;) %&amp;gt;%
  unite(var_wave, variable, wave) %&amp;gt;%
  pivot_wider(names_from = var_wave, values_from = value)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 9 × 16
##      id agegrp_1 age_1 piat_1 agegrp.c_1 age.c_1 agegrp_2 age_2 piat_2
##   &amp;lt;dbl&amp;gt;    &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;  &amp;lt;dbl&amp;gt;      &amp;lt;dbl&amp;gt;   &amp;lt;dbl&amp;gt;    &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;  &amp;lt;dbl&amp;gt;
## 1     4      6.5  6        18          0  -0.5        8.5  8.5      31
## 2    27      6.5  6.25     19          0  -0.25       8.5  9.17     36
## 3    31      6.5  6.33     18          0  -0.167      8.5  8.83     31
## 4    33      6.5  6.33     18          0  -0.167      8.5  8.92     34
## 5    41      6.5  6.33     18          0  -0.167      8.5  8.75     28
## 6    49      6.5  6.5      19          0   0          8.5  8.75     32
## 7    69      6.5  6.67     26          0   0.167      8.5  9.17     47
## 8    77      6.5  6.83     17          0   0.333      8.5  8.08     19
## 9    87      6.5  6.92     22          0   0.417      8.5  9.42     49
## # … with 7 more variables: agegrp.c_2 &amp;lt;dbl&amp;gt;, age.c_2 &amp;lt;dbl&amp;gt;, agegrp_3 &amp;lt;dbl&amp;gt;,
## #   age_3 &amp;lt;dbl&amp;gt;, piat_3 &amp;lt;dbl&amp;gt;, agegrp.c_3 &amp;lt;dbl&amp;gt;, age.c_3 &amp;lt;dbl&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;div id=&#34;exercises&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Exercises&lt;/h3&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;Using the following data generation code, convert these data to long format.&lt;/li&gt;
&lt;/ol&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;set.seed(10)
messy &amp;lt;- data.frame(
  id = 1:4,
  trt = sample(rep(c(&amp;#39;control&amp;#39;, &amp;#39;treatment&amp;#39;), each = 2)),
  work.T1 = runif(4),
  home.T1 = runif(4),
  work.T2 = runif(4),
  home.T2 = runif(4)
)&lt;/code&gt;&lt;/pre&gt;
&lt;ol start=&#34;2&#34; style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;Once successfully converted to long format, convert back to wide format.&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Joining Data</title>
      <link>https://psqf6250.brandonlebeau.org/rcode/data_joins/</link>
      <pubDate>Thu, 18 Feb 2021 00:00:00 +0000</pubDate>
      <guid>https://psqf6250.brandonlebeau.org/rcode/data_joins/</guid>
      <description>
&lt;script src=&#34;https://psqf6250.brandonlebeau.org/rmarkdown-libs/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;

&lt;div id=&#34;TOC&#34;&gt;

&lt;/div&gt;

&lt;p&gt;Another common data manipulation task is to join multiple data sources into a single data file for an analysis. This task is most easily accomplished using a set of &lt;code&gt;join&lt;/code&gt; functions found in the &lt;code&gt;dplyr&lt;/code&gt; package. In this set of notes we are going to focus on mutating joins and filtering joins. There is another class of joins called set operations. I use these much less frequently, but for those interested, see the text in the R for Data Science book &lt;a href=&#34;http://r4ds.had.co.nz/relational-data.html&#34; class=&#34;uri&#34;&gt;http://r4ds.had.co.nz/relational-data.html&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;For this set of notes, we are going to make use of two packages:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(tidyverse)
# install.packages(&amp;#39;Lahman&amp;#39;)
library(Lahman)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The &lt;code&gt;Lahman&lt;/code&gt; package contains data from the Major League Baseball (MLB), a professional baseball association in the United States. For this section, we are going to focus on the following three data tables, &lt;code&gt;Teams&lt;/code&gt;, &lt;code&gt;Salaries&lt;/code&gt;, and &lt;code&gt;Managers&lt;/code&gt;. I print the first ten rows of the data for each table below.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;head(Teams, n = 10)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##    yearID lgID teamID franchID divID Rank  G Ghome  W  L DivWin WCWin LgWin
## 1    1871   NA    BS1      BNA  &amp;lt;NA&amp;gt;    3 31    NA 20 10   &amp;lt;NA&amp;gt;  &amp;lt;NA&amp;gt;     N
## 2    1871   NA    CH1      CNA  &amp;lt;NA&amp;gt;    2 28    NA 19  9   &amp;lt;NA&amp;gt;  &amp;lt;NA&amp;gt;     N
## 3    1871   NA    CL1      CFC  &amp;lt;NA&amp;gt;    8 29    NA 10 19   &amp;lt;NA&amp;gt;  &amp;lt;NA&amp;gt;     N
## 4    1871   NA    FW1      KEK  &amp;lt;NA&amp;gt;    7 19    NA  7 12   &amp;lt;NA&amp;gt;  &amp;lt;NA&amp;gt;     N
## 5    1871   NA    NY2      NNA  &amp;lt;NA&amp;gt;    5 33    NA 16 17   &amp;lt;NA&amp;gt;  &amp;lt;NA&amp;gt;     N
## 6    1871   NA    PH1      PNA  &amp;lt;NA&amp;gt;    1 28    NA 21  7   &amp;lt;NA&amp;gt;  &amp;lt;NA&amp;gt;     Y
## 7    1871   NA    RC1      ROK  &amp;lt;NA&amp;gt;    9 25    NA  4 21   &amp;lt;NA&amp;gt;  &amp;lt;NA&amp;gt;     N
## 8    1871   NA    TRO      TRO  &amp;lt;NA&amp;gt;    6 29    NA 13 15   &amp;lt;NA&amp;gt;  &amp;lt;NA&amp;gt;     N
## 9    1871   NA    WS3      OLY  &amp;lt;NA&amp;gt;    4 32    NA 15 15   &amp;lt;NA&amp;gt;  &amp;lt;NA&amp;gt;     N
## 10   1872   NA    BL1      BLC  &amp;lt;NA&amp;gt;    2 58    NA 35 19   &amp;lt;NA&amp;gt;  &amp;lt;NA&amp;gt;     N
##    WSWin   R   AB   H X2B X3B HR BB SO SB CS HBP SF  RA  ER  ERA CG SHO SV
## 1   &amp;lt;NA&amp;gt; 401 1372 426  70  37  3 60 19 73 16  NA NA 303 109 3.55 22   1  3
## 2   &amp;lt;NA&amp;gt; 302 1196 323  52  21 10 60 22 69 21  NA NA 241  77 2.76 25   0  1
## 3   &amp;lt;NA&amp;gt; 249 1186 328  35  40  7 26 25 18  8  NA NA 341 116 4.11 23   0  0
## 4   &amp;lt;NA&amp;gt; 137  746 178  19   8  2 33  9 16  4  NA NA 243  97 5.17 19   1  0
## 5   &amp;lt;NA&amp;gt; 302 1404 403  43  21  1 33 15 46 15  NA NA 313 121 3.72 32   1  0
## 6   &amp;lt;NA&amp;gt; 376 1281 410  66  27  9 46 23 56 12  NA NA 266 137 4.95 27   0  0
## 7   &amp;lt;NA&amp;gt; 231 1036 274  44  25  3 38 30 53 10  NA NA 287 108 4.30 23   1  0
## 8   &amp;lt;NA&amp;gt; 351 1248 384  51  34  6 49 19 62 24  NA NA 362 153 5.51 28   0  0
## 9   &amp;lt;NA&amp;gt; 310 1353 375  54  26  6 48 13 48 13  NA NA 303 137 4.37 32   0  0
## 10  &amp;lt;NA&amp;gt; 617 2571 753 106  31 14 29 28 53 18  NA NA 434 166 2.90 48   1  1
##    IPouts  HA HRA BBA SOA   E DP    FP                    name
## 1     828 367   2  42  23 243 24 0.834    Boston Red Stockings
## 2     753 308   6  28  22 229 16 0.829 Chicago White Stockings
## 3     762 346  13  53  34 234 15 0.818  Cleveland Forest Citys
## 4     507 261   5  21  17 163  8 0.803    Fort Wayne Kekiongas
## 5     879 373   7  42  22 235 14 0.840        New York Mutuals
## 6     747 329   3  53  16 194 13 0.845  Philadelphia Athletics
## 7     678 315   3  34  16 220 14 0.821   Rockford Forest Citys
## 8     750 431   4  75  12 198 22 0.845          Troy Haymakers
## 9     846 371   4  45  13 218 20 0.850     Washington Olympics
## 10   1548 573   3  63  77 432 22 0.830      Baltimore Canaries
##                                 park attendance BPF PPF teamIDBR teamIDlahman45
## 1                South End Grounds I         NA 103  98      BOS            BS1
## 2            Union Base-Ball Grounds         NA 104 102      CHI            CH1
## 3       National Association Grounds         NA  96 100      CLE            CL1
## 4                     Hamilton Field         NA 101 107      KEK            FW1
## 5           Union Grounds (Brooklyn)         NA  90  88      NYU            NY2
## 6           Jefferson Street Grounds         NA 102  98      ATH            PH1
## 7  Agricultural Society Fair Grounds         NA  97  99      ROK            RC1
## 8                 Haymakers&amp;#39; Grounds         NA 101 100      TRO            TRO
## 9                   Olympics Grounds         NA  94  98      OLY            WS3
## 10                    Newington Park         NA 106 102      BAL            BL1
##    teamIDretro
## 1          BS1
## 2          CH1
## 3          CL1
## 4          FW1
## 5          NY2
## 6          PH1
## 7          RC1
## 8          TRO
## 9          WS3
## 10         BL1&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;head(Salaries, n = 10)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##    yearID teamID lgID  playerID salary
## 1    1985    ATL   NL barkele01 870000
## 2    1985    ATL   NL bedrost01 550000
## 3    1985    ATL   NL benedbr01 545000
## 4    1985    ATL   NL  campri01 633333
## 5    1985    ATL   NL ceronri01 625000
## 6    1985    ATL   NL chambch01 800000
## 7    1985    ATL   NL dedmoje01 150000
## 8    1985    ATL   NL forstte01 483333
## 9    1985    ATL   NL garbege01 772000
## 10   1985    ATL   NL harpete01 250000&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;head(Managers, n = 10)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##     playerID yearID teamID lgID inseason  G  W  L rank plyrMgr
## 1  wrighha01   1871    BS1   NA        1 31 20 10    3       Y
## 2   woodji01   1871    CH1   NA        1 28 19  9    2       Y
## 3  paborch01   1871    CL1   NA        1 29 10 19    8       Y
## 4  lennobi01   1871    FW1   NA        1 14  5  9    8       Y
## 5  deaneha01   1871    FW1   NA        2  5  2  3    8       Y
## 6  fergubo01   1871    NY2   NA        1 33 16 17    5       Y
## 7  mcbridi01   1871    PH1   NA        1 28 21  7    1       Y
## 8  hastisc01   1871    RC1   NA        1 25  4 21    9       Y
## 9   pikeli01   1871    TRO   NA        1  4  1  3    6       Y
## 10 cravebi01   1871    TRO   NA        2 25 12 12    6       Y&lt;/code&gt;&lt;/pre&gt;
&lt;div id=&#34;inner-join&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Inner Join&lt;/h2&gt;
&lt;p&gt;The most basic join is the inner join. This join takes two tables and returns values if key variables match in both tables. If rows do not match on the key variables, these observations are removed. Suppose for example, we wanted to select the rows that matched between the &lt;code&gt;Teams&lt;/code&gt; and &lt;code&gt;Salaries&lt;/code&gt; data. This would be useful for example if we wished to calculate the average salary of the players for each team for every year.&lt;/p&gt;
&lt;p&gt;This join could be done with the &lt;code&gt;inner_join&lt;/code&gt; function.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;team_salary &amp;lt;- inner_join(Teams, Salaries)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Joining, by = c(&amp;quot;yearID&amp;quot;, &amp;quot;lgID&amp;quot;, &amp;quot;teamID&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;head(team_salary, n = 10)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##    yearID lgID teamID franchID divID Rank   G Ghome  W  L DivWin WCWin LgWin
## 1    1985   NL    ATL      ATL     W    5 162    81 66 96      N  &amp;lt;NA&amp;gt;     N
## 2    1985   NL    ATL      ATL     W    5 162    81 66 96      N  &amp;lt;NA&amp;gt;     N
## 3    1985   NL    ATL      ATL     W    5 162    81 66 96      N  &amp;lt;NA&amp;gt;     N
## 4    1985   NL    ATL      ATL     W    5 162    81 66 96      N  &amp;lt;NA&amp;gt;     N
## 5    1985   NL    ATL      ATL     W    5 162    81 66 96      N  &amp;lt;NA&amp;gt;     N
## 6    1985   NL    ATL      ATL     W    5 162    81 66 96      N  &amp;lt;NA&amp;gt;     N
## 7    1985   NL    ATL      ATL     W    5 162    81 66 96      N  &amp;lt;NA&amp;gt;     N
## 8    1985   NL    ATL      ATL     W    5 162    81 66 96      N  &amp;lt;NA&amp;gt;     N
## 9    1985   NL    ATL      ATL     W    5 162    81 66 96      N  &amp;lt;NA&amp;gt;     N
## 10   1985   NL    ATL      ATL     W    5 162    81 66 96      N  &amp;lt;NA&amp;gt;     N
##    WSWin   R   AB    H X2B X3B  HR  BB  SO SB CS HBP SF  RA  ER  ERA CG SHO SV
## 1      N 632 5526 1359 213  28 126 553 849 72 52  22 41 781 679 4.19  9   9 29
## 2      N 632 5526 1359 213  28 126 553 849 72 52  22 41 781 679 4.19  9   9 29
## 3      N 632 5526 1359 213  28 126 553 849 72 52  22 41 781 679 4.19  9   9 29
## 4      N 632 5526 1359 213  28 126 553 849 72 52  22 41 781 679 4.19  9   9 29
## 5      N 632 5526 1359 213  28 126 553 849 72 52  22 41 781 679 4.19  9   9 29
## 6      N 632 5526 1359 213  28 126 553 849 72 52  22 41 781 679 4.19  9   9 29
## 7      N 632 5526 1359 213  28 126 553 849 72 52  22 41 781 679 4.19  9   9 29
## 8      N 632 5526 1359 213  28 126 553 849 72 52  22 41 781 679 4.19  9   9 29
## 9      N 632 5526 1359 213  28 126 553 849 72 52  22 41 781 679 4.19  9   9 29
## 10     N 632 5526 1359 213  28 126 553 849 72 52  22 41 781 679 4.19  9   9 29
##    IPouts   HA HRA BBA SOA   E  DP    FP           name
## 1    4372 1512 134 642 776 159 197 0.976 Atlanta Braves
## 2    4372 1512 134 642 776 159 197 0.976 Atlanta Braves
## 3    4372 1512 134 642 776 159 197 0.976 Atlanta Braves
## 4    4372 1512 134 642 776 159 197 0.976 Atlanta Braves
## 5    4372 1512 134 642 776 159 197 0.976 Atlanta Braves
## 6    4372 1512 134 642 776 159 197 0.976 Atlanta Braves
## 7    4372 1512 134 642 776 159 197 0.976 Atlanta Braves
## 8    4372 1512 134 642 776 159 197 0.976 Atlanta Braves
## 9    4372 1512 134 642 776 159 197 0.976 Atlanta Braves
## 10   4372 1512 134 642 776 159 197 0.976 Atlanta Braves
##                             park attendance BPF PPF teamIDBR teamIDlahman45
## 1  Atlanta-Fulton County Stadium    1350137 105 106      ATL            ATL
## 2  Atlanta-Fulton County Stadium    1350137 105 106      ATL            ATL
## 3  Atlanta-Fulton County Stadium    1350137 105 106      ATL            ATL
## 4  Atlanta-Fulton County Stadium    1350137 105 106      ATL            ATL
## 5  Atlanta-Fulton County Stadium    1350137 105 106      ATL            ATL
## 6  Atlanta-Fulton County Stadium    1350137 105 106      ATL            ATL
## 7  Atlanta-Fulton County Stadium    1350137 105 106      ATL            ATL
## 8  Atlanta-Fulton County Stadium    1350137 105 106      ATL            ATL
## 9  Atlanta-Fulton County Stadium    1350137 105 106      ATL            ATL
## 10 Atlanta-Fulton County Stadium    1350137 105 106      ATL            ATL
##    teamIDretro  playerID salary
## 1          ATL barkele01 870000
## 2          ATL bedrost01 550000
## 3          ATL benedbr01 545000
## 4          ATL  campri01 633333
## 5          ATL ceronri01 625000
## 6          ATL chambch01 800000
## 7          ATL dedmoje01 150000
## 8          ATL forstte01 483333
## 9          ATL garbege01 772000
## 10         ATL harpete01 250000&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;You’ll notice that there is only data from 1985 onward, the data in the &lt;code&gt;Teams&lt;/code&gt; data from before 1985 have automatically been removed due to no matching data in the &lt;code&gt;Salaries&lt;/code&gt; data. You may have also noticed, that I did not specify the variables to join by above, for interactive work this can be okay, but to be more reproducible, specifying the variables to join on would be better. The function call above can be modified to include this information.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;team_salary &amp;lt;- inner_join(Teams, Salaries, by = c(&amp;#39;yearID&amp;#39;, &amp;#39;teamID&amp;#39;, &amp;#39;lgID&amp;#39;))
head(team_salary, n = 10)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##    yearID lgID teamID franchID divID Rank   G Ghome  W  L DivWin WCWin LgWin
## 1    1985   NL    ATL      ATL     W    5 162    81 66 96      N  &amp;lt;NA&amp;gt;     N
## 2    1985   NL    ATL      ATL     W    5 162    81 66 96      N  &amp;lt;NA&amp;gt;     N
## 3    1985   NL    ATL      ATL     W    5 162    81 66 96      N  &amp;lt;NA&amp;gt;     N
## 4    1985   NL    ATL      ATL     W    5 162    81 66 96      N  &amp;lt;NA&amp;gt;     N
## 5    1985   NL    ATL      ATL     W    5 162    81 66 96      N  &amp;lt;NA&amp;gt;     N
## 6    1985   NL    ATL      ATL     W    5 162    81 66 96      N  &amp;lt;NA&amp;gt;     N
## 7    1985   NL    ATL      ATL     W    5 162    81 66 96      N  &amp;lt;NA&amp;gt;     N
## 8    1985   NL    ATL      ATL     W    5 162    81 66 96      N  &amp;lt;NA&amp;gt;     N
## 9    1985   NL    ATL      ATL     W    5 162    81 66 96      N  &amp;lt;NA&amp;gt;     N
## 10   1985   NL    ATL      ATL     W    5 162    81 66 96      N  &amp;lt;NA&amp;gt;     N
##    WSWin   R   AB    H X2B X3B  HR  BB  SO SB CS HBP SF  RA  ER  ERA CG SHO SV
## 1      N 632 5526 1359 213  28 126 553 849 72 52  22 41 781 679 4.19  9   9 29
## 2      N 632 5526 1359 213  28 126 553 849 72 52  22 41 781 679 4.19  9   9 29
## 3      N 632 5526 1359 213  28 126 553 849 72 52  22 41 781 679 4.19  9   9 29
## 4      N 632 5526 1359 213  28 126 553 849 72 52  22 41 781 679 4.19  9   9 29
## 5      N 632 5526 1359 213  28 126 553 849 72 52  22 41 781 679 4.19  9   9 29
## 6      N 632 5526 1359 213  28 126 553 849 72 52  22 41 781 679 4.19  9   9 29
## 7      N 632 5526 1359 213  28 126 553 849 72 52  22 41 781 679 4.19  9   9 29
## 8      N 632 5526 1359 213  28 126 553 849 72 52  22 41 781 679 4.19  9   9 29
## 9      N 632 5526 1359 213  28 126 553 849 72 52  22 41 781 679 4.19  9   9 29
## 10     N 632 5526 1359 213  28 126 553 849 72 52  22 41 781 679 4.19  9   9 29
##    IPouts   HA HRA BBA SOA   E  DP    FP           name
## 1    4372 1512 134 642 776 159 197 0.976 Atlanta Braves
## 2    4372 1512 134 642 776 159 197 0.976 Atlanta Braves
## 3    4372 1512 134 642 776 159 197 0.976 Atlanta Braves
## 4    4372 1512 134 642 776 159 197 0.976 Atlanta Braves
## 5    4372 1512 134 642 776 159 197 0.976 Atlanta Braves
## 6    4372 1512 134 642 776 159 197 0.976 Atlanta Braves
## 7    4372 1512 134 642 776 159 197 0.976 Atlanta Braves
## 8    4372 1512 134 642 776 159 197 0.976 Atlanta Braves
## 9    4372 1512 134 642 776 159 197 0.976 Atlanta Braves
## 10   4372 1512 134 642 776 159 197 0.976 Atlanta Braves
##                             park attendance BPF PPF teamIDBR teamIDlahman45
## 1  Atlanta-Fulton County Stadium    1350137 105 106      ATL            ATL
## 2  Atlanta-Fulton County Stadium    1350137 105 106      ATL            ATL
## 3  Atlanta-Fulton County Stadium    1350137 105 106      ATL            ATL
## 4  Atlanta-Fulton County Stadium    1350137 105 106      ATL            ATL
## 5  Atlanta-Fulton County Stadium    1350137 105 106      ATL            ATL
## 6  Atlanta-Fulton County Stadium    1350137 105 106      ATL            ATL
## 7  Atlanta-Fulton County Stadium    1350137 105 106      ATL            ATL
## 8  Atlanta-Fulton County Stadium    1350137 105 106      ATL            ATL
## 9  Atlanta-Fulton County Stadium    1350137 105 106      ATL            ATL
## 10 Atlanta-Fulton County Stadium    1350137 105 106      ATL            ATL
##    teamIDretro  playerID salary
## 1          ATL barkele01 870000
## 2          ATL bedrost01 550000
## 3          ATL benedbr01 545000
## 4          ATL  campri01 633333
## 5          ATL ceronri01 625000
## 6          ATL chambch01 800000
## 7          ATL dedmoje01 150000
## 8          ATL forstte01 483333
## 9          ATL garbege01 772000
## 10         ATL harpete01 250000&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We could then use other &lt;code&gt;dplyr&lt;/code&gt; verbs to calculate the average salary for every team by year and plot these.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;team_salary %&amp;gt;%
  group_by(yearID, teamID) %&amp;gt;%
  summarise(avg_salary = mean(salary, na.rm = TRUE)) %&amp;gt;%
  ggplot(aes(x = yearID, y = avg_salary)) + 
  geom_line(size = 1) + 
  facet_wrap(~teamID)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## `summarise()` has grouped output by &amp;#39;yearID&amp;#39;. You can override using the
## `.groups` argument.&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://psqf6250.brandonlebeau.org/rcode/data_joins_files/figure-html/avg_salary-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Below is a diagram of the inner join found in the R for Data Science text, &lt;a href=&#34;https://r4ds.had.co.nz/relational-data.html#inner-join&#34;&gt;inner join diagram&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;left-join&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Left Join&lt;/h2&gt;
&lt;p&gt;This is by far the most common join I perform. Left join is more formally part of a group of operations called outer joins. Outer joins are useful when you want to use one data table as a base data set in which variables will be added to this data if the keys match. It is likely best shown with an example.&lt;/p&gt;
&lt;p&gt;Suppose we wish to add the salary information to the &lt;code&gt;Teams&lt;/code&gt; data. However, instead of using a &lt;code&gt;inner_join&lt;/code&gt;, let’s use &lt;code&gt;left_join&lt;/code&gt; to see the difference. &lt;em&gt;Note: I print only 10 rows of data with the &lt;code&gt;head()&lt;/code&gt; function. This part of the code below would generally not be used.&lt;/em&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;left_join(Teams, Salaries) %&amp;gt;%
  head(n = 10)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Joining, by = c(&amp;quot;yearID&amp;quot;, &amp;quot;lgID&amp;quot;, &amp;quot;teamID&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##    yearID lgID teamID franchID divID Rank  G Ghome  W  L DivWin WCWin LgWin
## 1    1871   NA    BS1      BNA  &amp;lt;NA&amp;gt;    3 31    NA 20 10   &amp;lt;NA&amp;gt;  &amp;lt;NA&amp;gt;     N
## 2    1871   NA    CH1      CNA  &amp;lt;NA&amp;gt;    2 28    NA 19  9   &amp;lt;NA&amp;gt;  &amp;lt;NA&amp;gt;     N
## 3    1871   NA    CL1      CFC  &amp;lt;NA&amp;gt;    8 29    NA 10 19   &amp;lt;NA&amp;gt;  &amp;lt;NA&amp;gt;     N
## 4    1871   NA    FW1      KEK  &amp;lt;NA&amp;gt;    7 19    NA  7 12   &amp;lt;NA&amp;gt;  &amp;lt;NA&amp;gt;     N
## 5    1871   NA    NY2      NNA  &amp;lt;NA&amp;gt;    5 33    NA 16 17   &amp;lt;NA&amp;gt;  &amp;lt;NA&amp;gt;     N
## 6    1871   NA    PH1      PNA  &amp;lt;NA&amp;gt;    1 28    NA 21  7   &amp;lt;NA&amp;gt;  &amp;lt;NA&amp;gt;     Y
## 7    1871   NA    RC1      ROK  &amp;lt;NA&amp;gt;    9 25    NA  4 21   &amp;lt;NA&amp;gt;  &amp;lt;NA&amp;gt;     N
## 8    1871   NA    TRO      TRO  &amp;lt;NA&amp;gt;    6 29    NA 13 15   &amp;lt;NA&amp;gt;  &amp;lt;NA&amp;gt;     N
## 9    1871   NA    WS3      OLY  &amp;lt;NA&amp;gt;    4 32    NA 15 15   &amp;lt;NA&amp;gt;  &amp;lt;NA&amp;gt;     N
## 10   1872   NA    BL1      BLC  &amp;lt;NA&amp;gt;    2 58    NA 35 19   &amp;lt;NA&amp;gt;  &amp;lt;NA&amp;gt;     N
##    WSWin   R   AB   H X2B X3B HR BB SO SB CS HBP SF  RA  ER  ERA CG SHO SV
## 1   &amp;lt;NA&amp;gt; 401 1372 426  70  37  3 60 19 73 16  NA NA 303 109 3.55 22   1  3
## 2   &amp;lt;NA&amp;gt; 302 1196 323  52  21 10 60 22 69 21  NA NA 241  77 2.76 25   0  1
## 3   &amp;lt;NA&amp;gt; 249 1186 328  35  40  7 26 25 18  8  NA NA 341 116 4.11 23   0  0
## 4   &amp;lt;NA&amp;gt; 137  746 178  19   8  2 33  9 16  4  NA NA 243  97 5.17 19   1  0
## 5   &amp;lt;NA&amp;gt; 302 1404 403  43  21  1 33 15 46 15  NA NA 313 121 3.72 32   1  0
## 6   &amp;lt;NA&amp;gt; 376 1281 410  66  27  9 46 23 56 12  NA NA 266 137 4.95 27   0  0
## 7   &amp;lt;NA&amp;gt; 231 1036 274  44  25  3 38 30 53 10  NA NA 287 108 4.30 23   1  0
## 8   &amp;lt;NA&amp;gt; 351 1248 384  51  34  6 49 19 62 24  NA NA 362 153 5.51 28   0  0
## 9   &amp;lt;NA&amp;gt; 310 1353 375  54  26  6 48 13 48 13  NA NA 303 137 4.37 32   0  0
## 10  &amp;lt;NA&amp;gt; 617 2571 753 106  31 14 29 28 53 18  NA NA 434 166 2.90 48   1  1
##    IPouts  HA HRA BBA SOA   E DP    FP                    name
## 1     828 367   2  42  23 243 24 0.834    Boston Red Stockings
## 2     753 308   6  28  22 229 16 0.829 Chicago White Stockings
## 3     762 346  13  53  34 234 15 0.818  Cleveland Forest Citys
## 4     507 261   5  21  17 163  8 0.803    Fort Wayne Kekiongas
## 5     879 373   7  42  22 235 14 0.840        New York Mutuals
## 6     747 329   3  53  16 194 13 0.845  Philadelphia Athletics
## 7     678 315   3  34  16 220 14 0.821   Rockford Forest Citys
## 8     750 431   4  75  12 198 22 0.845          Troy Haymakers
## 9     846 371   4  45  13 218 20 0.850     Washington Olympics
## 10   1548 573   3  63  77 432 22 0.830      Baltimore Canaries
##                                 park attendance BPF PPF teamIDBR teamIDlahman45
## 1                South End Grounds I         NA 103  98      BOS            BS1
## 2            Union Base-Ball Grounds         NA 104 102      CHI            CH1
## 3       National Association Grounds         NA  96 100      CLE            CL1
## 4                     Hamilton Field         NA 101 107      KEK            FW1
## 5           Union Grounds (Brooklyn)         NA  90  88      NYU            NY2
## 6           Jefferson Street Grounds         NA 102  98      ATH            PH1
## 7  Agricultural Society Fair Grounds         NA  97  99      ROK            RC1
## 8                 Haymakers&amp;#39; Grounds         NA 101 100      TRO            TRO
## 9                   Olympics Grounds         NA  94  98      OLY            WS3
## 10                    Newington Park         NA 106 102      BAL            BL1
##    teamIDretro playerID salary
## 1          BS1     &amp;lt;NA&amp;gt;     NA
## 2          CH1     &amp;lt;NA&amp;gt;     NA
## 3          CL1     &amp;lt;NA&amp;gt;     NA
## 4          FW1     &amp;lt;NA&amp;gt;     NA
## 5          NY2     &amp;lt;NA&amp;gt;     NA
## 6          PH1     &amp;lt;NA&amp;gt;     NA
## 7          RC1     &amp;lt;NA&amp;gt;     NA
## 8          TRO     &amp;lt;NA&amp;gt;     NA
## 9          WS3     &amp;lt;NA&amp;gt;     NA
## 10         BL1     &amp;lt;NA&amp;gt;     NA&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The first thing to notice is that now there are years in the yearID variable from before 1985, this was not the case in the above data joined using &lt;code&gt;inner_join&lt;/code&gt;. If you scroll over to explore variables to the right, there are missing values for the salary variable. What &lt;code&gt;left_join&lt;/code&gt; does when it doesn’t find a match in the table is to produce NA values, so all records within the joined data will be NA before 1985.&lt;/p&gt;
&lt;p&gt;This is the major difference between outer joins and inner joins. Outer joins will preserve data in the keyed data that do not match and NA values are returned for non-matching values. For inner joins, any keys that do not match are removed.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;right-join&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Right Join&lt;/h2&gt;
&lt;p&gt;A right join is similar to a left join, except the keyed table is the second one specified (the rightmost data). For example, if we wished for the salary information to be the keyed table, we could do that same specification as above, but use &lt;code&gt;right_join&lt;/code&gt; instead of &lt;code&gt;left_join&lt;/code&gt;. &lt;em&gt;Note: I print only 10 rows of data with the &lt;code&gt;head()&lt;/code&gt; function. This part of the code below would generally not be used.&lt;/em&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;right_join(Teams, Salaries) %&amp;gt;%
  head(n = 10)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Joining, by = c(&amp;quot;yearID&amp;quot;, &amp;quot;lgID&amp;quot;, &amp;quot;teamID&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##    yearID lgID teamID franchID divID Rank   G Ghome  W  L DivWin WCWin LgWin
## 1    1985   NL    ATL      ATL     W    5 162    81 66 96      N  &amp;lt;NA&amp;gt;     N
## 2    1985   NL    ATL      ATL     W    5 162    81 66 96      N  &amp;lt;NA&amp;gt;     N
## 3    1985   NL    ATL      ATL     W    5 162    81 66 96      N  &amp;lt;NA&amp;gt;     N
## 4    1985   NL    ATL      ATL     W    5 162    81 66 96      N  &amp;lt;NA&amp;gt;     N
## 5    1985   NL    ATL      ATL     W    5 162    81 66 96      N  &amp;lt;NA&amp;gt;     N
## 6    1985   NL    ATL      ATL     W    5 162    81 66 96      N  &amp;lt;NA&amp;gt;     N
## 7    1985   NL    ATL      ATL     W    5 162    81 66 96      N  &amp;lt;NA&amp;gt;     N
## 8    1985   NL    ATL      ATL     W    5 162    81 66 96      N  &amp;lt;NA&amp;gt;     N
## 9    1985   NL    ATL      ATL     W    5 162    81 66 96      N  &amp;lt;NA&amp;gt;     N
## 10   1985   NL    ATL      ATL     W    5 162    81 66 96      N  &amp;lt;NA&amp;gt;     N
##    WSWin   R   AB    H X2B X3B  HR  BB  SO SB CS HBP SF  RA  ER  ERA CG SHO SV
## 1      N 632 5526 1359 213  28 126 553 849 72 52  22 41 781 679 4.19  9   9 29
## 2      N 632 5526 1359 213  28 126 553 849 72 52  22 41 781 679 4.19  9   9 29
## 3      N 632 5526 1359 213  28 126 553 849 72 52  22 41 781 679 4.19  9   9 29
## 4      N 632 5526 1359 213  28 126 553 849 72 52  22 41 781 679 4.19  9   9 29
## 5      N 632 5526 1359 213  28 126 553 849 72 52  22 41 781 679 4.19  9   9 29
## 6      N 632 5526 1359 213  28 126 553 849 72 52  22 41 781 679 4.19  9   9 29
## 7      N 632 5526 1359 213  28 126 553 849 72 52  22 41 781 679 4.19  9   9 29
## 8      N 632 5526 1359 213  28 126 553 849 72 52  22 41 781 679 4.19  9   9 29
## 9      N 632 5526 1359 213  28 126 553 849 72 52  22 41 781 679 4.19  9   9 29
## 10     N 632 5526 1359 213  28 126 553 849 72 52  22 41 781 679 4.19  9   9 29
##    IPouts   HA HRA BBA SOA   E  DP    FP           name
## 1    4372 1512 134 642 776 159 197 0.976 Atlanta Braves
## 2    4372 1512 134 642 776 159 197 0.976 Atlanta Braves
## 3    4372 1512 134 642 776 159 197 0.976 Atlanta Braves
## 4    4372 1512 134 642 776 159 197 0.976 Atlanta Braves
## 5    4372 1512 134 642 776 159 197 0.976 Atlanta Braves
## 6    4372 1512 134 642 776 159 197 0.976 Atlanta Braves
## 7    4372 1512 134 642 776 159 197 0.976 Atlanta Braves
## 8    4372 1512 134 642 776 159 197 0.976 Atlanta Braves
## 9    4372 1512 134 642 776 159 197 0.976 Atlanta Braves
## 10   4372 1512 134 642 776 159 197 0.976 Atlanta Braves
##                             park attendance BPF PPF teamIDBR teamIDlahman45
## 1  Atlanta-Fulton County Stadium    1350137 105 106      ATL            ATL
## 2  Atlanta-Fulton County Stadium    1350137 105 106      ATL            ATL
## 3  Atlanta-Fulton County Stadium    1350137 105 106      ATL            ATL
## 4  Atlanta-Fulton County Stadium    1350137 105 106      ATL            ATL
## 5  Atlanta-Fulton County Stadium    1350137 105 106      ATL            ATL
## 6  Atlanta-Fulton County Stadium    1350137 105 106      ATL            ATL
## 7  Atlanta-Fulton County Stadium    1350137 105 106      ATL            ATL
## 8  Atlanta-Fulton County Stadium    1350137 105 106      ATL            ATL
## 9  Atlanta-Fulton County Stadium    1350137 105 106      ATL            ATL
## 10 Atlanta-Fulton County Stadium    1350137 105 106      ATL            ATL
##    teamIDretro  playerID salary
## 1          ATL barkele01 870000
## 2          ATL bedrost01 550000
## 3          ATL benedbr01 545000
## 4          ATL  campri01 633333
## 5          ATL ceronri01 625000
## 6          ATL chambch01 800000
## 7          ATL dedmoje01 150000
## 8          ATL forstte01 483333
## 9          ATL garbege01 772000
## 10         ATL harpete01 250000&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This data is very similar (although not identical) to the one from the inner join above. Can you spot what is different?&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;full-join&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Full Join&lt;/h2&gt;
&lt;p&gt;Full join is the last type of outer join and this will return all values from both tables and NAs will be given for those keys that do not match. For example,&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;full_join(Teams, Salaries) %&amp;gt;%
  head(n = 10)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Joining, by = c(&amp;quot;yearID&amp;quot;, &amp;quot;lgID&amp;quot;, &amp;quot;teamID&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##    yearID lgID teamID franchID divID Rank  G Ghome  W  L DivWin WCWin LgWin
## 1    1871   NA    BS1      BNA  &amp;lt;NA&amp;gt;    3 31    NA 20 10   &amp;lt;NA&amp;gt;  &amp;lt;NA&amp;gt;     N
## 2    1871   NA    CH1      CNA  &amp;lt;NA&amp;gt;    2 28    NA 19  9   &amp;lt;NA&amp;gt;  &amp;lt;NA&amp;gt;     N
## 3    1871   NA    CL1      CFC  &amp;lt;NA&amp;gt;    8 29    NA 10 19   &amp;lt;NA&amp;gt;  &amp;lt;NA&amp;gt;     N
## 4    1871   NA    FW1      KEK  &amp;lt;NA&amp;gt;    7 19    NA  7 12   &amp;lt;NA&amp;gt;  &amp;lt;NA&amp;gt;     N
## 5    1871   NA    NY2      NNA  &amp;lt;NA&amp;gt;    5 33    NA 16 17   &amp;lt;NA&amp;gt;  &amp;lt;NA&amp;gt;     N
## 6    1871   NA    PH1      PNA  &amp;lt;NA&amp;gt;    1 28    NA 21  7   &amp;lt;NA&amp;gt;  &amp;lt;NA&amp;gt;     Y
## 7    1871   NA    RC1      ROK  &amp;lt;NA&amp;gt;    9 25    NA  4 21   &amp;lt;NA&amp;gt;  &amp;lt;NA&amp;gt;     N
## 8    1871   NA    TRO      TRO  &amp;lt;NA&amp;gt;    6 29    NA 13 15   &amp;lt;NA&amp;gt;  &amp;lt;NA&amp;gt;     N
## 9    1871   NA    WS3      OLY  &amp;lt;NA&amp;gt;    4 32    NA 15 15   &amp;lt;NA&amp;gt;  &amp;lt;NA&amp;gt;     N
## 10   1872   NA    BL1      BLC  &amp;lt;NA&amp;gt;    2 58    NA 35 19   &amp;lt;NA&amp;gt;  &amp;lt;NA&amp;gt;     N
##    WSWin   R   AB   H X2B X3B HR BB SO SB CS HBP SF  RA  ER  ERA CG SHO SV
## 1   &amp;lt;NA&amp;gt; 401 1372 426  70  37  3 60 19 73 16  NA NA 303 109 3.55 22   1  3
## 2   &amp;lt;NA&amp;gt; 302 1196 323  52  21 10 60 22 69 21  NA NA 241  77 2.76 25   0  1
## 3   &amp;lt;NA&amp;gt; 249 1186 328  35  40  7 26 25 18  8  NA NA 341 116 4.11 23   0  0
## 4   &amp;lt;NA&amp;gt; 137  746 178  19   8  2 33  9 16  4  NA NA 243  97 5.17 19   1  0
## 5   &amp;lt;NA&amp;gt; 302 1404 403  43  21  1 33 15 46 15  NA NA 313 121 3.72 32   1  0
## 6   &amp;lt;NA&amp;gt; 376 1281 410  66  27  9 46 23 56 12  NA NA 266 137 4.95 27   0  0
## 7   &amp;lt;NA&amp;gt; 231 1036 274  44  25  3 38 30 53 10  NA NA 287 108 4.30 23   1  0
## 8   &amp;lt;NA&amp;gt; 351 1248 384  51  34  6 49 19 62 24  NA NA 362 153 5.51 28   0  0
## 9   &amp;lt;NA&amp;gt; 310 1353 375  54  26  6 48 13 48 13  NA NA 303 137 4.37 32   0  0
## 10  &amp;lt;NA&amp;gt; 617 2571 753 106  31 14 29 28 53 18  NA NA 434 166 2.90 48   1  1
##    IPouts  HA HRA BBA SOA   E DP    FP                    name
## 1     828 367   2  42  23 243 24 0.834    Boston Red Stockings
## 2     753 308   6  28  22 229 16 0.829 Chicago White Stockings
## 3     762 346  13  53  34 234 15 0.818  Cleveland Forest Citys
## 4     507 261   5  21  17 163  8 0.803    Fort Wayne Kekiongas
## 5     879 373   7  42  22 235 14 0.840        New York Mutuals
## 6     747 329   3  53  16 194 13 0.845  Philadelphia Athletics
## 7     678 315   3  34  16 220 14 0.821   Rockford Forest Citys
## 8     750 431   4  75  12 198 22 0.845          Troy Haymakers
## 9     846 371   4  45  13 218 20 0.850     Washington Olympics
## 10   1548 573   3  63  77 432 22 0.830      Baltimore Canaries
##                                 park attendance BPF PPF teamIDBR teamIDlahman45
## 1                South End Grounds I         NA 103  98      BOS            BS1
## 2            Union Base-Ball Grounds         NA 104 102      CHI            CH1
## 3       National Association Grounds         NA  96 100      CLE            CL1
## 4                     Hamilton Field         NA 101 107      KEK            FW1
## 5           Union Grounds (Brooklyn)         NA  90  88      NYU            NY2
## 6           Jefferson Street Grounds         NA 102  98      ATH            PH1
## 7  Agricultural Society Fair Grounds         NA  97  99      ROK            RC1
## 8                 Haymakers&amp;#39; Grounds         NA 101 100      TRO            TRO
## 9                   Olympics Grounds         NA  94  98      OLY            WS3
## 10                    Newington Park         NA 106 102      BAL            BL1
##    teamIDretro playerID salary
## 1          BS1     &amp;lt;NA&amp;gt;     NA
## 2          CH1     &amp;lt;NA&amp;gt;     NA
## 3          CL1     &amp;lt;NA&amp;gt;     NA
## 4          FW1     &amp;lt;NA&amp;gt;     NA
## 5          NY2     &amp;lt;NA&amp;gt;     NA
## 6          PH1     &amp;lt;NA&amp;gt;     NA
## 7          RC1     &amp;lt;NA&amp;gt;     NA
## 8          TRO     &amp;lt;NA&amp;gt;     NA
## 9          WS3     &amp;lt;NA&amp;gt;     NA
## 10         BL1     &amp;lt;NA&amp;gt;     NA&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;em&gt;Note: I print only 10 rows of data with the &lt;code&gt;head()&lt;/code&gt; function. This part of the code below would generally not be used.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;This data is very similar to the left join above, but not identical, can you tell the difference again?&lt;/p&gt;
&lt;p&gt;Below is a diagram of the differences between the three outer joins from the R for Data Science text, &lt;a href=&#34;https://r4ds.had.co.nz/relational-data.html#outer-join&#34;&gt;outer joins diagram&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;filtering-joins&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Filtering Joins&lt;/h2&gt;
&lt;p&gt;I tend to not use filtering joins, however, these are useful to connect summary data back to the original rows in the data. For example, using the &lt;code&gt;team_salary&lt;/code&gt; data created above, let’s select only the top 10 teams in terms of average salary from the year 2015.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;top_salary_15 &amp;lt;- team_salary %&amp;gt;%
  group_by(yearID, teamID) %&amp;gt;%
  summarise(avg_salary = mean(salary, na.rm = TRUE)) %&amp;gt;%
  filter(yearID == 2015) %&amp;gt;%
  arrange(desc(avg_salary)) %&amp;gt;%
  head(10)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## `summarise()` has grouped output by &amp;#39;yearID&amp;#39;. You can override using the
## `.groups` argument.&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;top_salary_15&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 10 × 3
## # Groups:   yearID [1]
##    yearID teamID avg_salary
##     &amp;lt;int&amp;gt; &amp;lt;fct&amp;gt;       &amp;lt;dbl&amp;gt;
##  1   2015 LAN      7441103.
##  2   2015 NYA      7336274.
##  3   2015 DET      6891390 
##  4   2015 SFN      6100056.
##  5   2015 BOS      5659481.
##  6   2015 WAS      5365085.
##  7   2015 SEA      4888348 
##  8   2015 TEX      4791426.
##  9   2015 SLN      4586212.
## 10   2015 SDN      4555435.&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Although not impossible, it would be a bit more difficult to connect these teams and years back to the original data in the &lt;code&gt;team_salary&lt;/code&gt; data. This can be done simply with a filtering join, namely a semi join.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;team_salary %&amp;gt;%
  semi_join(top_salary_15) %&amp;gt;%
  head(n = 10)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Joining, by = c(&amp;quot;yearID&amp;quot;, &amp;quot;teamID&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##    yearID lgID teamID franchID divID Rank   G Ghome  W  L DivWin WCWin LgWin
## 1    2015   AL    BOS      BOS     E    5 162    81 78 84      N     N     N
## 2    2015   AL    BOS      BOS     E    5 162    81 78 84      N     N     N
## 3    2015   AL    BOS      BOS     E    5 162    81 78 84      N     N     N
## 4    2015   AL    BOS      BOS     E    5 162    81 78 84      N     N     N
## 5    2015   AL    BOS      BOS     E    5 162    81 78 84      N     N     N
## 6    2015   AL    BOS      BOS     E    5 162    81 78 84      N     N     N
## 7    2015   AL    BOS      BOS     E    5 162    81 78 84      N     N     N
## 8    2015   AL    BOS      BOS     E    5 162    81 78 84      N     N     N
## 9    2015   AL    BOS      BOS     E    5 162    81 78 84      N     N     N
## 10   2015   AL    BOS      BOS     E    5 162    81 78 84      N     N     N
##    WSWin   R   AB    H X2B X3B  HR  BB   SO SB CS HBP SF  RA  ER  ERA CG SHO SV
## 1      N 748 5640 1495 294  33 161 478 1148 71 27  46 42 753 694 4.31  3  10 40
## 2      N 748 5640 1495 294  33 161 478 1148 71 27  46 42 753 694 4.31  3  10 40
## 3      N 748 5640 1495 294  33 161 478 1148 71 27  46 42 753 694 4.31  3  10 40
## 4      N 748 5640 1495 294  33 161 478 1148 71 27  46 42 753 694 4.31  3  10 40
## 5      N 748 5640 1495 294  33 161 478 1148 71 27  46 42 753 694 4.31  3  10 40
## 6      N 748 5640 1495 294  33 161 478 1148 71 27  46 42 753 694 4.31  3  10 40
## 7      N 748 5640 1495 294  33 161 478 1148 71 27  46 42 753 694 4.31  3  10 40
## 8      N 748 5640 1495 294  33 161 478 1148 71 27  46 42 753 694 4.31  3  10 40
## 9      N 748 5640 1495 294  33 161 478 1148 71 27  46 42 753 694 4.31  3  10 40
## 10     N 748 5640 1495 294  33 161 478 1148 71 27  46 42 753 694 4.31  3  10 40
##    IPouts   HA HRA BBA  SOA  E  DP    FP           name           park
## 1    4345 1486 178 478 1218 97 148 0.984 Boston Red Sox Fenway Park II
## 2    4345 1486 178 478 1218 97 148 0.984 Boston Red Sox Fenway Park II
## 3    4345 1486 178 478 1218 97 148 0.984 Boston Red Sox Fenway Park II
## 4    4345 1486 178 478 1218 97 148 0.984 Boston Red Sox Fenway Park II
## 5    4345 1486 178 478 1218 97 148 0.984 Boston Red Sox Fenway Park II
## 6    4345 1486 178 478 1218 97 148 0.984 Boston Red Sox Fenway Park II
## 7    4345 1486 178 478 1218 97 148 0.984 Boston Red Sox Fenway Park II
## 8    4345 1486 178 478 1218 97 148 0.984 Boston Red Sox Fenway Park II
## 9    4345 1486 178 478 1218 97 148 0.984 Boston Red Sox Fenway Park II
## 10   4345 1486 178 478 1218 97 148 0.984 Boston Red Sox Fenway Park II
##    attendance BPF PPF teamIDBR teamIDlahman45 teamIDretro  playerID   salary
## 1     2880694 104 107      BOS            BOS         BOS barnema01   508500
## 2     2880694 104 107      BOS            BOS         BOS bettsmo01   514500
## 3     2880694 104 107      BOS            BOS         BOS bogaexa01   543000
## 4     2880694 104 107      BOS            BOS         BOS bradlja02   528000
## 5     2880694 104 107      BOS            BOS         BOS breslcr01  2000000
## 6     2880694 104 107      BOS            BOS         BOS buchhcl01 12000000
## 7     2880694 104 107      BOS            BOS         BOS castiru01 11271000
## 8     2880694 104 107      BOS            BOS         BOS cecchga01   508500
## 9     2880694 104 107      BOS            BOS         BOS craigal01  5500000
## 10    2880694 104 107      BOS            BOS         BOS hanigry01  3500000&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;em&gt;Note: I print only 10 rows of data with the &lt;code&gt;head()&lt;/code&gt; function. This part of the code below would generally not be used.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;This operation selected only the rows that had the matching keys from the first table (note that the columns were not touched).&lt;/p&gt;
&lt;p&gt;The opposite operation is to use an anti join, in this type of join, the rows that do not match will be returned.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;team_salary %&amp;gt;%
  anti_join(top_salary_15) %&amp;gt;%
  head(n = 10)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Joining, by = c(&amp;quot;yearID&amp;quot;, &amp;quot;teamID&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##    yearID lgID teamID franchID divID Rank   G Ghome  W  L DivWin WCWin LgWin
## 1    1985   NL    ATL      ATL     W    5 162    81 66 96      N  &amp;lt;NA&amp;gt;     N
## 2    1985   NL    ATL      ATL     W    5 162    81 66 96      N  &amp;lt;NA&amp;gt;     N
## 3    1985   NL    ATL      ATL     W    5 162    81 66 96      N  &amp;lt;NA&amp;gt;     N
## 4    1985   NL    ATL      ATL     W    5 162    81 66 96      N  &amp;lt;NA&amp;gt;     N
## 5    1985   NL    ATL      ATL     W    5 162    81 66 96      N  &amp;lt;NA&amp;gt;     N
## 6    1985   NL    ATL      ATL     W    5 162    81 66 96      N  &amp;lt;NA&amp;gt;     N
## 7    1985   NL    ATL      ATL     W    5 162    81 66 96      N  &amp;lt;NA&amp;gt;     N
## 8    1985   NL    ATL      ATL     W    5 162    81 66 96      N  &amp;lt;NA&amp;gt;     N
## 9    1985   NL    ATL      ATL     W    5 162    81 66 96      N  &amp;lt;NA&amp;gt;     N
## 10   1985   NL    ATL      ATL     W    5 162    81 66 96      N  &amp;lt;NA&amp;gt;     N
##    WSWin   R   AB    H X2B X3B  HR  BB  SO SB CS HBP SF  RA  ER  ERA CG SHO SV
## 1      N 632 5526 1359 213  28 126 553 849 72 52  22 41 781 679 4.19  9   9 29
## 2      N 632 5526 1359 213  28 126 553 849 72 52  22 41 781 679 4.19  9   9 29
## 3      N 632 5526 1359 213  28 126 553 849 72 52  22 41 781 679 4.19  9   9 29
## 4      N 632 5526 1359 213  28 126 553 849 72 52  22 41 781 679 4.19  9   9 29
## 5      N 632 5526 1359 213  28 126 553 849 72 52  22 41 781 679 4.19  9   9 29
## 6      N 632 5526 1359 213  28 126 553 849 72 52  22 41 781 679 4.19  9   9 29
## 7      N 632 5526 1359 213  28 126 553 849 72 52  22 41 781 679 4.19  9   9 29
## 8      N 632 5526 1359 213  28 126 553 849 72 52  22 41 781 679 4.19  9   9 29
## 9      N 632 5526 1359 213  28 126 553 849 72 52  22 41 781 679 4.19  9   9 29
## 10     N 632 5526 1359 213  28 126 553 849 72 52  22 41 781 679 4.19  9   9 29
##    IPouts   HA HRA BBA SOA   E  DP    FP           name
## 1    4372 1512 134 642 776 159 197 0.976 Atlanta Braves
## 2    4372 1512 134 642 776 159 197 0.976 Atlanta Braves
## 3    4372 1512 134 642 776 159 197 0.976 Atlanta Braves
## 4    4372 1512 134 642 776 159 197 0.976 Atlanta Braves
## 5    4372 1512 134 642 776 159 197 0.976 Atlanta Braves
## 6    4372 1512 134 642 776 159 197 0.976 Atlanta Braves
## 7    4372 1512 134 642 776 159 197 0.976 Atlanta Braves
## 8    4372 1512 134 642 776 159 197 0.976 Atlanta Braves
## 9    4372 1512 134 642 776 159 197 0.976 Atlanta Braves
## 10   4372 1512 134 642 776 159 197 0.976 Atlanta Braves
##                             park attendance BPF PPF teamIDBR teamIDlahman45
## 1  Atlanta-Fulton County Stadium    1350137 105 106      ATL            ATL
## 2  Atlanta-Fulton County Stadium    1350137 105 106      ATL            ATL
## 3  Atlanta-Fulton County Stadium    1350137 105 106      ATL            ATL
## 4  Atlanta-Fulton County Stadium    1350137 105 106      ATL            ATL
## 5  Atlanta-Fulton County Stadium    1350137 105 106      ATL            ATL
## 6  Atlanta-Fulton County Stadium    1350137 105 106      ATL            ATL
## 7  Atlanta-Fulton County Stadium    1350137 105 106      ATL            ATL
## 8  Atlanta-Fulton County Stadium    1350137 105 106      ATL            ATL
## 9  Atlanta-Fulton County Stadium    1350137 105 106      ATL            ATL
## 10 Atlanta-Fulton County Stadium    1350137 105 106      ATL            ATL
##    teamIDretro  playerID salary
## 1          ATL barkele01 870000
## 2          ATL bedrost01 550000
## 3          ATL benedbr01 545000
## 4          ATL  campri01 633333
## 5          ATL ceronri01 625000
## 6          ATL chambch01 800000
## 7          ATL dedmoje01 150000
## 8          ATL forstte01 483333
## 9          ATL garbege01 772000
## 10         ATL harpete01 250000&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;em&gt;Note: I print only 10 rows of data with the &lt;code&gt;head()&lt;/code&gt; function. This part of the code below would generally not be used.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;The sum of the number of rows in these two tables should equal the number of rows from the entire &lt;code&gt;team_salary&lt;/code&gt; data table&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;anti_rows &amp;lt;- team_salary %&amp;gt;%
  anti_join(top_salary_15) %&amp;gt;%
  nrow()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Joining, by = c(&amp;quot;yearID&amp;quot;, &amp;quot;teamID&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;semi_rows &amp;lt;- team_salary %&amp;gt;%
  semi_join(top_salary_15) %&amp;gt;%
  nrow()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Joining, by = c(&amp;quot;yearID&amp;quot;, &amp;quot;teamID&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;anti_rows + semi_rows == nrow(team_salary)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] TRUE&lt;/code&gt;&lt;/pre&gt;
&lt;div id=&#34;exercises&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Exercises&lt;/h4&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;Using the &lt;code&gt;Teams&lt;/code&gt; and &lt;code&gt;Managers&lt;/code&gt; data, join the two tables and only keep the matching observations in both tables. Note, you may need to specify the column names directly you wish to join by. What happens to the columns that have the same names but are not keys?&lt;/li&gt;
&lt;li&gt;Using the same data tables from #1, add all the &lt;code&gt;Managers&lt;/code&gt; variables to the &lt;code&gt;Teams&lt;/code&gt; data while retaining all the rows for the &lt;code&gt;Teams&lt;/code&gt; data.&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Factors</title>
      <link>https://psqf6250.brandonlebeau.org/rcode/factors/</link>
      <pubDate>Fri, 26 Feb 2021 00:00:00 +0000</pubDate>
      <guid>https://psqf6250.brandonlebeau.org/rcode/factors/</guid>
      <description>
&lt;script src=&#34;https://psqf6250.brandonlebeau.org/rmarkdown-libs/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;

&lt;div id=&#34;TOC&#34;&gt;

&lt;/div&gt;

&lt;p&gt;To date I have ignored factor variables and how these are implemented in R. Much of this is due to the greater flexibility of character vectors instead of factors. Also, if using the &lt;code&gt;readr&lt;/code&gt; or &lt;code&gt;readxl&lt;/code&gt; packages to read in data, the variables are also read in as character strings instead of factors. However, there are situations when factors are useful. Most of these uses are for readability when creating output formats for a report or paper.&lt;/p&gt;
&lt;p&gt;This set of notes will make use of the following three packages:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(tidyverse)
library(forcats)
library(fivethirtyeight)&lt;/code&gt;&lt;/pre&gt;
&lt;div id=&#34;uses-for-factors&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Uses for Factors&lt;/h2&gt;
&lt;p&gt;To see a few of the benefits of a factor, assume we have a variable that represents the levels of a survey question with five possible responses and we only saw three of those response categories.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;resp &amp;lt;- c(&amp;#39;Disagree&amp;#39;, &amp;#39;Agree&amp;#39;, &amp;#39;Neutral&amp;#39;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This type of variable has a natural order, namely the disagree side of the scale (i.e. strongly disagree) to the agree side of the scale (i.e. strongly agree) with neutral belonging in the middle. However, if we sort this variable, this ordering will not be taken into account with a character string.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sort(resp)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;Agree&amp;quot;    &amp;quot;Disagree&amp;quot; &amp;quot;Neutral&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Notice, these are actually in alphabetical order, likely not what we wanted. This can be fixed by defining this variable as a factor with levels of the variable specified.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;scale_levels &amp;lt;- c(&amp;#39;Strongly Disagree&amp;#39;, &amp;#39;Disagree&amp;#39;, 
                  &amp;#39;Neutral&amp;#39;, &amp;#39;Agree&amp;#39;, &amp;#39;Strongly Agree&amp;#39;)
resp_fact &amp;lt;- factor(resp, levels = scale_levels)
resp_fact&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] Disagree Agree    Neutral 
## Levels: Strongly Disagree Disagree Neutral Agree Strongly Agree&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sort(resp_fact)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] Disagree Neutral  Agree   
## Levels: Strongly Disagree Disagree Neutral Agree Strongly Agree&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Another benefit, if values that are not found in the levels of the factor variable, these will be replaced with NAs. For example,&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;factor(c(&amp;#39;disagree&amp;#39;, &amp;#39;Agree&amp;#39;, &amp;#39;Strongly Agree&amp;#39;), 
       levels = scale_levels)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;lt;NA&amp;gt;           Agree          Strongly Agree
## Levels: Strongly Disagree Disagree Neutral Agree Strongly Agree&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We can also explore valid levels of a variables with the &lt;code&gt;levels&lt;/code&gt; function.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;levels(resp_fact)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;Strongly Disagree&amp;quot; &amp;quot;Disagree&amp;quot;          &amp;quot;Neutral&amp;quot;          
## [4] &amp;quot;Agree&amp;quot;             &amp;quot;Strongly Agree&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;div id=&#34;exercises&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Exercises&lt;/h4&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;How are factors stored internally by R? To explore this, use the &lt;code&gt;str&lt;/code&gt; function on a factor variable and see what it looks like?&lt;/li&gt;
&lt;li&gt;To further this idea from #1, what happens when you do each of the following commands? Why is this happening?&lt;/li&gt;
&lt;/ol&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;as.numeric(resp)
as.numeric(resp_fact)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;common-factor-manipulations&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Common Factor Manipulations&lt;/h2&gt;
&lt;p&gt;In addition to setting the levels of the variable, there are two common tasks useful with factors.&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;Reorder factor levels for plotting or table creation&lt;/li&gt;
&lt;li&gt;Change the levels of the factor (i.e. collapse levels)&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Examples of each of these will be given with the &lt;code&gt;weather_check&lt;/code&gt; data from the &lt;code&gt;fivethirtyeight&lt;/code&gt; package.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;weather_check&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 928 × 9
##    respondent_id ck_weather weather_source     weather_source_… ck_weather_watch
##            &amp;lt;dbl&amp;gt; &amp;lt;lgl&amp;gt;      &amp;lt;chr&amp;gt;              &amp;lt;chr&amp;gt;            &amp;lt;ord&amp;gt;           
##  1    3887201482 TRUE       The default weath… &amp;lt;NA&amp;gt;             Very likely     
##  2    3887159451 TRUE       The default weath… &amp;lt;NA&amp;gt;             Very likely     
##  3    3887152228 TRUE       The default weath… &amp;lt;NA&amp;gt;             Very likely     
##  4    3887145426 TRUE       The default weath… &amp;lt;NA&amp;gt;             Somewhat likely 
##  5    3887021873 TRUE       A specific websit… Iphone app       Very likely     
##  6    3886937140 TRUE       A specific websit… AccuWeather App  Somewhat likely 
##  7    3886923931 TRUE       The Weather Chann… &amp;lt;NA&amp;gt;             Very unlikely   
##  8    3886913587 TRUE       &amp;lt;NA&amp;gt;               &amp;lt;NA&amp;gt;             &amp;lt;NA&amp;gt;            
##  9    3886889048 TRUE       The Weather Chann… &amp;lt;NA&amp;gt;             Very likely     
## 10    3886848806 TRUE       The default weath… &amp;lt;NA&amp;gt;             Very likely     
## # … with 918 more rows, and 4 more variables: age &amp;lt;fct&amp;gt;, female &amp;lt;lgl&amp;gt;,
## #   hhold_income &amp;lt;ord&amp;gt;, region &amp;lt;chr&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;div id=&#34;reorder-factor-variables&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Reorder Factor Variables&lt;/h3&gt;
&lt;p&gt;To show examples of this operation, suppose we calculated the proportion of respondents that checked the weather daily by region of the country. We could use dplyr for this:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;prop_check_weather &amp;lt;- weather_check %&amp;gt;%
  group_by(region) %&amp;gt;%
  summarise(prop = mean(ck_weather))
prop_check_weather&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 10 × 2
##    region              prop
##    &amp;lt;chr&amp;gt;              &amp;lt;dbl&amp;gt;
##  1 East North Central 0.858
##  2 East South Central 0.927
##  3 Middle Atlantic    0.885
##  4 Mountain           0.792
##  5 New England        0.942
##  6 Pacific            0.697
##  7 South Atlantic     0.740
##  8 West North Central 0.815
##  9 West South Central 0.904
## 10 &amp;lt;NA&amp;gt;               0.548&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This would be a bit easier to view if we plotted this data:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(prop_check_weather, aes(prop, region)) + 
  geom_point()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://psqf6250.brandonlebeau.org/rcode/factors_files/figure-html/prop_weather-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;This plot is difficult to read, primarily due to the way the points are ordered. Showing the regions in alphabetical order makes it more difficult to discern the trend. Instead, we would likely wish to reorder this variable by the ascending order of the proportion that check the weather. We will use the &lt;code&gt;fct_reorder&lt;/code&gt; function from the &lt;code&gt;forcats&lt;/code&gt; package. Note, I also omit the NA category here.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(na.omit(prop_check_weather), 
       aes(prop, fct_reorder(region, prop))) + 
  geom_point()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://psqf6250.brandonlebeau.org/rcode/factors_files/figure-html/prop_weather_reorder-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Need to be a bit careful with this operation however. For example:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;weather_check %&amp;gt;%
  group_by(hhold_income) %&amp;gt;%
  summarise(prop = mean(ck_weather)) %&amp;gt;%
  na.omit() %&amp;gt;%
  ggplot(aes(prop, fct_reorder(hhold_income, prop))) + 
  geom_point()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://psqf6250.brandonlebeau.org/rcode/factors_files/figure-html/reorder_income-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Instead, this is the proper way to show this relationship:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;weather_check %&amp;gt;%
  group_by(hhold_income) %&amp;gt;%
  summarise(prop = mean(ck_weather)) %&amp;gt;%
  na.omit() %&amp;gt;%
  ggplot(aes(prop, hhold_income)) + 
  geom_point()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://psqf6250.brandonlebeau.org/rcode/factors_files/figure-html/income-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;div id=&#34;exercises-1&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Exercises&lt;/h4&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;Using data from the &lt;code&gt;fivethirtyeight&lt;/code&gt; package called &lt;code&gt;flying&lt;/code&gt;, explore the proportion of respondents that believe the reclining the chair while flying should be eliminated (the variable is recline_eliminate).&lt;/li&gt;
&lt;li&gt;Do these proportions differ by the location?&lt;/li&gt;
&lt;li&gt;Create a graphic that captures this relationship, you may wish to reorder the columns to more appropriately represent the relationship.&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;rename-factor-levels&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Rename Factor Levels&lt;/h3&gt;
&lt;p&gt;These operations are useful to collapse categories or rename levels for publication. The primary function we will use for this operation is &lt;code&gt;fct_recode&lt;/code&gt; from the &lt;code&gt;forcats&lt;/code&gt; package.&lt;/p&gt;
&lt;p&gt;Again, using the &lt;code&gt;weather_check&lt;/code&gt; data, suppose we wished to change the levels of the age variable. The levels currently are:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;levels(weather_check$age)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;18 - 29&amp;quot; &amp;quot;30 - 44&amp;quot; &amp;quot;45 - 59&amp;quot; &amp;quot;60+&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Suppose we wished to better represent these as words. We can use this with &lt;code&gt;mutate&lt;/code&gt; from dplyr combined with &lt;code&gt;fct_recode&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;weather_check %&amp;gt;%
  mutate(age_recode = fct_recode(age,
      &amp;#39;18 to 29&amp;#39; = &amp;#39;18 - 29&amp;#39;,
      &amp;#39;30 to 44&amp;#39; = &amp;#39;30 - 44&amp;#39;,
      &amp;#39;45 to 59&amp;#39; = &amp;#39;45 - 59&amp;#39;
  )) %&amp;gt;%
  count(age_recode)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 5 × 2
##   age_recode     n
##   &amp;lt;fct&amp;gt;      &amp;lt;int&amp;gt;
## 1 18 to 29     176
## 2 30 to 44     204
## 3 45 to 59     278
## 4 60+          258
## 5 &amp;lt;NA&amp;gt;          12&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We could also collapse categories by assigning many levels to the same new level. For example, suppose we wished to collapse the ck_weather_watch variable to unlikely and likely instead of the very unlikely to very likely.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;levels(weather_check$ck_weather_watch)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;Very unlikely&amp;quot;     &amp;quot;Somewhat unlikely&amp;quot; &amp;quot;Somewhat likely&amp;quot;  
## [4] &amp;quot;Very likely&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;weather_check %&amp;gt;%
  mutate(watch_recode = fct_recode(ck_weather_watch,
         &amp;#39;Unlikely&amp;#39; = &amp;#39;Very unlikely&amp;#39;,
         &amp;#39;Unlikely&amp;#39; = &amp;#39;Somewhat unlikely&amp;#39;,
         &amp;#39;Likely&amp;#39; = &amp;#39;Somewhat likely&amp;#39;,
         &amp;#39;Likely&amp;#39; = &amp;#39;Very likely&amp;#39;
  )) %&amp;gt;%
  count(watch_recode)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 3 × 2
##   watch_recode     n
##   &amp;lt;ord&amp;gt;        &amp;lt;int&amp;gt;
## 1 Unlikely       281
## 2 Likely         636
## 3 &amp;lt;NA&amp;gt;            11&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Finally, one last option that may be useful is to lump together categories that are too small to report independently. This functionality is implemented with the function &lt;code&gt;fct_lump&lt;/code&gt;. For example, suppose we want to lump the region variable together to have only 5 regions.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;weather_check %&amp;gt;%
  mutate(region = fct_lump(region, n = 5)) %&amp;gt;%
  count(region, sort = TRUE)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 7 × 2
##   region                 n
##   &amp;lt;fct&amp;gt;              &amp;lt;int&amp;gt;
## 1 Other                219
## 2 Pacific              185
## 3 South Atlantic       154
## 4 East North Central   141
## 5 Middle Atlantic      104
## 6 West South Central    94
## 7 &amp;lt;NA&amp;gt;                  31&lt;/code&gt;&lt;/pre&gt;
&lt;div id=&#34;exercises-2&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Exercises&lt;/h4&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;Again, using the &lt;code&gt;flying&lt;/code&gt; data from the &lt;code&gt;fivethirtyeight&lt;/code&gt; package, is there a relationship between the proportion of respondents who have a children under 18 years old and if they believe it is rude to bring a baby on a plane? For this question, collapse the baby variable to two levels, no and yes.&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Working with Character Strings</title>
      <link>https://psqf6250.brandonlebeau.org/rcode/strings/</link>
      <pubDate>Fri, 26 Feb 2021 00:00:00 +0000</pubDate>
      <guid>https://psqf6250.brandonlebeau.org/rcode/strings/</guid>
      <description>
&lt;script src=&#34;https://psqf6250.brandonlebeau.org/rmarkdown-libs/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;
&lt;script src=&#34;https://psqf6250.brandonlebeau.org/rmarkdown-libs/htmlwidgets/htmlwidgets.js&#34;&gt;&lt;/script&gt;
&lt;link href=&#34;https://psqf6250.brandonlebeau.org/rmarkdown-libs/str_view/str_view.css&#34; rel=&#34;stylesheet&#34; /&gt;
&lt;script src=&#34;https://psqf6250.brandonlebeau.org/rmarkdown-libs/str_view-binding/str_view.js&#34;&gt;&lt;/script&gt;

&lt;div id=&#34;TOC&#34;&gt;

&lt;/div&gt;

&lt;p&gt;An often useful task is to manipulate character string variables. This usually comes in the form of regular expressions. Regular expressions come as a part of the base R, however, the regular expressions found in the &lt;code&gt;stringr&lt;/code&gt; package are a bit more consistent in their naming structure, so we will use them (they are simply wrappers around the base R regular expressions).&lt;/p&gt;
&lt;p&gt;The following packages will be used in this section of notes.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(tidyverse)
# install.packages(&amp;quot;stringr&amp;quot;)
library(stringr)&lt;/code&gt;&lt;/pre&gt;
&lt;div id=&#34;basic-string-tasks&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Basic String Tasks&lt;/h2&gt;
&lt;p&gt;This section will discuss three basic string functions that help with simple string manipulations. These functions include: &lt;code&gt;str_length&lt;/code&gt;, &lt;code&gt;str_c&lt;/code&gt;, and &lt;code&gt;str_sub&lt;/code&gt;.&lt;/p&gt;
&lt;div id=&#34;str_length&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;&lt;code&gt;str_length&lt;/code&gt;&lt;/h3&gt;
&lt;p&gt;The &lt;code&gt;str_length&lt;/code&gt; function can be used to calculate the length of the string. For example:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;string &amp;lt;- c(&amp;#39;Iowa City&amp;#39;, &amp;#39;Cedar Rapids&amp;#39;, &amp;#39;Des Moines&amp;#39;, &amp;#39;IA&amp;#39;)
str_length(string)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1]  9 12 10  2&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;str_c&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;&lt;code&gt;str_c&lt;/code&gt;&lt;/h3&gt;
&lt;p&gt;The &lt;code&gt;str_c&lt;/code&gt; function allows you to combine strings together in different ways. One way to think about this is to think about pasting strings together. For example:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;str_c(&amp;#39;Iowa City&amp;#39;, &amp;#39;Cedar Rapids&amp;#39;, &amp;#39;Des Moines&amp;#39;, &amp;#39;IA&amp;#39;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;Iowa CityCedar RapidsDes MoinesIA&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Perhaps more useful:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;str_c(c(&amp;#39;Iowa City&amp;#39;, &amp;#39;Cedar Rapids&amp;#39;, &amp;#39;Des Moines&amp;#39;), &amp;#39;IA&amp;#39;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;Iowa CityIA&amp;quot;    &amp;quot;Cedar RapidsIA&amp;quot; &amp;quot;Des MoinesIA&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;More useful yet:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;str_c(c(&amp;#39;Iowa City&amp;#39;, &amp;#39;Cedar Rapids&amp;#39;, &amp;#39;Des Moines&amp;#39;), &amp;#39;IA&amp;#39;, sep = &amp;#39;, &amp;#39;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;Iowa City, IA&amp;quot;    &amp;quot;Cedar Rapids, IA&amp;quot; &amp;quot;Des Moines, IA&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;You can also collapse multiple vectors of strings into a single string using the collapse argument.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;str_c(c(&amp;#39;Iowa City&amp;#39;, &amp;#39;Cedar Rapids&amp;#39;, &amp;#39;Des Moines&amp;#39;), collapse = &amp;#39;, &amp;#39;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;Iowa City, Cedar Rapids, Des Moines&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;str_sub&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;&lt;code&gt;str_sub&lt;/code&gt;&lt;/h3&gt;
&lt;p&gt;The &lt;code&gt;str_sub&lt;/code&gt; function is useful for subsetting strings by location. For example:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;str_sub(c(&amp;#39;Iowa City&amp;#39;, &amp;#39;Cedar Rapids&amp;#39;, &amp;#39;Des Moines&amp;#39;), 1, 4)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;Iowa&amp;quot; &amp;quot;Ceda&amp;quot; &amp;quot;Des &amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;You can use negative numbers to start from the end:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;str_sub(c(&amp;#39;Iowa City&amp;#39;, &amp;#39;Cedar Rapids&amp;#39;, &amp;#39;Des Moines&amp;#39;), -6, -1)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;a City&amp;quot; &amp;quot;Rapids&amp;quot; &amp;quot;Moines&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;regular-expressions&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Regular Expressions&lt;/h2&gt;
&lt;p&gt;Regular expressions are complicated and take awhile to master. This introduction is just going to cover the surface to get you started. To see the basics of regular expressions, we are going to use the &lt;code&gt;str_view&lt;/code&gt; function to view text matches.&lt;/p&gt;
&lt;p&gt;The most basic regular expression is simply to match literal text. For example:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;x &amp;lt;- c(&amp;#39;Iowa City&amp;#39;, &amp;#39;Cedar Rapids&amp;#39;, &amp;#39;Des Moines&amp;#39;)
str_view(x, &amp;#39;City&amp;#39;)&lt;/code&gt;&lt;/pre&gt;
&lt;div id=&#34;htmlwidget-1&#34; style=&#34;width:960px;height:100%;&#34; class=&#34;str_view html-widget&#34;&gt;&lt;/div&gt;
&lt;script type=&#34;application/json&#34; data-for=&#34;htmlwidget-1&#34;&gt;{&#34;x&#34;:{&#34;html&#34;:&#34;&lt;ul&gt;\n  &lt;li&gt;Iowa &lt;span class=&#39;match&#39;&gt;City&lt;\/span&gt;&lt;\/li&gt;\n  &lt;li&gt;Cedar Rapids&lt;\/li&gt;\n  &lt;li&gt;Des Moines&lt;\/li&gt;\n&lt;\/ul&gt;&#34;},&#34;evals&#34;:[],&#34;jsHooks&#34;:[]}&lt;/script&gt;
&lt;p&gt;Note that generally, regular expressions are case sensitive.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;str_view(x, &amp;#39;city&amp;#39;)&lt;/code&gt;&lt;/pre&gt;
&lt;div id=&#34;htmlwidget-2&#34; style=&#34;width:960px;height:100%;&#34; class=&#34;str_view html-widget&#34;&gt;&lt;/div&gt;
&lt;script type=&#34;application/json&#34; data-for=&#34;htmlwidget-2&#34;&gt;{&#34;x&#34;:{&#34;html&#34;:&#34;&lt;ul&gt;\n  &lt;li&gt;Iowa City&lt;\/li&gt;\n  &lt;li&gt;Cedar Rapids&lt;\/li&gt;\n  &lt;li&gt;Des Moines&lt;\/li&gt;\n&lt;\/ul&gt;&#34;},&#34;evals&#34;:[],&#34;jsHooks&#34;:[]}&lt;/script&gt;
&lt;p&gt;If you want the expression to ignore case, use the &lt;code&gt;ignore_case&lt;/code&gt; argument in tandem with &lt;code&gt;regex&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;str_view(x, regex(&amp;#39;city&amp;#39;, ignore_case = TRUE))&lt;/code&gt;&lt;/pre&gt;
&lt;div id=&#34;htmlwidget-3&#34; style=&#34;width:960px;height:100%;&#34; class=&#34;str_view html-widget&#34;&gt;&lt;/div&gt;
&lt;script type=&#34;application/json&#34; data-for=&#34;htmlwidget-3&#34;&gt;{&#34;x&#34;:{&#34;html&#34;:&#34;&lt;ul&gt;\n  &lt;li&gt;Iowa &lt;span class=&#39;match&#39;&gt;City&lt;\/span&gt;&lt;\/li&gt;\n  &lt;li&gt;Cedar Rapids&lt;\/li&gt;\n  &lt;li&gt;Des Moines&lt;\/li&gt;\n&lt;\/ul&gt;&#34;},&#34;evals&#34;:[],&#34;jsHooks&#34;:[]}&lt;/script&gt;
&lt;p&gt;Two other useful regular expression tools are anchoring and repeating patterns. First, anchor refers to whether the match should occur anywhere (the default), match at the beginning of the string, or match at the end of the string. To match at the start of the string:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;x &amp;lt;- c(&amp;#39;Iowa City&amp;#39;, &amp;#39;Des Moines, Iowa&amp;#39;)
str_view(x, &amp;#39;^Iowa&amp;#39;)&lt;/code&gt;&lt;/pre&gt;
&lt;div id=&#34;htmlwidget-4&#34; style=&#34;width:960px;height:100%;&#34; class=&#34;str_view html-widget&#34;&gt;&lt;/div&gt;
&lt;script type=&#34;application/json&#34; data-for=&#34;htmlwidget-4&#34;&gt;{&#34;x&#34;:{&#34;html&#34;:&#34;&lt;ul&gt;\n  &lt;li&gt;&lt;span class=&#39;match&#39;&gt;Iowa&lt;\/span&gt; City&lt;\/li&gt;\n  &lt;li&gt;Des Moines, Iowa&lt;\/li&gt;\n&lt;\/ul&gt;&#34;},&#34;evals&#34;:[],&#34;jsHooks&#34;:[]}&lt;/script&gt;
&lt;p&gt;Or to match at the end of a string:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;str_view(x, &amp;#39;Iowa$&amp;#39;)&lt;/code&gt;&lt;/pre&gt;
&lt;div id=&#34;htmlwidget-5&#34; style=&#34;width:960px;height:100%;&#34; class=&#34;str_view html-widget&#34;&gt;&lt;/div&gt;
&lt;script type=&#34;application/json&#34; data-for=&#34;htmlwidget-5&#34;&gt;{&#34;x&#34;:{&#34;html&#34;:&#34;&lt;ul&gt;\n  &lt;li&gt;Iowa City&lt;\/li&gt;\n  &lt;li&gt;Des Moines, &lt;span class=&#39;match&#39;&gt;Iowa&lt;\/span&gt;&lt;\/li&gt;\n&lt;\/ul&gt;&#34;},&#34;evals&#34;:[],&#34;jsHooks&#34;:[]}&lt;/script&gt;
&lt;p&gt;There are three operators that are useful for matching repetitious strings.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;?&lt;/code&gt; 0 or 1 match&lt;/li&gt;
&lt;li&gt;&lt;code&gt;+&lt;/code&gt; 1 or more&lt;/li&gt;
&lt;li&gt;&lt;code&gt;*&lt;/code&gt; 0 or more&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Examples of these are given below:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sounds &amp;lt;- c(&amp;#39;baaaa&amp;#39;, &amp;#39;ssss&amp;#39;, &amp;#39;moo&amp;#39;, &amp;#39;buzz&amp;#39;, &amp;#39;purr&amp;#39;)
str_view(sounds, &amp;#39;a?&amp;#39;)&lt;/code&gt;&lt;/pre&gt;
&lt;div id=&#34;htmlwidget-6&#34; style=&#34;width:960px;height:100%;&#34; class=&#34;str_view html-widget&#34;&gt;&lt;/div&gt;
&lt;script type=&#34;application/json&#34; data-for=&#34;htmlwidget-6&#34;&gt;{&#34;x&#34;:{&#34;html&#34;:&#34;&lt;ul&gt;\n  &lt;li&gt;&lt;span class=&#39;match&#39;&gt;&lt;\/span&gt;baaaa&lt;\/li&gt;\n  &lt;li&gt;&lt;span class=&#39;match&#39;&gt;&lt;\/span&gt;ssss&lt;\/li&gt;\n  &lt;li&gt;&lt;span class=&#39;match&#39;&gt;&lt;\/span&gt;moo&lt;\/li&gt;\n  &lt;li&gt;&lt;span class=&#39;match&#39;&gt;&lt;\/span&gt;buzz&lt;\/li&gt;\n  &lt;li&gt;&lt;span class=&#39;match&#39;&gt;&lt;\/span&gt;purr&lt;\/li&gt;\n&lt;\/ul&gt;&#34;},&#34;evals&#34;:[],&#34;jsHooks&#34;:[]}&lt;/script&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;str_view(sounds, &amp;#39;a+&amp;#39;)&lt;/code&gt;&lt;/pre&gt;
&lt;div id=&#34;htmlwidget-7&#34; style=&#34;width:960px;height:100%;&#34; class=&#34;str_view html-widget&#34;&gt;&lt;/div&gt;
&lt;script type=&#34;application/json&#34; data-for=&#34;htmlwidget-7&#34;&gt;{&#34;x&#34;:{&#34;html&#34;:&#34;&lt;ul&gt;\n  &lt;li&gt;b&lt;span class=&#39;match&#39;&gt;aaaa&lt;\/span&gt;&lt;\/li&gt;\n  &lt;li&gt;ssss&lt;\/li&gt;\n  &lt;li&gt;moo&lt;\/li&gt;\n  &lt;li&gt;buzz&lt;\/li&gt;\n  &lt;li&gt;purr&lt;\/li&gt;\n&lt;\/ul&gt;&#34;},&#34;evals&#34;:[],&#34;jsHooks&#34;:[]}&lt;/script&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;str_view(sounds, &amp;#39;rrr*&amp;#39;)&lt;/code&gt;&lt;/pre&gt;
&lt;div id=&#34;htmlwidget-8&#34; style=&#34;width:960px;height:100%;&#34; class=&#34;str_view html-widget&#34;&gt;&lt;/div&gt;
&lt;script type=&#34;application/json&#34; data-for=&#34;htmlwidget-8&#34;&gt;{&#34;x&#34;:{&#34;html&#34;:&#34;&lt;ul&gt;\n  &lt;li&gt;baaaa&lt;\/li&gt;\n  &lt;li&gt;ssss&lt;\/li&gt;\n  &lt;li&gt;moo&lt;\/li&gt;\n  &lt;li&gt;buzz&lt;\/li&gt;\n  &lt;li&gt;pu&lt;span class=&#39;match&#39;&gt;rr&lt;\/span&gt;&lt;\/li&gt;\n&lt;\/ul&gt;&#34;},&#34;evals&#34;:[],&#34;jsHooks&#34;:[]}&lt;/script&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;str_view(sounds, &amp;#39;rrr+&amp;#39;)&lt;/code&gt;&lt;/pre&gt;
&lt;div id=&#34;htmlwidget-9&#34; style=&#34;width:960px;height:100%;&#34; class=&#34;str_view html-widget&#34;&gt;&lt;/div&gt;
&lt;script type=&#34;application/json&#34; data-for=&#34;htmlwidget-9&#34;&gt;{&#34;x&#34;:{&#34;html&#34;:&#34;&lt;ul&gt;\n  &lt;li&gt;baaaa&lt;\/li&gt;\n  &lt;li&gt;ssss&lt;\/li&gt;\n  &lt;li&gt;moo&lt;\/li&gt;\n  &lt;li&gt;buzz&lt;\/li&gt;\n  &lt;li&gt;purr&lt;\/li&gt;\n&lt;\/ul&gt;&#34;},&#34;evals&#34;:[],&#34;jsHooks&#34;:[]}&lt;/script&gt;
&lt;p&gt;There are additional repetition operators using braces, &lt;code&gt;{}&lt;/code&gt; that can be useful.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;{n}&lt;/code&gt; match exactly n&lt;/li&gt;
&lt;li&gt;&lt;code&gt;{n, }&lt;/code&gt; match n or more&lt;/li&gt;
&lt;li&gt;&lt;code&gt;{, m}&lt;/code&gt; match at most m&lt;/li&gt;
&lt;li&gt;&lt;code&gt;{n, m}&lt;/code&gt; match between n and m&lt;/li&gt;
&lt;/ul&gt;
&lt;div id=&#34;exercises&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Exercises&lt;/h4&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;Using the &lt;code&gt;str_view&lt;/code&gt; function and the sounds object created above, rewrite this regular expression using braces: &lt;code&gt;str_view(sounds, &#39;rrr*&#39;)&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;Explore the &lt;code&gt;str_trim&lt;/code&gt; function. What does this do? Test this function on the following string: &lt;code&gt;string &amp;lt;- &#34;\n\nString with trailing and leading white space\n\n&#34;&lt;/code&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;regular-expression-functions&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Regular Expression Functions&lt;/h2&gt;
&lt;p&gt;So far we have just visualized the regular expression match. This is useful for testing, however, commonly we would like to create a new variable based on information processed from text strings. The tools we will explore are: &lt;code&gt;str_detect&lt;/code&gt;, &lt;code&gt;str_count&lt;/code&gt;, &lt;code&gt;str_extract&lt;/code&gt;, &lt;code&gt;str_replace&lt;/code&gt;, and &lt;code&gt;str_split&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Suppose we have the following string:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;x &amp;lt;- c(&amp;#39;Iowa City, Iowa&amp;#39;, &amp;#39;Cedar Rapids, IA&amp;#39;, &amp;#39;Des Moines, Iowa&amp;#39;, &amp;#39;Waterloo, IA&amp;#39;, &amp;#39;Rochester, Minnesota&amp;#39;)
x&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;Iowa City, Iowa&amp;quot;      &amp;quot;Cedar Rapids, IA&amp;quot;     &amp;quot;Des Moines, Iowa&amp;quot;    
## [4] &amp;quot;Waterloo, IA&amp;quot;         &amp;quot;Rochester, Minnesota&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Supose we were interested in knowing which cities are from Iowa in this text string, the &lt;code&gt;str_detect&lt;/code&gt; function is useful for this.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;str_detect(x, &amp;#39;Iowa$&amp;#39;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1]  TRUE FALSE  TRUE FALSE FALSE&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This didn’t return all the correct matches due to formatting differences. There are two options to fix this. First, we could search for two strings:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;str_detect(x, &amp;#39;Iowa$|IA$&amp;#39;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1]  TRUE  TRUE  TRUE  TRUE FALSE&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We could then calculate the proportion of cities in the string directly:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;mean(str_detect(x, &amp;#39;Iowa$|IA$&amp;#39;))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.8&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Another useful related function to &lt;code&gt;str_detect&lt;/code&gt; is &lt;code&gt;str_count&lt;/code&gt; which instead of TRUE/FALSE, will tell you how many matches are in each string.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;str_count(x, &amp;#39;Iowa$|IA$&amp;#39;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 1 1 1 1 0&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;There are instances where you will need to be careful with this function as it will calculate number of matches.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;str_count(x, &amp;#39;Iowa|IA&amp;#39;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 2 1 1 1 0&lt;/code&gt;&lt;/pre&gt;
&lt;div id=&#34;replace-text&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Replace Text&lt;/h3&gt;
&lt;p&gt;Above we solved the different formatting differences by searching for two text strings. This can be useful for a few different strings, however, for more complex searches, it can be useful to standardize the text to be the same across variables. This is the job for &lt;code&gt;str_replace&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;str_replace(x, &amp;#39;Iowa$&amp;#39;, &amp;#39;IA&amp;#39;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;Iowa City, IA&amp;quot;        &amp;quot;Cedar Rapids, IA&amp;quot;     &amp;quot;Des Moines, IA&amp;quot;      
## [4] &amp;quot;Waterloo, IA&amp;quot;         &amp;quot;Rochester, Minnesota&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This function takes two arguments, first the text to be matched and second the text the match should be changed to. If there are no matches the text is not changed. You need to be careful with this function too:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;str_replace(x, &amp;#39;Iowa&amp;#39;, &amp;#39;IA&amp;#39;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;IA City, Iowa&amp;quot;        &amp;quot;Cedar Rapids, IA&amp;quot;     &amp;quot;Des Moines, IA&amp;quot;      
## [4] &amp;quot;Waterloo, IA&amp;quot;         &amp;quot;Rochester, Minnesota&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;By default, the function will only replace the first match. If you’d like to replace all matches you need to use the &lt;code&gt;str_replace_all&lt;/code&gt; function.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;str_replace_all(x, &amp;#39;Iowa&amp;#39;, &amp;#39;IA&amp;#39;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;IA City, IA&amp;quot;          &amp;quot;Cedar Rapids, IA&amp;quot;     &amp;quot;Des Moines, IA&amp;quot;      
## [4] &amp;quot;Waterloo, IA&amp;quot;         &amp;quot;Rochester, Minnesota&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This operation is not useful here, but there are many places that this is a useful operation.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;extract-text&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Extract Text&lt;/h3&gt;
&lt;p&gt;If you wished to extract text instead of replacing text, &lt;code&gt;str_extract&lt;/code&gt; is useful for this. For example, if we wished to extract the Minnesota:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;str_extract(x, &amp;#39;Minnesota&amp;#39;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] NA          NA          NA          NA          &amp;quot;Minnesota&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;You can build more complicated expressions using the &lt;code&gt;str_extract&lt;/code&gt; function. For example, suppose we wished to extract only the city name.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;str_extract(x, &amp;#39;^.*,&amp;#39;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;Iowa City,&amp;quot;    &amp;quot;Cedar Rapids,&amp;quot; &amp;quot;Des Moines,&amp;quot;   &amp;quot;Waterloo,&amp;quot;    
## [5] &amp;quot;Rochester,&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This included the comma as well which may not be desired, we will show another way to achieve the same operation with the &lt;code&gt;str_split&lt;/code&gt; function. One quick note about the above operation, I used a &lt;code&gt;.&lt;/code&gt;. The &lt;code&gt;.&lt;/code&gt; means to match any character (except a new line character). To match a literal &lt;code&gt;.&lt;/code&gt;, you would need to escape this with &lt;code&gt;\\.&lt;/code&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;split-on-delimiter&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Split on Delimiter&lt;/h3&gt;
&lt;p&gt;If you’d like to split a string based on a common delimiter, using the &lt;code&gt;str_split&lt;/code&gt; function is useful. For example, if we wished to split the city from the state:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;str_split(x, &amp;#39;, &amp;#39;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [[1]]
## [1] &amp;quot;Iowa City&amp;quot; &amp;quot;Iowa&amp;quot;     
## 
## [[2]]
## [1] &amp;quot;Cedar Rapids&amp;quot; &amp;quot;IA&amp;quot;          
## 
## [[3]]
## [1] &amp;quot;Des Moines&amp;quot; &amp;quot;Iowa&amp;quot;      
## 
## [[4]]
## [1] &amp;quot;Waterloo&amp;quot; &amp;quot;IA&amp;quot;      
## 
## [[5]]
## [1] &amp;quot;Rochester&amp;quot; &amp;quot;Minnesota&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The &lt;code&gt;str_split&lt;/code&gt; function will remove the delimiter that it used to split on. The function also allows you to simplify the structure:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;str_split(x, &amp;#39;, &amp;#39;, simplify = TRUE)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##      [,1]           [,2]       
## [1,] &amp;quot;Iowa City&amp;quot;    &amp;quot;Iowa&amp;quot;     
## [2,] &amp;quot;Cedar Rapids&amp;quot; &amp;quot;IA&amp;quot;       
## [3,] &amp;quot;Des Moines&amp;quot;   &amp;quot;Iowa&amp;quot;     
## [4,] &amp;quot;Waterloo&amp;quot;     &amp;quot;IA&amp;quot;       
## [5,] &amp;quot;Rochester&amp;quot;    &amp;quot;Minnesota&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now a matrix is returned.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;real-world-example&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Real World Example&lt;/h2&gt;
&lt;p&gt;To give a sense of some real world applications of regular expressions, I’m going to use the “ufo.csv” data we used once previously.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ufo &amp;lt;- read_csv(&amp;#39;https://raw.githubusercontent.com/lebebr01/psqf-6250-blogdown/main/data/ufo.csv&amp;#39;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Rows: 8031 Columns: 7
## ── Column specification ────────────────────────────────────────────────────────
## Delimiter: &amp;quot;,&amp;quot;
## chr (7): Date / Time, City, State, Shape, Duration, Summary, Posted
## 
## ℹ Use `spec()` to retrieve the full column specification for this data.
## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ufo&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 8,031 × 7
##    `Date / Time`  City                     State Shape   Duration Summary Posted
##    &amp;lt;chr&amp;gt;          &amp;lt;chr&amp;gt;                    &amp;lt;chr&amp;gt; &amp;lt;chr&amp;gt;   &amp;lt;chr&amp;gt;    &amp;lt;chr&amp;gt;   &amp;lt;chr&amp;gt; 
##  1 12/12/14 17:30 North Wales              PA    Triang… 5 minut… &amp;quot;I hea… &amp;lt;NA&amp;gt;  
##  2 12/12/14 12:40 Cartersville             GA    Unknown 3.6 min… &amp;quot;Looki… 12/12…
##  3 12/12/14 06:30 Isle of Man (UK/England) &amp;lt;NA&amp;gt;  Light   2 secon… &amp;quot;Over … 12/12…
##  4 12/12/14 01:00 Miamisburg               OH    Changi… &amp;lt;NA&amp;gt;     &amp;quot;Brigh… 12/12…
##  5 12/12/14 00:00 Spotsylvania             VA    Unknown 1 minute &amp;quot;White… 12/12…
##  6 12/11/14 23:25 Kenner                   LA    Chevron ~1 minu… &amp;quot;Stran… 12/12…
##  7 12/11/14 23:15 Eugene                   OR    Disk    2 minut… &amp;quot;Dual … 12/12…
##  8 12/11/14 20:04 Phoenix                  AZ    Chevron 3 minut… &amp;quot;4 Ora… 12/12…
##  9 12/11/14 20:00 Franklin                 NC    Disk    5 minut… &amp;quot;There… 12/12…
## 10 12/11/14 18:30 Longview                 WA    Cylind… 10 seco… &amp;quot;Two c… 12/12…
## # … with 8,021 more rows&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;A few things may be of interest here. First, we may wish to add columns that split the Duration variable into a time and metric variables.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ufo_duration &amp;lt;- str_split(ufo$Duration, &amp;#39; &amp;#39;, simplify = TRUE)
cbind(ufo, ufo_duration) %&amp;gt;%
  head(n = 20)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##       Date / Time                     City State     Shape      Duration
## 1  12/12/14 17:30              North Wales    PA  Triangle     5 minutes
## 2  12/12/14 12:40             Cartersville    GA   Unknown   3.6 minutes
## 3  12/12/14 06:30 Isle of Man (UK/England)  &amp;lt;NA&amp;gt;     Light     2 seconds
## 4  12/12/14 01:00               Miamisburg    OH  Changing          &amp;lt;NA&amp;gt;
## 5  12/12/14 00:00             Spotsylvania    VA   Unknown      1 minute
## 6  12/11/14 23:25                   Kenner    LA   Chevron     ~1 minute
## 7  12/11/14 23:15                   Eugene    OR      Disk     2 minutes
## 8  12/11/14 20:04                  Phoenix    AZ   Chevron     3 minutes
## 9  12/11/14 20:00                 Franklin    NC      Disk     5 minutes
## 10 12/11/14 18:30                 Longview    WA  Cylinder    10 seconds
## 11 12/11/14 17:30                 Markesan    WI     Light    10 minutes
## 12 12/11/14 16:40               Birmingham    AL  Fireball    20 minutes
## 13 12/11/14 06:00             West Milford    NJ  Fireball    10 seconds
## 14 12/11/14 00:00             Williamsburg    VA       Egg    10 minutes
## 15 12/10/14 20:30                 Chandler    AZ    Sphere        1 hour
## 16 12/10/14 20:00                 Maricopa    AZ Formation 20-25 minutes
## 17 12/10/14 19:30          Litchfield Park    AZ Formation    20 minutes
## 18 12/10/14 19:15                  Flagler    CO     Light      1 minute
## 19 12/10/14 19:00                   Garner    NC     Light    12 minutes
## 20 12/10/14 17:30                  Ruidoso    NM  Fireball    20 minutes
##                                                                                                                                    Summary
## 1  I heard an extremely loud noise outside, and went onto my balcony to investigate. I saw an very very large green light headed my direct
## 2          Looking up towards the west I noticed an object that flashed from white to green to red.  ((NUFORC Note:  Possible star??  PD))
## 3                                                                       Over the Isle of Man, very fast moving light, diving then zooming.
## 4            Bright color changing and, shape shifting object seen over Miamisburg, OH.  ((NUFORC Note:  Possible &amp;quot;twinkling&amp;quot; star??  PD))
## 5                                                                White then orange orb gained a &amp;quot;tail of light&amp;quot; when chased off by a heli.
## 6                                                                            Strange, chevron-shaped, ufo moving east to west over Kenner.
## 7                                                                                          Dual orange orbs in Eugene, Oregon. 12/11/2014.
## 8                                                                                       4 Orange Lights Spotted South Of The Phoenix Area.
## 9             There were 5 or 6 lights in a row blinking, whites and reds.  It was just sitting there over top the ridge of the mountains.
## 10                                                                              Two cylinder shaped objects that flew parallel in the sky.
## 11                                                      Dark sky, large lights, nothing like an airplane, turning on and off in a pattern.
## 12                                                                                  UFOs moving fast like fireballs or individual rockets.
## 13                                                                                                               Strange light across sky.
## 14                                                                                       Bright light object with three clusters of light.
## 15                                  1-7 bright orange spheres seen for over an hour in Chandler, Arizona, near the Gila River Reservation.
## 16                                                                                                     Bright orange lights over Maricopa.
## 17                                                                                 Multiple lights in the sky in Litchfield Park, Arizona.
## 18                                                                                                                Eastern Colorado lights.
## 19                                                   Lights in distance quickly moving in every direction then shooting up at great speed.
## 20     1 lg. bright orange orb that split into 3 orbs.  Fighter jets chased them &amp;amp; they disappeared.  Mil. jets, helis, and a b2 followed.
##      Posted     1       2 3 4 5 6 7
## 1      &amp;lt;NA&amp;gt;     5 minutes          
## 2  12/12/14   3.6 minutes          
## 3  12/12/14     2 seconds          
## 4  12/12/14  &amp;lt;NA&amp;gt;                  
## 5  12/12/14     1  minute          
## 6  12/12/14    ~1  minute          
## 7  12/12/14     2 minutes          
## 8  12/12/14     3 minutes          
## 9  12/12/14     5 minutes          
## 10 12/12/14    10 seconds          
## 11 12/12/14    10 minutes          
## 12 12/12/14    20 minutes          
## 13 12/12/14    10 seconds          
## 14 12/12/14    10 minutes          
## 15 12/12/14     1    hour          
## 16 12/12/14 20-25 minutes          
## 17 12/12/14    20 minutes          
## 18 12/12/14     1  minute          
## 19 12/12/14    12 minutes          
## 20 12/12/14    20 minutes&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;It could also be useful to count the number of times colors were mentioned in the summary text.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ufo %&amp;gt;%
  mutate(
    num_colors = str_count(Summary, &amp;#39;white|green|red|blue|orange|purple|yellow&amp;#39;)
  )&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 8,031 × 8
##    `Date / Time`  City            State Shape Duration Summary Posted num_colors
##    &amp;lt;chr&amp;gt;          &amp;lt;chr&amp;gt;           &amp;lt;chr&amp;gt; &amp;lt;chr&amp;gt; &amp;lt;chr&amp;gt;    &amp;lt;chr&amp;gt;   &amp;lt;chr&amp;gt;       &amp;lt;int&amp;gt;
##  1 12/12/14 17:30 North Wales     PA    Tria… 5 minut… &amp;quot;I hea… &amp;lt;NA&amp;gt;            1
##  2 12/12/14 12:40 Cartersville    GA    Unkn… 3.6 min… &amp;quot;Looki… 12/12…          3
##  3 12/12/14 06:30 Isle of Man (U… &amp;lt;NA&amp;gt;  Light 2 secon… &amp;quot;Over … 12/12…          0
##  4 12/12/14 01:00 Miamisburg      OH    Chan… &amp;lt;NA&amp;gt;     &amp;quot;Brigh… 12/12…          0
##  5 12/12/14 00:00 Spotsylvania    VA    Unkn… 1 minute &amp;quot;White… 12/12…          1
##  6 12/11/14 23:25 Kenner          LA    Chev… ~1 minu… &amp;quot;Stran… 12/12…          0
##  7 12/11/14 23:15 Eugene          OR    Disk  2 minut… &amp;quot;Dual … 12/12…          1
##  8 12/11/14 20:04 Phoenix         AZ    Chev… 3 minut… &amp;quot;4 Ora… 12/12…          0
##  9 12/11/14 20:00 Franklin        NC    Disk  5 minut… &amp;quot;There… 12/12…          2
## 10 12/11/14 18:30 Longview        WA    Cyli… 10 seco… &amp;quot;Two c… 12/12…          0
## # … with 8,021 more rows&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;an-easier-way-to-manipulate-dates&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;An Easier way to manipulate dates&lt;/h2&gt;
&lt;p&gt;The lubridate package in R makes working with date vectors much simpler.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# install.packages(&amp;quot;lubridate&amp;quot;)
library(lubridate)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;First, we need to convert the Date/Time column in the ufo data to an actual date column. Note above that this column is actually a character vector. Fortunately, lubridate has some functions for common ways that dates and times are stored. The biggest hurdle to know which function to use, is to identify the pattern in the date/time column in our data. Below I print the first 6 rows of the date/time vector of data. Notice that the format is month/day/year then hour/minutes. We can use this information to parse the column to a date/time vector using lubridate’s built in date conversion tools.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;head(ufo$`Date / Time`)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;12/12/14 17:30&amp;quot; &amp;quot;12/12/14 12:40&amp;quot; &amp;quot;12/12/14 06:30&amp;quot; &amp;quot;12/12/14 01:00&amp;quot;
## [5] &amp;quot;12/12/14 00:00&amp;quot; &amp;quot;12/11/14 23:25&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The primary way to determine which conversion tool to use, is to understand lubridate’s shorthand notation. Below is a list showing these elements.&lt;/p&gt;
&lt;p&gt;For date components, these are the shorthand notation.
* y = year
* m = month
* d = day&lt;/p&gt;
&lt;p&gt;For time components, these are the shorthand notation.
* h = hours
* m = minutes
* s = seconds&lt;/p&gt;
&lt;p&gt;Note that “m” stands for both minute and month, but is used in context with either the date or time conversion. The lubridate package will handle this for us. Based on this table and the pattern depicted above, we can convert this with the following pattern and function: &lt;code&gt;mdy_hm()&lt;/code&gt;. This can be read in English as, month, day, year followed by hour and minute.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ufo &amp;lt;- ufo %&amp;gt;%
  mutate(converted_date = mdy_hm(`Date / Time`))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning: 56 failed to parse.&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ufo&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 8,031 × 8
##    `Date / Time`  City   State Shape Duration Summary Posted converted_date     
##    &amp;lt;chr&amp;gt;          &amp;lt;chr&amp;gt;  &amp;lt;chr&amp;gt; &amp;lt;chr&amp;gt; &amp;lt;chr&amp;gt;    &amp;lt;chr&amp;gt;   &amp;lt;chr&amp;gt;  &amp;lt;dttm&amp;gt;             
##  1 12/12/14 17:30 North… PA    Tria… 5 minut… &amp;quot;I hea… &amp;lt;NA&amp;gt;   2014-12-12 17:30:00
##  2 12/12/14 12:40 Carte… GA    Unkn… 3.6 min… &amp;quot;Looki… 12/12… 2014-12-12 12:40:00
##  3 12/12/14 06:30 Isle … &amp;lt;NA&amp;gt;  Light 2 secon… &amp;quot;Over … 12/12… 2014-12-12 06:30:00
##  4 12/12/14 01:00 Miami… OH    Chan… &amp;lt;NA&amp;gt;     &amp;quot;Brigh… 12/12… 2014-12-12 01:00:00
##  5 12/12/14 00:00 Spots… VA    Unkn… 1 minute &amp;quot;White… 12/12… 2014-12-12 00:00:00
##  6 12/11/14 23:25 Kenner LA    Chev… ~1 minu… &amp;quot;Stran… 12/12… 2014-12-11 23:25:00
##  7 12/11/14 23:15 Eugene OR    Disk  2 minut… &amp;quot;Dual … 12/12… 2014-12-11 23:15:00
##  8 12/11/14 20:04 Phoen… AZ    Chev… 3 minut… &amp;quot;4 Ora… 12/12… 2014-12-11 20:04:00
##  9 12/11/14 20:00 Frank… NC    Disk  5 minut… &amp;quot;There… 12/12… 2014-12-11 20:00:00
## 10 12/11/14 18:30 Longv… WA    Cyli… 10 seco… &amp;quot;Two c… 12/12… 2014-12-11 18:30:00
## # … with 8,021 more rows&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The resulting output has the converted_date added to the original table. Note, we did get some warning messages, these basically say that there were some dates that could not be converted properly, these are likely due to missing data or different patterns in the conversion. We would want to inspect these in more detail to understand why those 56 date/times failed to parse.&lt;/p&gt;
&lt;p&gt;Once the dates are now in a date/time format, we can now use additional functions from lubridate to pull out specific elements of the date or time. For example, we could use &lt;code&gt;year()&lt;/code&gt;, &lt;code&gt;month()&lt;/code&gt;, &lt;code&gt;day()&lt;/code&gt; to extract the year, month or day from each element. There are also similar functions, &lt;code&gt;hour()&lt;/code&gt;, &lt;code&gt;minute()&lt;/code&gt;, and &lt;code&gt;second()&lt;/code&gt;. These are shown in use below.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ufo %&amp;gt;%
  mutate(
    year = year(converted_date),
    month = month(converted_date),
    day = day(converted_date),
    hour = hour(converted_date),
    minute = minute(converted_date),
    month_label_abbr = month(converted_date, label = TRUE),
    wday_abbr = wday(converted_date, label = TRUE),
    month_label = month(converted_date, label = TRUE, abbr = FALSE),
    wday = wday(converted_date, label = TRUE, abbr = FALSE)
  )&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 8,031 × 17
##    `Date / Time`  City   State Shape Duration Summary Posted converted_date     
##    &amp;lt;chr&amp;gt;          &amp;lt;chr&amp;gt;  &amp;lt;chr&amp;gt; &amp;lt;chr&amp;gt; &amp;lt;chr&amp;gt;    &amp;lt;chr&amp;gt;   &amp;lt;chr&amp;gt;  &amp;lt;dttm&amp;gt;             
##  1 12/12/14 17:30 North… PA    Tria… 5 minut… &amp;quot;I hea… &amp;lt;NA&amp;gt;   2014-12-12 17:30:00
##  2 12/12/14 12:40 Carte… GA    Unkn… 3.6 min… &amp;quot;Looki… 12/12… 2014-12-12 12:40:00
##  3 12/12/14 06:30 Isle … &amp;lt;NA&amp;gt;  Light 2 secon… &amp;quot;Over … 12/12… 2014-12-12 06:30:00
##  4 12/12/14 01:00 Miami… OH    Chan… &amp;lt;NA&amp;gt;     &amp;quot;Brigh… 12/12… 2014-12-12 01:00:00
##  5 12/12/14 00:00 Spots… VA    Unkn… 1 minute &amp;quot;White… 12/12… 2014-12-12 00:00:00
##  6 12/11/14 23:25 Kenner LA    Chev… ~1 minu… &amp;quot;Stran… 12/12… 2014-12-11 23:25:00
##  7 12/11/14 23:15 Eugene OR    Disk  2 minut… &amp;quot;Dual … 12/12… 2014-12-11 23:15:00
##  8 12/11/14 20:04 Phoen… AZ    Chev… 3 minut… &amp;quot;4 Ora… 12/12… 2014-12-11 20:04:00
##  9 12/11/14 20:00 Frank… NC    Disk  5 minut… &amp;quot;There… 12/12… 2014-12-11 20:00:00
## 10 12/11/14 18:30 Longv… WA    Cyli… 10 seco… &amp;quot;Two c… 12/12… 2014-12-11 18:30:00
## # … with 8,021 more rows, and 9 more variables: year &amp;lt;dbl&amp;gt;, month &amp;lt;dbl&amp;gt;,
## #   day &amp;lt;int&amp;gt;, hour &amp;lt;int&amp;gt;, minute &amp;lt;int&amp;gt;, month_label_abbr &amp;lt;ord&amp;gt;,
## #   wday_abbr &amp;lt;ord&amp;gt;, month_label &amp;lt;ord&amp;gt;, wday &amp;lt;ord&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Model Introduction</title>
      <link>https://psqf6250.brandonlebeau.org/rcode/model-intro/</link>
      <pubDate>Mon, 28 Feb 2022 00:00:00 +0000</pubDate>
      <guid>https://psqf6250.brandonlebeau.org/rcode/model-intro/</guid>
      <description>
&lt;script src=&#34;https://psqf6250.brandonlebeau.org/rmarkdown-libs/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;

&lt;div id=&#34;TOC&#34;&gt;

&lt;/div&gt;

&lt;p&gt;This section of the notes is going to introduce you into the world of models in R. For the most part, we are going to stick with simple linear models and build up the various models using one function &lt;code&gt;lm&lt;/code&gt;. The &lt;code&gt;lm&lt;/code&gt; function is an extremely powerful function that can accommodate many different models in a single framework.&lt;/p&gt;
&lt;p&gt;This section of notes is going to make use of four R packages:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(tidyverse)
library(modelr)
# install.packages(&amp;quot;broom&amp;quot;)
library(broom)
library(fivethirtyeight)&lt;/code&gt;&lt;/pre&gt;
&lt;div id=&#34;simple-linear-regression&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Simple Linear Regression&lt;/h2&gt;
&lt;p&gt;First we need some data. We are going to explore the data from the &lt;code&gt;fivethirtyeight&lt;/code&gt; package called &lt;code&gt;fandango&lt;/code&gt;. Here are the first few rows:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;fandango&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 146 × 23
##    film    year rottentomatoes rottentomatoes_… metacritic metacritic_user  imdb
##    &amp;lt;chr&amp;gt;  &amp;lt;dbl&amp;gt;          &amp;lt;int&amp;gt;            &amp;lt;int&amp;gt;      &amp;lt;int&amp;gt;           &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;
##  1 Aveng…  2015             74               86         66             7.1   7.8
##  2 Cinde…  2015             85               80         67             7.5   7.1
##  3 Ant-M…  2015             80               90         64             8.1   7.8
##  4 Do Yo…  2015             18               84         22             4.7   5.4
##  5 Hot T…  2015             14               28         29             3.4   5.1
##  6 The W…  2015             63               62         50             6.8   7.2
##  7 Irrat…  2015             42               53         53             7.6   6.9
##  8 Top F…  2014             86               64         81             6.8   6.5
##  9 Shaun…  2015             99               82         81             8.8   7.4
## 10 Love …  2015             89               87         80             8.5   7.8
## # … with 136 more rows, and 16 more variables: fandango_stars &amp;lt;dbl&amp;gt;,
## #   fandango_ratingvalue &amp;lt;dbl&amp;gt;, rt_norm &amp;lt;dbl&amp;gt;, rt_user_norm &amp;lt;dbl&amp;gt;,
## #   metacritic_norm &amp;lt;dbl&amp;gt;, metacritic_user_nom &amp;lt;dbl&amp;gt;, imdb_norm &amp;lt;dbl&amp;gt;,
## #   rt_norm_round &amp;lt;dbl&amp;gt;, rt_user_norm_round &amp;lt;dbl&amp;gt;, metacritic_norm_round &amp;lt;dbl&amp;gt;,
## #   metacritic_user_norm_round &amp;lt;dbl&amp;gt;, imdb_norm_round &amp;lt;dbl&amp;gt;,
## #   metacritic_user_vote_count &amp;lt;int&amp;gt;, imdb_user_vote_count &amp;lt;int&amp;gt;,
## #   fandango_votes &amp;lt;int&amp;gt;, fandango_difference &amp;lt;dbl&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;These data have 146 rows and 23 columns.&lt;/p&gt;
&lt;p&gt;Suppose we were interested in exploring the relationship between ratings from rottentomatoes and metacritic. Note, we will not use the user rating for this exploration. A natural first step may be to look at a scatterplot of these data to explore the shape of the relationship.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(fandango, aes(rottentomatoes, metacritic)) + 
  theme_bw() + 
  geom_point(size = 3)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://psqf6250.brandonlebeau.org/rcode/model-intro_files/figure-html/scatter-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;To better explore the relationship, including a smoother can be useful:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(fandango, aes(rottentomatoes, metacritic)) + 
  theme_bw() + 
  geom_point(size = 3) + 
  geom_smooth(method = &amp;#39;loess&amp;#39;, se = FALSE, size = 1.5)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## `geom_smooth()` using formula &amp;#39;y ~ x&amp;#39;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://psqf6250.brandonlebeau.org/rcode/model-intro_files/figure-html/smoother-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;It may also be useful to calculate a correlation coefficient between these two variables.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;with(fandango, cor(rottentomatoes, metacritic))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.9573596&lt;/code&gt;&lt;/pre&gt;
&lt;div id=&#34;fit-linear-regression&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Fit Linear Regression&lt;/h3&gt;
&lt;p&gt;Now we will attempt to fit a model to these data. Namely, the relationship appears to be mostly linear and suppose we wished to predict the metacritic review score with the rotten tomatoes score. To do this, we will use the &lt;code&gt;lm&lt;/code&gt; function and the &lt;code&gt;~&lt;/code&gt; that we used with &lt;code&gt;facet_wrap&lt;/code&gt; and &lt;code&gt;facet_grid&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;More concretely, suppose we wished to fit the model:
&lt;span class=&#34;math display&#34;&gt;\[ metacritic_{i} = b_{0} + b_{1} rottentomatoes_{i} + \epsilon_{i} \]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;In this model, &lt;span class=&#34;math inline&#34;&gt;\(metacritic_{i}\)&lt;/span&gt; is the dependent or response variable and &lt;span class=&#34;math inline&#34;&gt;\(rottentomatoes_{i}\)&lt;/span&gt; is the independent, predictor, or covariate. In many traditional statistics courses, &lt;span class=&#34;math inline&#34;&gt;\(metacritic_{i}\)&lt;/span&gt; would be represented with &lt;span class=&#34;math inline&#34;&gt;\(Y\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(rottentomatoes_{i}\)&lt;/span&gt; would be represented with &lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt;. It is often more descriptive to represent these with their variable names instead of &lt;span class=&#34;math inline&#34;&gt;\(Y\)&lt;/span&gt; or &lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;To fit this model, we simply need to replace the &lt;span class=&#34;math inline&#34;&gt;\(=\)&lt;/span&gt; sign found in the equation above with the &lt;code&gt;~&lt;/code&gt;. For example, the equation above would turn into:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;meta_mod &amp;lt;- lm(metacritic ~ rottentomatoes, data = fandango)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;To see output from the model, we can take two approaches. One is to use &lt;code&gt;summary&lt;/code&gt; and another is to use the &lt;code&gt;tidy&lt;/code&gt; function from the broom package. I show each below in turn.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;summary(meta_mod)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Call:
## lm(formula = metacritic ~ rottentomatoes, data = fandango)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -11.7209  -4.1999   0.3855   3.7952  14.6662 
## 
## Coefficients:
##                Estimate Std. Error t value Pr(&amp;gt;|t|)    
## (Intercept)    21.12097    1.05710   19.98   &amp;lt;2e-16 ***
## rottentomatoes  0.61935    0.01558   39.77   &amp;lt;2e-16 ***
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1
## 
## Residual standard error: 5.658 on 144 degrees of freedom
## Multiple R-squared:  0.9165, Adjusted R-squared:  0.916 
## F-statistic:  1581 on 1 and 144 DF,  p-value: &amp;lt; 2.2e-16&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;tidy(meta_mod)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 2 × 5
##   term           estimate std.error statistic  p.value
##   &amp;lt;chr&amp;gt;             &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;    &amp;lt;dbl&amp;gt;
## 1 (Intercept)      21.1      1.06        20.0 2.36e-43
## 2 rottentomatoes    0.619    0.0156      39.8 1.54e-79&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;With the broom package, the results are reported in a tidier framework. We will see additional useful functions using the broom package later on.&lt;/p&gt;
&lt;p&gt;You can also directly request confidence intervals with the &lt;code&gt;tidy&lt;/code&gt; function:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;tidy(meta_mod, conf.int = TRUE)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 2 × 7
##   term           estimate std.error statistic  p.value conf.low conf.high
##   &amp;lt;chr&amp;gt;             &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;    &amp;lt;dbl&amp;gt;    &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;
## 1 (Intercept)      21.1      1.06        20.0 2.36e-43   19.0      23.2  
## 2 rottentomatoes    0.619    0.0156      39.8 1.54e-79    0.589     0.650&lt;/code&gt;&lt;/pre&gt;
&lt;div id=&#34;exercises&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Exercises&lt;/h4&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;Fit a new model using the &lt;code&gt;fandango&lt;/code&gt; data that attempts to explain the metacritic ratings with the imdb rating.&lt;/li&gt;
&lt;li&gt;Fit another model using the &lt;code&gt;fandango&lt;/code&gt; data that attempts to explain the metacritic ratings with the fandango_ratingvalue scores.&lt;/li&gt;
&lt;li&gt;Exploring the predictors of these two new models with the one fitted above with the rottentomatoes scores, which rating score best helps us predict the metacritic scores?&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;workings-behind-lm-function&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Workings Behind &lt;code&gt;lm&lt;/code&gt; function&lt;/h3&gt;
&lt;p&gt;To see what the &lt;code&gt;lm&lt;/code&gt; function is doing behind the scenes, we will use the &lt;code&gt;model_matrix&lt;/code&gt; function from the modelr package. For example, from the model above:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;model_matrix(fandango, metacritic ~ rottentomatoes)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 146 × 2
##    `(Intercept)` rottentomatoes
##            &amp;lt;dbl&amp;gt;          &amp;lt;dbl&amp;gt;
##  1             1             74
##  2             1             85
##  3             1             80
##  4             1             18
##  5             1             14
##  6             1             63
##  7             1             42
##  8             1             86
##  9             1             99
## 10             1             89
## # … with 136 more rows&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This is often referred to as the design matrix in statistics text books and is one of the matrices that are used by &lt;code&gt;lm&lt;/code&gt; to calculate the estimated parameters from above. Notice that is automatically included the intercept, normally this is of interest, if it is not, we can omit it directly by including a &lt;code&gt;-1&lt;/code&gt; in the formula. For example:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;model_matrix(fandango, metacritic ~ rottentomatoes - 1)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 146 × 1
##    rottentomatoes
##             &amp;lt;dbl&amp;gt;
##  1             74
##  2             85
##  3             80
##  4             18
##  5             14
##  6             63
##  7             42
##  8             86
##  9             99
## 10             89
## # … with 136 more rows&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;tidy(lm(metacritic ~ rottentomatoes - 1, data = fandango))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 1 × 5
##   term           estimate std.error statistic   p.value
##   &amp;lt;chr&amp;gt;             &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;
## 1 rottentomatoes    0.898    0.0134      67.3 3.14e-111&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;You need to be careful with this syntax as this is commonly not is what is desired when fitting a linear model.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;categorical-predictors&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Categorical Predictors&lt;/h3&gt;
&lt;p&gt;Suppose we were interested in the following research question:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;To what extent are there average differences in movie ratings between rottentomatoes and metacritic?&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;To answer this research question, we would need to transform our data to great a group variable and a rating variable.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;meta_rotten &amp;lt;- fandango %&amp;gt;%
  select(film, year, rottentomatoes, metacritic) %&amp;gt;%
  gather(group, rating, rottentomatoes, metacritic)
meta_rotten&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 292 × 4
##    film                     year group          rating
##    &amp;lt;chr&amp;gt;                   &amp;lt;dbl&amp;gt; &amp;lt;chr&amp;gt;           &amp;lt;int&amp;gt;
##  1 Avengers: Age of Ultron  2015 rottentomatoes     74
##  2 Cinderella               2015 rottentomatoes     85
##  3 Ant-Man                  2015 rottentomatoes     80
##  4 Do You Believe?          2015 rottentomatoes     18
##  5 Hot Tub Time Machine 2   2015 rottentomatoes     14
##  6 The Water Diviner        2015 rottentomatoes     63
##  7 Irrational Man           2015 rottentomatoes     42
##  8 Top Five                 2014 rottentomatoes     86
##  9 Shaun the Sheep Movie    2015 rottentomatoes     99
## 10 Love &amp;amp; Mercy             2015 rottentomatoes     89
## # … with 282 more rows&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now we can work with this data to answer the question from above. More specifically, our dependent variable will be the rating variable and the independent variable will be the group (categorical) variable. This can be fitted within a linear model as follows:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;tidy(lm(rating ~ factor(group), data = meta_rotten))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 2 × 5
##   term                        estimate std.error statistic  p.value
##   &amp;lt;chr&amp;gt;                          &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;    &amp;lt;dbl&amp;gt;
## 1 (Intercept)                    58.8       2.10    28.0   2.50e-84
## 2 factor(group)rottentomatoes     2.04      2.97     0.686 4.93e- 1&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;To see exactly what is happening, &lt;code&gt;model_matrix&lt;/code&gt; may be useful. First I am going to arrange the data by the films in alphabetical order.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;meta_rotten %&amp;gt;%
  arrange(film)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 292 × 4
##    film                 year group          rating
##    &amp;lt;chr&amp;gt;               &amp;lt;dbl&amp;gt; &amp;lt;chr&amp;gt;           &amp;lt;int&amp;gt;
##  1 &amp;#39;71                  2015 rottentomatoes     97
##  2 &amp;#39;71                  2015 metacritic         83
##  3 5 Flights Up         2015 rottentomatoes     52
##  4 5 Flights Up         2015 metacritic         55
##  5 A Little Chaos       2015 rottentomatoes     40
##  6 A Little Chaos       2015 metacritic         51
##  7 A Most Violent Year  2014 rottentomatoes     90
##  8 A Most Violent Year  2014 metacritic         79
##  9 About Elly           2015 rottentomatoes     97
## 10 About Elly           2015 metacritic         87
## # … with 282 more rows&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;meta_rotten %&amp;gt;%
  arrange(film) %&amp;gt;%
  model_matrix(rating ~ factor(group))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 292 × 2
##    `(Intercept)` `factor(group)rottentomatoes`
##            &amp;lt;dbl&amp;gt;                         &amp;lt;dbl&amp;gt;
##  1             1                             1
##  2             1                             0
##  3             1                             1
##  4             1                             0
##  5             1                             1
##  6             1                             0
##  7             1                             1
##  8             1                             0
##  9             1                             1
## 10             1                             0
## # … with 282 more rows&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;You may be more familiar with using a t-test for this type of design. We can replicate the results above with a t-test using the &lt;code&gt;t.test&lt;/code&gt; function.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;t.test(rating ~ factor(group), data = meta_rotten, 
       var.equal = TRUE)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
##  Two Sample t-test
## 
## data:  rating by factor(group)
## t = -0.68638, df = 290, p-value = 0.493
## alternative hypothesis: true difference in means between group metacritic and group rottentomatoes is not equal to 0
## 95 percent confidence interval:
##  -7.893918  3.811726
## sample estimates:
##     mean in group metacritic mean in group rottentomatoes 
##                     58.80822                     60.84932&lt;/code&gt;&lt;/pre&gt;
&lt;div id=&#34;exercises-1&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Exercises&lt;/h4&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;Compute descriptive means using the &lt;code&gt;meta_rotten&lt;/code&gt; transformed data from above by the group variable. Do these means appear to be descriptively different?&lt;/li&gt;
&lt;li&gt;How do these means relate to the parameters estimated from the model above?&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;evaulating-model-fit&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Evaulating Model fit&lt;/h3&gt;
&lt;p&gt;There are many ways to evaluate model fit. Many of these are available using the &lt;code&gt;summary&lt;/code&gt; function.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;summary(lm(rating ~ factor(group), data = meta_rotten))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Call:
## lm(formula = rating ~ factor(group), data = meta_rotten)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -55.849 -19.089   0.671  22.161  39.151 
## 
## Coefficients:
##                             Estimate Std. Error t value Pr(&amp;gt;|t|)    
## (Intercept)                   58.808      2.103  27.967   &amp;lt;2e-16 ***
## factor(group)rottentomatoes    2.041      2.974   0.686    0.493    
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1
## 
## Residual standard error: 25.41 on 290 degrees of freedom
## Multiple R-squared:  0.001622,   Adjusted R-squared:  -0.001821 
## F-statistic: 0.4711 on 1 and 290 DF,  p-value: 0.493&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The unfortunate part of this is the fact that these are more difficult to pull out of the table programmatically (i.e. in a reproducible workflow). This is where the broom package helps with the use of the &lt;code&gt;glance&lt;/code&gt; function.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;glance(lm(rating ~ factor(group), data = meta_rotten))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 1 × 12
##   r.squared adj.r.squared sigma statistic p.value    df logLik   AIC   BIC
##       &amp;lt;dbl&amp;gt;         &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;   &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;  &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;
## 1   0.00162      -0.00182  25.4     0.471   0.493     1 -1358. 2722. 2733.
## # … with 3 more variables: deviance &amp;lt;dbl&amp;gt;, df.residual &amp;lt;int&amp;gt;, nobs &amp;lt;int&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;These are now in a more tidy data frame and if you have multiple models in an exploratory analysis, these could then be much easier compared and combined programmatically to come to a final model.&lt;/p&gt;
&lt;p&gt;Another useful function from the broom package is &lt;code&gt;augment&lt;/code&gt;. This function will add additional information to the original data such as residuals, fitted (predicted) values, and other diagnostic statistics.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;diagnostic &amp;lt;- augment(lm(rating ~ factor(group), data = meta_rotten))
diagnostic&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 292 × 7
##    rating `factor(group)` .fitted    .hat .sigma   .cooksd .std.resid
##     &amp;lt;int&amp;gt; &amp;lt;fct&amp;gt;             &amp;lt;dbl&amp;gt;   &amp;lt;dbl&amp;gt;  &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;      &amp;lt;dbl&amp;gt;
##  1     74 rottentomatoes     60.8 0.00685   25.4 0.000930      0.519 
##  2     85 rottentomatoes     60.8 0.00685   25.4 0.00314       0.954 
##  3     80 rottentomatoes     60.8 0.00685   25.4 0.00197       0.756 
##  4     18 rottentomatoes     60.8 0.00685   25.3 0.00988      -1.69  
##  5     14 rottentomatoes     60.8 0.00685   25.3 0.0118       -1.85  
##  6     63 rottentomatoes     60.8 0.00685   25.5 0.0000249     0.0849
##  7     42 rottentomatoes     60.8 0.00685   25.4 0.00191      -0.744 
##  8     86 rottentomatoes     60.8 0.00685   25.4 0.00340       0.993 
##  9     99 rottentomatoes     60.8 0.00685   25.4 0.00783       1.51  
## 10     89 rottentomatoes     60.8 0.00685   25.4 0.00426       1.11  
## # … with 282 more rows&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;These could then be plotted to explore more information about model fit. For example a histogram of the standardized residuals are often useful.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(diagnostic, aes(.std.resid)) + 
  geom_histogram(bins = 30, color = &amp;#39;white&amp;#39;) + 
  theme_bw()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://psqf6250.brandonlebeau.org/rcode/model-intro_files/figure-html/hist_resid-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;For this model, boxplots of the standardized residuals by the two groups can also be informative:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(diagnostic, aes(`factor(group)`, .std.resid)) + 
  geom_boxplot() + 
  geom_jitter() + 
  coord_flip() +
  theme_bw()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://psqf6250.brandonlebeau.org/rcode/model-intro_files/figure-html/boxplot_resid-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;We will explore more details on predicted or fitted values later.&lt;/p&gt;
&lt;p&gt;Lastly, the &lt;code&gt;augment&lt;/code&gt; function can be useful, however I personally do not like the naming convention used by the function. I want to point you to two additional functions from the modelr package that can be useful for predicted (&lt;code&gt;add_predictions&lt;/code&gt;) and residual values (&lt;code&gt;add_residuals&lt;/code&gt;).&lt;/p&gt;
&lt;p&gt;For example, to add the residuals to the original data:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;meta_rotten %&amp;gt;%
  add_residuals(lm(rating ~ factor(group), data = meta_rotten))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 292 × 5
##    film                     year group          rating  resid
##    &amp;lt;chr&amp;gt;                   &amp;lt;dbl&amp;gt; &amp;lt;chr&amp;gt;           &amp;lt;int&amp;gt;  &amp;lt;dbl&amp;gt;
##  1 Avengers: Age of Ultron  2015 rottentomatoes     74  13.2 
##  2 Cinderella               2015 rottentomatoes     85  24.2 
##  3 Ant-Man                  2015 rottentomatoes     80  19.2 
##  4 Do You Believe?          2015 rottentomatoes     18 -42.8 
##  5 Hot Tub Time Machine 2   2015 rottentomatoes     14 -46.8 
##  6 The Water Diviner        2015 rottentomatoes     63   2.15
##  7 Irrational Man           2015 rottentomatoes     42 -18.8 
##  8 Top Five                 2014 rottentomatoes     86  25.2 
##  9 Shaun the Sheep Movie    2015 rottentomatoes     99  38.2 
## 10 Love &amp;amp; Mercy             2015 rottentomatoes     89  28.2 
## # … with 282 more rows&lt;/code&gt;&lt;/pre&gt;
&lt;div id=&#34;exercises-2&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Exercises&lt;/h4&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;Fit a new model using the &lt;code&gt;fandango&lt;/code&gt; data that attempts to explain the metacritic ratings with the imdb rating. Explore the distribution of residuals. Does there appear to be problems with these residuals?&lt;/li&gt;
&lt;li&gt;Using the model from #1, create a scatterplot that displays the residuals by the predictor variable. Are there problems with this plot that we should be concerned with?&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Building Upon Linear Models</title>
      <link>https://psqf6250.brandonlebeau.org/rcode/model-part2/</link>
      <pubDate>Wed, 17 Mar 2021 00:00:00 +0000</pubDate>
      <guid>https://psqf6250.brandonlebeau.org/rcode/model-part2/</guid>
      <description>
&lt;script src=&#34;https://psqf6250.brandonlebeau.org/rmarkdown-libs/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;

&lt;div id=&#34;TOC&#34;&gt;

&lt;/div&gt;

&lt;p&gt;The last week has focused on building simple linear models with a single predictor. This week will evaluate these models and build them up with more complexity. Particularly, this week will focus on ways to build models with predictors that have more than two categories, alternative ways to code categorical predictors, mixing categorical and quantitative variables, and interactions.&lt;/p&gt;
&lt;p&gt;This section of notes will use the following packages.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(tidyverse)
library(modelr)
library(broom)
library(fivethirtyeight)
library(forcats)&lt;/code&gt;&lt;/pre&gt;
&lt;div id=&#34;more-than-two-categorical-levels&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;More than two categorical levels&lt;/h2&gt;
&lt;p&gt;Last week we explored a linear model framework for a two sample t-test (and the homework has you explore fitting a one-sample t-test in a linear model framework). I now want to generalize this idea to more than two categorical levels. It is traditional to think about these types of models as analysis of variance (ANOVA) models, however, the same model can be fitted in a linear model framework as well.&lt;/p&gt;
&lt;p&gt;For this set of notes, we are going to make use of the gss_cat data found in the forcats package. Below are the first few rows of the data:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;gss_cat&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 21,483 × 9
##     year marital         age race  rincome        partyid    relig denom tvhours
##    &amp;lt;int&amp;gt; &amp;lt;fct&amp;gt;         &amp;lt;int&amp;gt; &amp;lt;fct&amp;gt; &amp;lt;fct&amp;gt;          &amp;lt;fct&amp;gt;      &amp;lt;fct&amp;gt; &amp;lt;fct&amp;gt;   &amp;lt;int&amp;gt;
##  1  2000 Never married    26 White $8000 to 9999  Ind,near … Prot… Sout…      12
##  2  2000 Divorced         48 White $8000 to 9999  Not str r… Prot… Bapt…      NA
##  3  2000 Widowed          67 White Not applicable Independe… Prot… No d…       2
##  4  2000 Never married    39 White Not applicable Ind,near … Orth… Not …       4
##  5  2000 Divorced         25 White Not applicable Not str d… None  Not …       1
##  6  2000 Married          25 White $20000 - 24999 Strong de… Prot… Sout…      NA
##  7  2000 Never married    36 White $25000 or more Not str r… Chri… Not …       3
##  8  2000 Divorced         44 White $7000 to 7999  Ind,near … Prot… Luth…      NA
##  9  2000 Married          44 White $25000 or more Not str d… Prot… Other       0
## 10  2000 Married          47 White $25000 or more Strong re… Prot… Sout…       3
## # … with 21,473 more rows&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Suppose we were interested in exploring the relationship between the marital status of an individual and how much tv they watch. For example, perhaps married couples watch more tv compared to those that are single or never married. To get an idea of the categories in the marital variable, we could use the &lt;code&gt;count&lt;/code&gt; function within dplyr.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;gss_cat %&amp;gt;%
  count(marital)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 6 × 2
##   marital           n
##   &amp;lt;fct&amp;gt;         &amp;lt;int&amp;gt;
## 1 No answer        17
## 2 Never married  5416
## 3 Separated       743
## 4 Divorced       3383
## 5 Widowed        1807
## 6 Married       10117&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;You’ll notice that there a few responses of “No Answer” and we may wish to treat these as missing values. This can be done with the &lt;code&gt;fct_recode&lt;/code&gt; function as follows:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;gss_cat &amp;lt;- gss_cat %&amp;gt;%
  mutate(marital_miss = fct_recode(marital,
    NULL = &amp;#39;No answer&amp;#39;
  ))
gss_cat %&amp;gt;%
  count(marital_miss)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 6 × 2
##   marital_miss      n
##   &amp;lt;fct&amp;gt;         &amp;lt;int&amp;gt;
## 1 Never married  5416
## 2 Separated       743
## 3 Divorced       3383
## 4 Widowed        1807
## 5 Married       10117
## 6 &amp;lt;NA&amp;gt;             17&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We can now fit the model to this new data using the &lt;code&gt;lm&lt;/code&gt; function.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;anova_mod &amp;lt;- lm(tvhours ~ marital_miss, data = gss_cat)
summary(anova_mod)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Call:
## lm(formula = tvhours ~ marital_miss, data = gss_cat)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -3.9120 -1.6504 -0.6504  0.8948 21.3496 
## 
## Coefficients:
##                       Estimate Std. Error t value Pr(&amp;gt;|t|)    
## (Intercept)            3.10518    0.04679  66.366  &amp;lt; 2e-16 ***
## marital_missSeparated  0.44444    0.13738   3.235  0.00122 ** 
## marital_missDivorced  -0.01977    0.07680  -0.257  0.79687    
## marital_missWidowed    0.80682    0.09352   8.627  &amp;lt; 2e-16 ***
## marital_missMarried   -0.45475    0.05879  -7.735 1.13e-14 ***
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1
## 
## Residual standard error: 2.561 on 11323 degrees of freedom
##   (10155 observations deleted due to missingness)
## Multiple R-squared:  0.02141,    Adjusted R-squared:  0.02107 
## F-statistic: 61.94 on 4 and 11323 DF,  p-value: &amp;lt; 2.2e-16&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;To explore what the &lt;code&gt;lm&lt;/code&gt; function is doing internally, the design matrix is a natural way to do this.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;model_matrix(gss_cat, tvhours ~ marital_miss)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 11,328 × 5
##    `(Intercept)` marital_missSeparated marital_missDivorced marital_missWidowed
##            &amp;lt;dbl&amp;gt;                 &amp;lt;dbl&amp;gt;                &amp;lt;dbl&amp;gt;               &amp;lt;dbl&amp;gt;
##  1             1                     0                    0                   0
##  2             1                     0                    0                   1
##  3             1                     0                    0                   0
##  4             1                     0                    1                   0
##  5             1                     0                    0                   0
##  6             1                     0                    0                   0
##  7             1                     0                    0                   0
##  8             1                     0                    0                   0
##  9             1                     0                    0                   0
## 10             1                     0                    1                   0
## # … with 11,318 more rows, and 1 more variable: marital_missMarried &amp;lt;dbl&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Writing out this model with equations, the model looks like this:
&lt;span class=&#34;math display&#34;&gt;\[
tvhours_{i} = \beta_{0} + \beta_{1} Separated_{i} + \beta_{2} Divorced_{I} + \beta_{3} Widowed_{i} + \beta_{4} Married_{i} + \epsilon_{i}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;If you are more familiar with ANOVA terminology, you can get an ANOVA table using the &lt;code&gt;anova&lt;/code&gt; function on the model object.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;anova(anova_mod)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Analysis of Variance Table
## 
## Response: tvhours
##                 Df Sum Sq Mean Sq F value    Pr(&amp;gt;F)    
## marital_miss     4   1624  406.12  61.941 &amp;lt; 2.2e-16 ***
## Residuals    11323  74239    6.56                      
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Here you’ll notice that the F statistic is the same from the &lt;code&gt;lm&lt;/code&gt; and &lt;code&gt;anova&lt;/code&gt; functions showing that these are equivalent model calls.&lt;/p&gt;
&lt;div id=&#34;exercises&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Exercises&lt;/h4&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;Using the martial_miss variable created above, what are the sample means of the five groups?&lt;/li&gt;
&lt;li&gt;How do these sample means relate back to the parameters estimates shown above?&lt;/li&gt;
&lt;li&gt;How could you visualize these models results? Attempt to create a visualization that captures the model results above.&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;div id=&#34;adjusting-the-reference-group&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Adjusting the reference group&lt;/h3&gt;
&lt;p&gt;It is often of interest to adjust the reference group to make the intercept represent a specific group of interest. There are two approaches to take for this approach. The first I will show is using the forcats package to change the order of the levels of the variable.&lt;/p&gt;
&lt;p&gt;Suppose for example, we wish to make the widowed category the reference group. This is the job of &lt;code&gt;fct_relevel&lt;/code&gt; from the forcats package.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;gss_cat &amp;lt;- gss_cat %&amp;gt;%
  mutate(marital_m_widow = fct_relevel(
    marital_miss,
    &amp;#39;Widowed&amp;#39;
  ))
levels(gss_cat$marital_miss)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;Never married&amp;quot; &amp;quot;Separated&amp;quot;     &amp;quot;Divorced&amp;quot;      &amp;quot;Widowed&amp;quot;      
## [5] &amp;quot;Married&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;levels(gss_cat$marital_m_widow)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;Widowed&amp;quot;       &amp;quot;Never married&amp;quot; &amp;quot;Separated&amp;quot;     &amp;quot;Divorced&amp;quot;     
## [5] &amp;quot;Married&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;You’ll notice that in the new variable, the widowed category was moved to the beginning and the remaining order was not changed. We can now fit a new model with this newly releveled factor variable.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;summary(lm(tvhours ~ marital_m_widow, data = gss_cat))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Call:
## lm(formula = tvhours ~ marital_m_widow, data = gss_cat)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -3.9120 -1.6504 -0.6504  0.8948 21.3496 
## 
## Coefficients:
##                              Estimate Std. Error t value Pr(&amp;gt;|t|)    
## (Intercept)                   3.91200    0.08097  48.313  &amp;lt; 2e-16 ***
## marital_m_widowNever married -0.80682    0.09352  -8.627  &amp;lt; 2e-16 ***
## marital_m_widowSeparated     -0.36238    0.15245  -2.377   0.0175 *  
## marital_m_widowDivorced      -0.82659    0.10132  -8.159 3.75e-16 ***
## marital_m_widowMarried       -1.26157    0.08845 -14.262  &amp;lt; 2e-16 ***
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1
## 
## Residual standard error: 2.561 on 11323 degrees of freedom
##   (10155 observations deleted due to missingness)
## Multiple R-squared:  0.02141,    Adjusted R-squared:  0.02107 
## F-statistic: 61.94 on 4 and 11323 DF,  p-value: &amp;lt; 2.2e-16&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The second approach to modifying which group represents the reference group would be to create the indicator (dummy) variables manually. The logic follows from the design matrix above, namely that each variable should have a value of 1 if the marital status equals a specific category or 0 otherwise. For example, this can be created as follows:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;gss_cat &amp;lt;- gss_cat %&amp;gt;%
  mutate(
    separated = ifelse(marital_miss == &amp;#39;Separated&amp;#39;, 1, 0),
    never_married = ifelse(marital_miss == &amp;#39;Never married&amp;#39;, 1, 0),
    divorced = ifelse(marital_miss == &amp;#39;Divorced&amp;#39;, 1, 0),
    married = ifelse(marital_miss == &amp;#39;Married&amp;#39;, 1, 0)
  )
summary(lm(tvhours ~ separated + never_married + divorced + married, 
           data = gss_cat))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Call:
## lm(formula = tvhours ~ separated + never_married + divorced + 
##     married, data = gss_cat)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -3.9120 -1.6504 -0.6504  0.8948 21.3496 
## 
## Coefficients:
##               Estimate Std. Error t value Pr(&amp;gt;|t|)    
## (Intercept)    3.91200    0.08097  48.313  &amp;lt; 2e-16 ***
## separated     -0.36238    0.15245  -2.377   0.0175 *  
## never_married -0.80682    0.09352  -8.627  &amp;lt; 2e-16 ***
## divorced      -0.82659    0.10132  -8.159 3.75e-16 ***
## married       -1.26157    0.08845 -14.262  &amp;lt; 2e-16 ***
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1
## 
## Residual standard error: 2.561 on 11323 degrees of freedom
##   (10155 observations deleted due to missingness)
## Multiple R-squared:  0.02141,    Adjusted R-squared:  0.02107 
## F-statistic: 61.94 on 4 and 11323 DF,  p-value: &amp;lt; 2.2e-16&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Manually creating the variables has a few advantages, namely that there is a bit more flexibility on how the variables are created, but both approaches lead to the same model.&lt;/p&gt;
&lt;div id=&#34;exercises-1&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Exercises&lt;/h4&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;Combine the ‘Never married’ and ‘Divorced’ categories into one category.&lt;/li&gt;
&lt;li&gt;Fit a new model that combines these two categories. Does the model fit differ from the models shown above? Is this surprising?&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;post-hoc-tests&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Post Hoc Tests&lt;/h3&gt;
&lt;p&gt;From the models fitted above, it may be of interest to conduct post hoc tests that compare all pairwise mean differences, particularly as the tests above are all compared to the reference group. This approach will be explored using the multcomp package and with defining linear contrasts.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# install.packages(&amp;quot;multcomp&amp;quot;)
library(multcomp)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We first need to define linear contrasts based on the levels of the factor variable. For example, using the following model:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;gss_cat &amp;lt;- gss_cat %&amp;gt;%
  mutate(marital_m_widow = fct_recode(marital_m_widow,
           &amp;quot;Never_married&amp;quot; = &amp;quot;Never married&amp;quot;                           
  ))
anova_mod &amp;lt;- lm(tvhours ~ marital_m_widow, data = gss_cat)
levels(gss_cat$marital_m_widow)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;Widowed&amp;quot;       &amp;quot;Never_married&amp;quot; &amp;quot;Separated&amp;quot;     &amp;quot;Divorced&amp;quot;     
## [5] &amp;quot;Married&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We will use these level values to create linear contrasts that test all pairwise categories.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;my_contrasts &amp;lt;- c(&amp;quot;Widowed - Never_married = 0&amp;quot;,
                 &amp;quot;Widowed - Separated = 0&amp;quot;,
                 &amp;quot;Widowed - Divorced = 0&amp;quot;,
                 &amp;quot;Widowed - Married = 0&amp;quot;,
                 &amp;quot;Never_married - Separated = 0&amp;quot;,
                 &amp;quot;Never_married - Divorced = 0&amp;quot;,
                 &amp;quot;Never_married - Married = 0&amp;quot;,
                 &amp;quot;Separated - Divorced = 0&amp;quot;,
                 &amp;quot;Separated - Married = 0&amp;quot;,
                 &amp;quot;Divorced - Married = 0&amp;quot;)
contr_results &amp;lt;- glht(anova_mod, 
                      linfct = mcp(marital_m_widow = my_contrasts))
summary(contr_results)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
##   Simultaneous Tests for General Linear Hypotheses
## 
## Multiple Comparisons of Means: User-defined Contrasts
## 
## 
## Fit: lm(formula = tvhours ~ marital_m_widow, data = gss_cat)
## 
## Linear Hypotheses:
##                                Estimate Std. Error t value Pr(&amp;gt;|t|)    
## Widowed - Never_married == 0    0.80682    0.09352   8.627  &amp;lt; 0.001 ***
## Widowed - Separated == 0        0.36238    0.15245   2.377  0.11077    
## Widowed - Divorced == 0         0.82659    0.10132   8.159  &amp;lt; 0.001 ***
## Widowed - Married == 0          1.26157    0.08845  14.262  &amp;lt; 0.001 ***
## Never_married - Separated == 0 -0.44444    0.13738  -3.235  0.00949 ** 
## Never_married - Divorced == 0   0.01977    0.07680   0.257  0.99893    
## Never_married - Married == 0    0.45475    0.05879   7.735  &amp;lt; 0.001 ***
## Separated - Divorced == 0       0.46421    0.14280   3.251  0.00897 ** 
## Separated - Married == 0        0.89919    0.13398   6.711  &amp;lt; 0.001 ***
## Divorced - Married == 0         0.43498    0.07054   6.166  &amp;lt; 0.001 ***
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1
## (Adjusted p values reported -- single-step method)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;You can also specify different adjustment methods, such as the Benjamin-Hochberg method.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;summary(contr_results, test = adjusted(&amp;quot;BH&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
##   Simultaneous Tests for General Linear Hypotheses
## 
## Multiple Comparisons of Means: User-defined Contrasts
## 
## 
## Fit: lm(formula = tvhours ~ marital_m_widow, data = gss_cat)
## 
## Linear Hypotheses:
##                                Estimate Std. Error t value Pr(&amp;gt;|t|)    
## Widowed - Never_married == 0    0.80682    0.09352   8.627  &amp;lt; 2e-16 ***
## Widowed - Separated == 0        0.36238    0.15245   2.377  0.01941 *  
## Widowed - Divorced == 0         0.82659    0.10132   8.159 1.48e-15 ***
## Widowed - Married == 0          1.26157    0.08845  14.262  &amp;lt; 2e-16 ***
## Never_married - Separated == 0 -0.44444    0.13738  -3.235  0.00152 ** 
## Never_married - Divorced == 0   0.01977    0.07680   0.257  0.79687    
## Never_married - Married == 0    0.45475    0.05879   7.735 2.78e-14 ***
## Separated - Divorced == 0       0.46421    0.14280   3.251  0.00152 ** 
## Separated - Married == 0        0.89919    0.13398   6.711 4.04e-11 ***
## Divorced - Married == 0         0.43498    0.07054   6.166 1.20e-09 ***
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1
## (Adjusted p values reported -- BH method)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Although defining the linear contrasts manually is more flexible, for simple models, the multiple comparisons can be generated a bit more simply.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;summary(glht(anova_mod, linfct = mcp(marital_m_widow = &amp;quot;Tukey&amp;quot;)), 
        test = adjusted(&amp;quot;BH&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
##   Simultaneous Tests for General Linear Hypotheses
## 
## Multiple Comparisons of Means: Tukey Contrasts
## 
## 
## Fit: lm(formula = tvhours ~ marital_m_widow, data = gss_cat)
## 
## Linear Hypotheses:
##                                Estimate Std. Error t value Pr(&amp;gt;|t|)    
## Never_married - Widowed == 0   -0.80682    0.09352  -8.627  &amp;lt; 2e-16 ***
## Separated - Widowed == 0       -0.36238    0.15245  -2.377  0.01941 *  
## Divorced - Widowed == 0        -0.82659    0.10132  -8.159 1.48e-15 ***
## Married - Widowed == 0         -1.26157    0.08845 -14.262  &amp;lt; 2e-16 ***
## Separated - Never_married == 0  0.44444    0.13738   3.235  0.00152 ** 
## Divorced - Never_married == 0  -0.01977    0.07680  -0.257  0.79687    
## Married - Never_married == 0   -0.45475    0.05879  -7.735 2.78e-14 ***
## Divorced - Separated == 0      -0.46421    0.14280  -3.251  0.00152 ** 
## Married - Separated == 0       -0.89919    0.13398  -6.711 4.04e-11 ***
## Married - Divorced == 0        -0.43498    0.07054  -6.166 1.20e-09 ***
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1
## (Adjusted p values reported -- BH method)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;You can also generate simultaneous confidence intervals:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ci &amp;lt;- confint(summary(glht(anova_mod, linfct = mcp(marital_m_widow = &amp;quot;Tukey&amp;quot;)),
                test = adjusted(&amp;quot;BH&amp;quot;)))
ci&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
##   Simultaneous Confidence Intervals
## 
## Multiple Comparisons of Means: Tukey Contrasts
## 
## 
## Fit: lm(formula = tvhours ~ marital_m_widow, data = gss_cat)
## 
## Quantile = 2.6896
## 95% family-wise confidence level
##  
## 
## Linear Hypotheses:
##                                Estimate lwr      upr     
## Never_married - Widowed == 0   -0.80682 -1.05835 -0.55529
## Separated - Widowed == 0       -0.36238 -0.77241  0.04764
## Divorced - Widowed == 0        -0.82659 -1.09910 -0.55409
## Married - Widowed == 0         -1.26157 -1.49949 -1.02366
## Separated - Never_married == 0  0.44444  0.07495  0.81394
## Divorced - Never_married == 0  -0.01977 -0.22632  0.18678
## Married - Never_married == 0   -0.45475 -0.61289 -0.29661
## Divorced - Separated == 0      -0.46421 -0.84829 -0.08013
## Married - Separated == 0       -0.89919 -1.25955 -0.53883
## Married - Divorced == 0        -0.43498 -0.62471 -0.24525&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;These could then be visulized directly.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;SCI = data.frame(
  Contrast = 1:nrow(ci$confint),   #Contrast number
  MD = ci$confint[, 1],      #Mean difference
  LL = ci$confint[, 2],      #Lower limit
  UL = ci$confint[, 3],      #Upper limit
  Sig = c(&amp;quot;Yes&amp;quot;, &amp;quot;No&amp;quot;, &amp;quot;Yes&amp;quot;, &amp;quot;Yes&amp;quot;, &amp;#39;Yes&amp;#39;, &amp;#39;No&amp;#39;, 
          &amp;#39;Yes&amp;#39;, &amp;#39;Yes&amp;#39;, &amp;#39;Yes&amp;#39;, &amp;#39;Yes&amp;#39;),   #Statistically reliable?
  Alpha = c(1, .75, 1, 1, 1, .75, 1, 1, 1, 1),     #Transparency value
  Names = rownames(ci$confint)  # contrast label
)

# Plot of the simultaneous intervals
library(ggplot2)
ggplot(data = SCI, aes(x = Contrast, y = MD, color = Sig)) +
  geom_point(size = 4) +
  geom_segment(aes(x = Contrast, xend = Contrast, y = LL, 
                   yend = UL, alpha = Alpha), lwd = 1.5) +
  geom_hline(yintercept = 0, lty = &amp;quot;dotted&amp;quot;) +
  scale_color_manual(values = c(&amp;quot;Black&amp;quot;, &amp;quot;Gold&amp;quot;)) +
  scale_x_continuous(
    name = &amp;quot;&amp;quot;,
    breaks = 1:10,
    labels = SCI$Names
  ) +
  ylab(&amp;quot;Mean Difference&amp;quot;) +
  coord_flip() +
  theme_bw() +
  theme(
    legend.position = &amp;quot;none&amp;quot;,
    panel.grid.minor = element_blank(), 
    panel.grid.major = element_blank() 
  )&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://psqf6250.brandonlebeau.org/rcode/model-part2_files/figure-html/unnamed-chunk-1-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;div id=&#34;exercises-2&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Exercises&lt;/h4&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;Fit a model that explores mean differences in tvhours by the party affiliation (partyid variable). Do the means differ?&lt;/li&gt;
&lt;li&gt;Using the post-hoc tests, run post-hoc tests to test all pairwise differences.&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Advanced Modeling Topics</title>
      <link>https://psqf6250.brandonlebeau.org/rcode/adv-model/</link>
      <pubDate>Wed, 17 Mar 2021 00:00:00 +0000</pubDate>
      <guid>https://psqf6250.brandonlebeau.org/rcode/adv-model/</guid>
      <description>
&lt;script src=&#34;https://psqf6250.brandonlebeau.org/rmarkdown-libs/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;

&lt;div id=&#34;TOC&#34;&gt;

&lt;/div&gt;

&lt;p&gt;This section of notes will use the following packages.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(modelr)
library(broom)
library(forcats)
library(stringr)
library(tidyverse)&lt;/code&gt;&lt;/pre&gt;
&lt;div id=&#34;interactions&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Interactions&lt;/h2&gt;
&lt;p&gt;Interactions are an important modeling concept that can greatly increase model fit, prediction accuracy, and explained variance. Interactions can be difficult to interpret, however, we will explore them in more detail here with particular attention to graphical displays of interactions and also exploring the design matrix for how interactions are included in the model fitting procedure.&lt;/p&gt;
&lt;p&gt;We will use the &lt;code&gt;heights&lt;/code&gt; data from the modelr package to explore interactions. The primary interactions that we will explore are between two (or more) categorical predictors and also the interaction between a categorical predictor and a continuous predictor. Interpretations are similar between two continuous predictors as well.&lt;/p&gt;
&lt;p&gt;Here are the first few rows of the data:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;heights&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 7,006 × 8
##    income height weight   age marital  sex    education  afqt
##     &amp;lt;int&amp;gt;  &amp;lt;dbl&amp;gt;  &amp;lt;int&amp;gt; &amp;lt;int&amp;gt; &amp;lt;fct&amp;gt;    &amp;lt;fct&amp;gt;      &amp;lt;int&amp;gt; &amp;lt;dbl&amp;gt;
##  1  19000     60    155    53 married  female        13  6.84
##  2  35000     70    156    51 married  female        10 49.4 
##  3 105000     65    195    52 married  male          16 99.4 
##  4  40000     63    197    54 married  female        14 44.0 
##  5  75000     66    190    49 married  male          14 59.7 
##  6 102000     68    200    49 divorced female        18 98.8 
##  7      0     74    225    48 married  male          16 82.3 
##  8  70000     64    160    54 divorced female        12 50.3 
##  9  60000     69    162    55 divorced male          12 89.7 
## 10 150000     69    194    54 divorced male          13 96.0 
## # … with 6,996 more rows&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Suppose we were interested in exploring the relationship between sex and afqt (armed forces qualifications test, in percentiles) and if this relationship is moderated by marital status. First, it may be useful to get a baseline to see the relationship between sex and afqt.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;afqt_sex &amp;lt;- lm(afqt ~ sex, data = heights)
summary(afqt_sex)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Call:
## lm(formula = afqt ~ sex, data = heights)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -41.876 -26.034  -4.429  24.046  59.406 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&amp;gt;|t|)    
## (Intercept)  41.8760     0.5093  82.221   &amp;lt;2e-16 ***
## sexfemale    -1.2824     0.7074  -1.813   0.0699 .  
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1
## 
## Residual standard error: 29.03 on 6742 degrees of freedom
##   (262 observations deleted due to missingness)
## Multiple R-squared:  0.0004872,  Adjusted R-squared:  0.000339 
## F-statistic: 3.287 on 1 and 6742 DF,  p-value: 0.06989&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Notice that there is a small effect, which is not significant if using an alpha value of 0.05. Also, notice the extremely small r-square value here, this is actually a good finding, we would hope there would be no statistical differences between males and females on this qualifications test. Now lets start adding in marital status. We can do this as follows (Note, I have combined separated and widowed into a single category due to relatively small sample sizes):&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;heights &amp;lt;- heights %&amp;gt;%
  mutate(
    marital_comb = fct_recode(marital,
          &amp;#39;Other&amp;#39; = &amp;#39;separated&amp;#39;,
          &amp;#39;Other&amp;#39; = &amp;#39;widowed&amp;#39;
    )
  )
afqt_sex_marital &amp;lt;- lm(afqt ~ sex + marital_comb, data = heights)
summary(afqt_sex_marital)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Call:
## lm(formula = afqt ~ sex + marital_comb, data = heights)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -47.957 -23.174  -4.386  22.389  74.002 
## 
## Coefficients:
##                      Estimate Std. Error t value Pr(&amp;gt;|t|)    
## (Intercept)           31.7982     0.9093  34.970  &amp;lt; 2e-16 ***
## sexfemale             -0.6819     0.6869  -0.993 0.320829    
## marital_combmarried   16.1587     0.9727  16.611  &amp;lt; 2e-16 ***
## marital_combOther     -5.5953     1.5186  -3.685 0.000231 ***
## marital_combdivorced   6.2811     1.1232   5.592 2.33e-08 ***
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1
## 
## Residual standard error: 28.02 on 6739 degrees of freedom
##   (262 observations deleted due to missingness)
## Multiple R-squared:  0.069,  Adjusted R-squared:  0.06845 
## F-statistic: 124.9 on 4 and 6739 DF,  p-value: &amp;lt; 2.2e-16&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This model only contains what are often referred to as main effects. Namely, these are only the additive effects of sex and marital variables. To get a sense as to what the design matrix looks like, we can use &lt;code&gt;model_matrix&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;model_matrix(heights, afqt ~ sex + marital_comb)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 6,744 × 5
##    `(Intercept)` sexfemale marital_combmarried marital_combOth… marital_combdiv…
##            &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;               &amp;lt;dbl&amp;gt;            &amp;lt;dbl&amp;gt;            &amp;lt;dbl&amp;gt;
##  1             1         1                   1                0                0
##  2             1         1                   1                0                0
##  3             1         0                   1                0                0
##  4             1         1                   1                0                0
##  5             1         0                   1                0                0
##  6             1         1                   0                0                1
##  7             1         0                   1                0                0
##  8             1         1                   0                0                1
##  9             1         0                   0                0                1
## 10             1         0                   0                0                1
## # … with 6,734 more rows&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;To add the interaction between the two variables (multiplicative effects), we can add one additional term to the &lt;code&gt;lm&lt;/code&gt; function call.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;interact_mod &amp;lt;- lm(afqt ~ sex + marital_comb + sex:marital_comb, data = heights)
summary(interact_mod)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Call:
## lm(formula = afqt ~ sex + marital_comb + sex:marital_comb, data = heights)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -47.981 -22.978  -4.336  22.488  75.275 
## 
## Coefficients:
##                                Estimate Std. Error t value Pr(&amp;gt;|t|)    
## (Intercept)                     31.4205     1.1536  27.237  &amp;lt; 2e-16 ***
## sexfemale                        0.1564     1.7184   0.091    0.928    
## marital_combmarried             16.5603     1.3273  12.477  &amp;lt; 2e-16 ***
## marital_combOther               -2.5872     2.4677  -1.048    0.294    
## marital_combdivorced             6.2796     1.5814   3.971 7.24e-05 ***
## sexfemale:marital_combmarried   -0.8856     1.9516  -0.454    0.650    
## sexfemale:marital_combOther     -4.7414     3.1645  -1.498    0.134    
## sexfemale:marital_combdivorced  -0.1494     2.2535  -0.066    0.947    
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1
## 
## Residual standard error: 28.02 on 6736 degrees of freedom
##   (262 observations deleted due to missingness)
## Multiple R-squared:  0.06936,    Adjusted R-squared:  0.0684 
## F-statistic: 71.72 on 7 and 6736 DF,  p-value: &amp;lt; 2.2e-16&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;There is also an &lt;code&gt;anova&lt;/code&gt; function that gives more traditional anova and sum of squares information.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;anova(interact_mod)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Analysis of Variance Table
## 
## Response: afqt
##                    Df  Sum Sq Mean Sq  F value  Pr(&amp;gt;F)    
## sex                 1    2769    2769   3.5267 0.06043 .  
## marital_comb        3  389378  129793 165.3055 &amp;lt; 2e-16 ***
## sex:marital_comb    3    2058     686   0.8738 0.45380    
## Residuals        6736 5288896     785                     
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In this model, there are not actually any significant results for the interaction, but lets explore the design matrix to see exactly what is happening.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;model_matrix(heights, afqt ~ sex + marital_comb + sex:marital_comb)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 6,744 × 8
##    `(Intercept)` sexfemale marital_combmarried marital_combOth… marital_combdiv…
##            &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;               &amp;lt;dbl&amp;gt;            &amp;lt;dbl&amp;gt;            &amp;lt;dbl&amp;gt;
##  1             1         1                   1                0                0
##  2             1         1                   1                0                0
##  3             1         0                   1                0                0
##  4             1         1                   1                0                0
##  5             1         0                   1                0                0
##  6             1         1                   0                0                1
##  7             1         0                   1                0                0
##  8             1         1                   0                0                1
##  9             1         0                   0                0                1
## 10             1         0                   0                0                1
## # … with 6,734 more rows, and 3 more variables:
## #   `sexfemale:marital_combmarried` &amp;lt;dbl&amp;gt;, `sexfemale:marital_combOther` &amp;lt;dbl&amp;gt;,
## #   `sexfemale:marital_combdivorced` &amp;lt;dbl&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This model specifically adds columns that literally are multiplications of other columns in the design matrix. This is why interactions are often depicted with the symbol “x”, e.g. marital x sex. R uses &lt;code&gt;:&lt;/code&gt; as interactions. The interaction model can also be specified in an alternate more compact formula:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;summary(lm(afqt ~ sex * marital_comb, data = heights))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Call:
## lm(formula = afqt ~ sex * marital_comb, data = heights)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -47.981 -22.978  -4.336  22.488  75.275 
## 
## Coefficients:
##                                Estimate Std. Error t value Pr(&amp;gt;|t|)    
## (Intercept)                     31.4205     1.1536  27.237  &amp;lt; 2e-16 ***
## sexfemale                        0.1564     1.7184   0.091    0.928    
## marital_combmarried             16.5603     1.3273  12.477  &amp;lt; 2e-16 ***
## marital_combOther               -2.5872     2.4677  -1.048    0.294    
## marital_combdivorced             6.2796     1.5814   3.971 7.24e-05 ***
## sexfemale:marital_combmarried   -0.8856     1.9516  -0.454    0.650    
## sexfemale:marital_combOther     -4.7414     3.1645  -1.498    0.134    
## sexfemale:marital_combdivorced  -0.1494     2.2535  -0.066    0.947    
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1
## 
## Residual standard error: 28.02 on 6736 degrees of freedom
##   (262 observations deleted due to missingness)
## Multiple R-squared:  0.06936,    Adjusted R-squared:  0.0684 
## F-statistic: 71.72 on 7 and 6736 DF,  p-value: &amp;lt; 2.2e-16&lt;/code&gt;&lt;/pre&gt;
&lt;div id=&#34;exercises&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Exercises&lt;/h4&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;Using the gss_cat data from the forcats package, fit a model that predicts age with marital status, partyid, and the interaction between the two.&lt;/li&gt;
&lt;li&gt;How well does this model fit?&lt;/li&gt;
&lt;li&gt;How is the intercept interpreted here?&lt;/li&gt;
&lt;li&gt;Do the results change when collapsing the partyid variable into the following three categories:
&lt;ul&gt;
&lt;li&gt;Republican&lt;/li&gt;
&lt;li&gt;Democrat&lt;/li&gt;
&lt;li&gt;Other&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;visualize-model-results&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Visualize Model Results&lt;/h2&gt;
&lt;p&gt;When exploring model results, visualizing the model results is often more useful than looking at a table of coefficients. In addition, if the model is simply attempting to predict means (ANOVA), plotting often simply involves computing means for the different categories. This section will also explore how best to visualize interactions.&lt;/p&gt;
&lt;p&gt;If we simply would like to show the main effects from the model above predicting Armed Forces Qualifiactions Test Score with marital status and sex, we could calculate the means of these groups.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;marital_means &amp;lt;- heights %&amp;gt;%
  group_by(marital_comb) %&amp;gt;%
  summarise(avg_afqt = mean(afqt, na.rm = TRUE),
            sd_afqt = sd(afqt, na.rm = TRUE), 
            n = n()) %&amp;gt;%
  mutate(se_mean = sd_afqt/sqrt(n), 
         group = &amp;#39;Marital&amp;#39;, 
         levels = marital_comb) %&amp;gt;%
  ungroup() %&amp;gt;%
  dplyr::select(-marital_comb)
sex_means &amp;lt;- heights %&amp;gt;%
  group_by(sex) %&amp;gt;%
  summarise(avg_afqt = mean(afqt, na.rm = TRUE),
            sd_afqt = sd(afqt, na.rm = TRUE), 
            n = n()) %&amp;gt;%
  mutate(se_mean = sd_afqt/sqrt(n),
         group = &amp;#39;Sex&amp;#39;, 
         levels = sex) %&amp;gt;%
  ungroup() %&amp;gt;%
  dplyr::select(-sex)
comb_means &amp;lt;- bind_rows(marital_means, sex_means)
comb_means&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 6 × 6
##   avg_afqt sd_afqt     n se_mean group   levels  
##      &amp;lt;dbl&amp;gt;   &amp;lt;dbl&amp;gt; &amp;lt;int&amp;gt;   &amp;lt;dbl&amp;gt; &amp;lt;chr&amp;gt;   &amp;lt;fct&amp;gt;   
## 1     31.5    27.7  1124   0.828 Marital single  
## 2     47.6    29.1  3806   0.472 Marital married 
## 3     25.7    24.1   527   1.05  Marital Other   
## 4     37.7    26.6  1549   0.676 Marital divorced
## 5     41.9    29.8  3402   0.511 Sex     male    
## 6     40.6    28.3  3604   0.472 Sex     female&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The effects can now be shown in a figure.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(comb_means, aes(avg_afqt, fct_reorder(levels, avg_afqt))) + 
  geom_point(size = 3) + 
  facet_grid(group ~ ., scales = &amp;#39;free&amp;#39;, space = &amp;#39;free&amp;#39;) + 
  ylab(&amp;quot;Groups&amp;quot;) + 
  xlab(&amp;quot;Average Armed Forces Qualification Score&amp;quot;) + 
  theme_bw()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://psqf6250.brandonlebeau.org/rcode/adv-model_files/figure-html/mean_fig-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Since we computed standard errors, we could also add error bars using &lt;code&gt;geom_errorbarh&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(comb_means, aes(avg_afqt, fct_reorder(levels, avg_afqt))) + 
  geom_point(size = 3) + 
  geom_errorbarh(aes(xmin = avg_afqt - se_mean*2, xmax = avg_afqt + se_mean*2),
                 height = 0) + 
  facet_grid(group ~ ., scales = &amp;#39;free&amp;#39;, space = &amp;#39;free&amp;#39;) +
  ylab(&amp;quot;Groups&amp;quot;) + 
  xlab(&amp;quot;Average Armed Forces Qualification Score&amp;quot;) + 
  theme_bw()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://psqf6250.brandonlebeau.org/rcode/adv-model_files/figure-html/pointrange-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Plotting the interaction happens in a similar fashion. Namely, we will now calculate means by using both variables in a single &lt;code&gt;group_by&lt;/code&gt; statement.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;int_means &amp;lt;- heights %&amp;gt;%
  group_by(marital_comb, sex) %&amp;gt;%
  summarise(avg_afqt = mean(afqt, na.rm = TRUE),
            sd_afqt = sd(afqt, na.rm = TRUE), 
            n = n()) %&amp;gt;%
  mutate(se_mean = sd_afqt/sqrt(n))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## `summarise()` has grouped output by &amp;#39;marital_comb&amp;#39;. You can override using the
## `.groups` argument.&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;int_means&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 8 × 6
## # Groups:   marital_comb [4]
##   marital_comb sex    avg_afqt sd_afqt     n se_mean
##   &amp;lt;fct&amp;gt;        &amp;lt;fct&amp;gt;     &amp;lt;dbl&amp;gt;   &amp;lt;dbl&amp;gt; &amp;lt;int&amp;gt;   &amp;lt;dbl&amp;gt;
## 1 single       male       31.4    28.2   624   1.13 
## 2 single       female     31.6    27.3   500   1.22 
## 3 married      male       48.0    29.8  1905   0.683
## 4 married      female     47.3    28.5  1901   0.653
## 5 Other        male       28.8    25.7   177   1.93 
## 6 Other        female     24.2    23.1   350   1.24 
## 7 divorced     male       37.7    27.7   696   1.05 
## 8 divorced     female     37.7    25.7   853   0.879&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;These means should now match the last model from the previous lecture. We can now plot these directly.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(int_means, aes(avg_afqt, fct_reorder(marital_comb, avg_afqt), 
                      shape = sex, linetype = sex, group = sex)) + 
  geom_point(size = 3) + 
  geom_line(size = 1) + 
  ylab(&amp;quot;Groups&amp;quot;) + 
  xlab(&amp;quot;Average Armed Forces Qualification Score&amp;quot;) + 
  theme_bw()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://psqf6250.brandonlebeau.org/rcode/adv-model_files/figure-html/int_plot-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Standard error bars can be shown here, but may complicate the figure too much.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(int_means, aes(avg_afqt, fct_reorder(marital_comb, avg_afqt), 
                      shape = sex, linetype = sex, group = sex)) + 
  geom_point(size = 3) + 
  geom_line(size = 1) + 
  geom_errorbarh(aes(xmin = avg_afqt - se_mean * 2, xmax = avg_afqt + se_mean * 2), 
                 height = 0) +
  ylab(&amp;quot;Groups&amp;quot;) + 
  xlab(&amp;quot;Average Armed Forces Qualification Score&amp;quot;) + 
  theme_bw()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://psqf6250.brandonlebeau.org/rcode/adv-model_files/figure-html/se_int-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;div id=&#34;exercises-1&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Exercises&lt;/h4&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;Using the gss_cat data from the forcats package, fit a model that predicts age with marital status, partyid, and the interaction between the two.&lt;/li&gt;
&lt;li&gt;Create a figure that explores the interaction between the two variables.&lt;/li&gt;
&lt;li&gt;Add a third variable to the model, race. Include this as a main effect, plus interacting with the other variables.&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;interaction-between-continuous-and-categorical-predictors&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Interaction between continuous and categorical predictors&lt;/h2&gt;
&lt;p&gt;Using again the heights data, suppose we wished to again predict the Armed Forces Qualifications Test score (afqt) with marital status and height. This can be done with the linear model.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;summary(lm(afqt ~ marital_comb + height, data = heights))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Call:
## lm(formula = afqt ~ marital_comb + height, data = heights)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -53.150 -22.517  -4.248  22.097  78.355 
## 
## Coefficients:
##                       Estimate Std. Error t value Pr(&amp;gt;|t|)    
## (Intercept)          -28.99932    5.67144  -5.113 3.25e-07 ***
## marital_combmarried   16.13531    0.96385  16.741  &amp;lt; 2e-16 ***
## marital_combOther     -4.63978    1.50160  -3.090  0.00201 ** 
## marital_combdivorced   6.75490    1.11278   6.070 1.35e-09 ***
## height                 0.89847    0.08329  10.787  &amp;lt; 2e-16 ***
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1
## 
## Residual standard error: 27.78 on 6739 degrees of freedom
##   (262 observations deleted due to missingness)
## Multiple R-squared:  0.08467,    Adjusted R-squared:  0.08413 
## F-statistic: 155.8 on 4 and 6739 DF,  p-value: &amp;lt; 2.2e-16&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;You’ll notice here that the intercept is negative. Why is this negative? You can most easily see this by looking at a figure of the data. Note, here I am simply showing the dependent and the height variable ignoring the marital status, however, this will have a slightly different slope than the one above (Try it).&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(heights, aes(x = height, y = afqt)) + 
  geom_jitter(size = 2) + 
  geom_abline(intercept = -26.02, slope = 1.002, size = 1, color = &amp;#39;blue&amp;#39;) + 
  coord_cartesian(xlim = c(0, 90), ylim = c(-30, 105)) +
  ylab(&amp;quot;Average Armed Forces Qualification Score&amp;quot;) + 
  xlab(&amp;quot;Height&amp;quot;) +
  theme_bw()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning: Removed 262 rows containing missing values (geom_point).&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://psqf6250.brandonlebeau.org/rcode/adv-model_files/figure-html/trend-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;It may be better to mean center the height variable.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;summary(lm(afqt ~ marital_comb + I(height - mean(heights$height)), data = heights))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Call:
## lm(formula = afqt ~ marital_comb + I(height - mean(heights$height)), 
##     data = heights)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -53.150 -22.517  -4.248  22.097  78.355 
## 
## Coefficients:
##                                  Estimate Std. Error t value Pr(&amp;gt;|t|)    
## (Intercept)                      31.29186    0.84798   36.90  &amp;lt; 2e-16 ***
## marital_combmarried              16.13531    0.96385   16.74  &amp;lt; 2e-16 ***
## marital_combOther                -4.63978    1.50160   -3.09  0.00201 ** 
## marital_combdivorced              6.75490    1.11278    6.07 1.35e-09 ***
## I(height - mean(heights$height))  0.89847    0.08329   10.79  &amp;lt; 2e-16 ***
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1
## 
## Residual standard error: 27.78 on 6739 degrees of freedom
##   (262 observations deleted due to missingness)
## Multiple R-squared:  0.08467,    Adjusted R-squared:  0.08413 
## F-statistic: 155.8 on 4 and 6739 DF,  p-value: &amp;lt; 2.2e-16&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Notice that the mean effects do not change, but rather just the location of the intercept. This is a traditional analysis of covariance model.&lt;/p&gt;
&lt;p&gt;Interactions are simple to add now, they follow the same syntax as the categorical predictors from above. For example, if we wanted to add an interaction between height and marital status, we could do this as follows.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;summary(lm(afqt ~ marital_comb + I(height - mean(heights$height)) + 
             marital_comb:I(height - mean(heights$height)), 
           data = heights))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Call:
## lm(formula = afqt ~ marital_comb + I(height - mean(heights$height)) + 
##     marital_comb:I(height - mean(heights$height)), data = heights)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -53.768 -22.664  -4.183  21.972  78.762 
## 
## Coefficients:
##                                                       Estimate Std. Error
## (Intercept)                                           31.32214    0.84911
## marital_combmarried                                   16.08587    0.96531
## marital_combOther                                     -4.58940    1.53070
## marital_combdivorced                                   6.66304    1.11478
## I(height - mean(heights$height))                       0.76180    0.20923
## marital_combmarried:I(height - mean(heights$height))   0.22912    0.23745
## marital_combOther:I(height - mean(heights$height))     0.21641    0.37137
## marital_combdivorced:I(height - mean(heights$height)) -0.02469    0.27510
##                                                       t value Pr(&amp;gt;|t|)    
## (Intercept)                                            36.888  &amp;lt; 2e-16 ***
## marital_combmarried                                    16.664  &amp;lt; 2e-16 ***
## marital_combOther                                      -2.998 0.002725 ** 
## marital_combdivorced                                    5.977 2.39e-09 ***
## I(height - mean(heights$height))                        3.641 0.000274 ***
## marital_combmarried:I(height - mean(heights$height))    0.965 0.334624    
## marital_combOther:I(height - mean(heights$height))      0.583 0.560092    
## marital_combdivorced:I(height - mean(heights$height))  -0.090 0.928481    
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1
## 
## Residual standard error: 27.79 on 6736 degrees of freedom
##   (262 observations deleted due to missingness)
## Multiple R-squared:  0.08494,    Adjusted R-squared:  0.08399 
## F-statistic: 89.32 on 7 and 6736 DF,  p-value: &amp;lt; 2.2e-16&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;or&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;summary(lm(afqt ~ marital_comb * I(height - mean(heights$height)), data = heights))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Call:
## lm(formula = afqt ~ marital_comb * I(height - mean(heights$height)), 
##     data = heights)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -53.768 -22.664  -4.183  21.972  78.762 
## 
## Coefficients:
##                                                       Estimate Std. Error
## (Intercept)                                           31.32214    0.84911
## marital_combmarried                                   16.08587    0.96531
## marital_combOther                                     -4.58940    1.53070
## marital_combdivorced                                   6.66304    1.11478
## I(height - mean(heights$height))                       0.76180    0.20923
## marital_combmarried:I(height - mean(heights$height))   0.22912    0.23745
## marital_combOther:I(height - mean(heights$height))     0.21641    0.37137
## marital_combdivorced:I(height - mean(heights$height)) -0.02469    0.27510
##                                                       t value Pr(&amp;gt;|t|)    
## (Intercept)                                            36.888  &amp;lt; 2e-16 ***
## marital_combmarried                                    16.664  &amp;lt; 2e-16 ***
## marital_combOther                                      -2.998 0.002725 ** 
## marital_combdivorced                                    5.977 2.39e-09 ***
## I(height - mean(heights$height))                        3.641 0.000274 ***
## marital_combmarried:I(height - mean(heights$height))    0.965 0.334624    
## marital_combOther:I(height - mean(heights$height))      0.583 0.560092    
## marital_combdivorced:I(height - mean(heights$height))  -0.090 0.928481    
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1
## 
## Residual standard error: 27.79 on 6736 degrees of freedom
##   (262 observations deleted due to missingness)
## Multiple R-squared:  0.08494,    Adjusted R-squared:  0.08399 
## F-statistic: 89.32 on 7 and 6736 DF,  p-value: &amp;lt; 2.2e-16&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;What do these coefficients mean however? This is best explained with a picture.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;model_summary &amp;lt;- augment(lm(afqt ~ marital_comb * I(height - mean(heights$height)), 
                            data = heights))
model_summary &amp;lt;- rename(model_summary, &amp;#39;height_center&amp;#39; = `I(height - mean(heights$height))`)
model_summary&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 6,744 × 9
##    .rownames  afqt marital_comb height_center .fitted     .hat .sigma    .cooksd
##    &amp;lt;chr&amp;gt;     &amp;lt;dbl&amp;gt; &amp;lt;fct&amp;gt;             &amp;lt;I&amp;lt;dbl&amp;gt;&amp;gt;   &amp;lt;dbl&amp;gt;    &amp;lt;dbl&amp;gt;  &amp;lt;dbl&amp;gt;      &amp;lt;dbl&amp;gt;
##  1 1          6.84 married             -7.10     40.4 0.00115    27.8    2.09e-4
##  2 2         49.4  married              2.90     50.3 0.000390   27.8    4.39e-8
##  3 3         99.4  married             -2.10     45.3 0.000360   27.8    1.70e-4
##  4 4         44.0  married             -4.10     43.3 0.000576   27.8    4.33e-8
##  5 5         59.7  married             -1.10     46.3 0.000301   27.8    8.70e-6
##  6 6         98.8  divorced             0.896    38.6 0.000737   27.8    4.33e-4
##  7 7         82.3  married              6.90     54.2 0.00100    27.8    1.28e-4
##  8 8         50.3  divorced            -3.10     35.7 0.000976   27.8    3.37e-5
##  9 9         89.7  divorced             1.90     39.4 0.000884   27.8    3.63e-4
## 10 10        96.0  divorced             1.90     39.4 0.000884   27.8    4.59e-4
## # … with 6,734 more rows, and 1 more variable: .std.resid &amp;lt;dbl&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(model_summary, aes(height_center, afqt)) + 
  geom_jitter(alpha = .1) + 
  geom_line(aes(x = height_center, y = .fitted, color = marital_comb),
            size = 2) + 
  ylab(&amp;quot;Average Armed Forces Qualification Score&amp;quot;) + 
  xlab(&amp;quot;Height&amp;quot;) +
  theme_bw()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://psqf6250.brandonlebeau.org/rcode/adv-model_files/figure-html/augment-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;The figure for the traditional ANCOVA model initially explored would look like:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;model_summary &amp;lt;- augment(lm(afqt ~ marital_comb + I(height - mean(heights$height)), 
                            data = heights))
model_summary &amp;lt;- rename(model_summary, &amp;#39;height_center&amp;#39; = `I(height - mean(heights$height))`)
model_summary&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 6,744 × 9
##    .rownames  afqt marital_comb height_center .fitted     .hat .sigma    .cooksd
##    &amp;lt;chr&amp;gt;     &amp;lt;dbl&amp;gt; &amp;lt;fct&amp;gt;             &amp;lt;I&amp;lt;dbl&amp;gt;&amp;gt;   &amp;lt;dbl&amp;gt;    &amp;lt;dbl&amp;gt;  &amp;lt;dbl&amp;gt;      &amp;lt;dbl&amp;gt;
##  1 1          6.84 married             -7.10     41.0 0.000753   27.8    2.29e-4
##  2 2         49.4  married              2.90     50.0 0.000337   27.8    2.99e-8
##  3 3         99.4  married             -2.10     45.5 0.000320   27.8    2.41e-4
##  4 4         44.0  married             -4.10     43.7 0.000439   27.8    9.09e-9
##  5 5         59.7  married             -1.10     46.4 0.000288   27.8    1.31e-5
##  6 6         98.8  divorced             0.896    38.9 0.000684   27.8    6.38e-4
##  7 7         82.3  married              6.90     53.6 0.000674   27.8    1.44e-4
##  8 8         50.3  divorced            -3.10     35.3 0.000736   27.8    4.31e-5
##  9 9         89.7  divorced             1.90     39.7 0.000716   27.8    4.63e-4
## 10 10        96.0  divorced             1.90     39.7 0.000716   27.8    5.88e-4
## # … with 6,734 more rows, and 1 more variable: .std.resid &amp;lt;dbl&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(model_summary, aes(height_center, afqt)) + 
  geom_jitter(alpha = .1) + 
  geom_line(aes(x = height_center, y = .fitted, color = marital_comb),
            size = 2) + 
  ylab(&amp;quot;Average Armed Forces Qualification Score&amp;quot;) + 
  xlab(&amp;quot;Height&amp;quot;) +
  theme_bw()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://psqf6250.brandonlebeau.org/rcode/adv-model_files/figure-html/ancova_figure-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;div id=&#34;exercises-2&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Exercises&lt;/h4&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;Using the gss_cat data from the forcats package, fit a model that predicts age with marital status, tvhours, and the interaction between the two.&lt;/li&gt;
&lt;li&gt;Interpret the parameter estimates from this model? Is there evidence that the interaction is adding to the model?&lt;/li&gt;
&lt;li&gt;Create a figure that explores the interaction between the two variables.&lt;/li&gt;
&lt;li&gt;Fit another model that predicts age with marital status, party affiliation, and tvhours (main effects) as well as the interaction between marital status and tvhours and party afilliation and tvhours (two second order interactions).&lt;/li&gt;
&lt;li&gt;Interpret the effects for this model.&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Model Assumptions</title>
      <link>https://psqf6250.brandonlebeau.org/rcode/model-assumptions/</link>
      <pubDate>Wed, 17 Mar 2021 00:00:00 +0000</pubDate>
      <guid>https://psqf6250.brandonlebeau.org/rcode/model-assumptions/</guid>
      <description>
&lt;script src=&#34;https://psqf6250.brandonlebeau.org/rmarkdown-libs/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;

&lt;div id=&#34;TOC&#34;&gt;

&lt;/div&gt;

&lt;p&gt;I want to spend a little bit of time talking about model assumptions. These are important and should be checked for any analysis. The following packages will be used for this set of notes.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(modelr)
library(broom)
library(forcats)
library(tidyverse)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We are also going to use this model from the advanced model section to explore model assumptions.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;heights2 &amp;lt;- heights %&amp;gt;%
  mutate(
    marital_comb = fct_recode(marital,
          &amp;#39;Other&amp;#39; = &amp;#39;separated&amp;#39;,
          &amp;#39;Other&amp;#39; = &amp;#39;widowed&amp;#39;
    )
  )

afqt_mod &amp;lt;- lm(afqt ~ marital_comb + height, data = heights2)
summary(afqt_mod)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Call:
## lm(formula = afqt ~ marital_comb + height, data = heights2)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -53.150 -22.517  -4.248  22.097  78.355 
## 
## Coefficients:
##                       Estimate Std. Error t value Pr(&amp;gt;|t|)    
## (Intercept)          -28.99932    5.67144  -5.113 3.25e-07 ***
## marital_combmarried   16.13531    0.96385  16.741  &amp;lt; 2e-16 ***
## marital_combOther     -4.63978    1.50160  -3.090  0.00201 ** 
## marital_combdivorced   6.75490    1.11278   6.070 1.35e-09 ***
## height                 0.89847    0.08329  10.787  &amp;lt; 2e-16 ***
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1
## 
## Residual standard error: 27.78 on 6739 degrees of freedom
##   (262 observations deleted due to missingness)
## Multiple R-squared:  0.08467,    Adjusted R-squared:  0.08413 
## F-statistic: 155.8 on 4 and 6739 DF,  p-value: &amp;lt; 2.2e-16&lt;/code&gt;&lt;/pre&gt;
&lt;div id=&#34;plot-function-with-model-object&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;&lt;code&gt;plot&lt;/code&gt; function with model object&lt;/h2&gt;
&lt;p&gt;One of the nicest features when model building within R, is that many diagnostic plots are very accessible using the &lt;code&gt;plot&lt;/code&gt; function. For example:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;plot(afqt_mod)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://psqf6250.brandonlebeau.org/rcode/model-assumptions_files/figure-html/diag_plots-1.png&#34; width=&#34;672&#34; /&gt;&lt;img src=&#34;https://psqf6250.brandonlebeau.org/rcode/model-assumptions_files/figure-html/diag_plots-2.png&#34; width=&#34;672&#34; /&gt;&lt;img src=&#34;https://psqf6250.brandonlebeau.org/rcode/model-assumptions_files/figure-html/diag_plots-3.png&#34; width=&#34;672&#34; /&gt;&lt;img src=&#34;https://psqf6250.brandonlebeau.org/rcode/model-assumptions_files/figure-html/diag_plots-4.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;These plots are shown one at a time in an interactive R session, but allow you to check many common assumptions such as normal residuals, linearity, homogeneity of variance, and even leverage.&lt;/p&gt;
&lt;p&gt;You can see from these figures that there is quite a bit to be desired from our model. First, the residuals are not normally distributed (very heavy tails) and more problematic is that the residuals have a trend to them. This suggests that we are missing an important variable in the model.&lt;/p&gt;
&lt;p&gt;Suppose we add some additional variables to the model keeping the model additive. Note, I am also mean centering many of the continuous variables to ease interpretation slightly.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;heights2 &amp;lt;- heights2 %&amp;gt;%
  mutate(income2 = ifelse(income == 0, .001, income),
         height2 = height - mean(height, na.rm = TRUE),
         education2 = education - mean(education, na.rm = TRUE),
         weight2 = weight - mean(weight, na.rm = TRUE),
         log_income = log(income2))
afqt_alt &amp;lt;- lm(afqt ~ marital_comb + height2 + education2 + 
                 log_income + weight2, data = heights2)
summary(afqt_alt)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Call:
## lm(formula = afqt ~ marital_comb + height2 + education2 + log_income + 
##     weight2, data = heights2)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -80.466 -16.515  -2.036  16.088 101.730 
## 
## Coefficients:
##                       Estimate Std. Error t value Pr(&amp;gt;|t|)    
## (Intercept)          32.645765   0.717463  45.502  &amp;lt; 2e-16 ***
## marital_combmarried   9.312248   0.802952  11.598  &amp;lt; 2e-16 ***
## marital_combOther    -2.537031   1.231340  -2.060   0.0394 *  
## marital_combdivorced  4.790976   0.913836   5.243 1.63e-07 ***
## height2               0.781474   0.077526  10.080  &amp;lt; 2e-16 ***
## education2            5.911616   0.111848  52.854  &amp;lt; 2e-16 ***
## log_income            0.395176   0.038720  10.206  &amp;lt; 2e-16 ***
## weight2              -0.027669   0.007074  -3.911 9.27e-05 ***
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1
## 
## Residual standard error: 22.57 on 6637 degrees of freedom
##   (361 observations deleted due to missingness)
## Multiple R-squared:  0.3969, Adjusted R-squared:  0.3963 
## F-statistic:   624 on 7 and 6637 DF,  p-value: &amp;lt; 2.2e-16&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;plot(afqt_alt)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://psqf6250.brandonlebeau.org/rcode/model-assumptions_files/figure-html/diag2-1.png&#34; width=&#34;672&#34; /&gt;&lt;img src=&#34;https://psqf6250.brandonlebeau.org/rcode/model-assumptions_files/figure-html/diag2-2.png&#34; width=&#34;672&#34; /&gt;&lt;img src=&#34;https://psqf6250.brandonlebeau.org/rcode/model-assumptions_files/figure-html/diag2-3.png&#34; width=&#34;672&#34; /&gt;&lt;img src=&#34;https://psqf6250.brandonlebeau.org/rcode/model-assumptions_files/figure-html/diag2-4.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;We could continue to model this variable by including additional predictors or interactions between our current predictors to attempt to remove this strong trend in the residuals. I’m going to stop here however and move on to another topic.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;exploring-individual-residuals&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Exploring individual residuals&lt;/h2&gt;
&lt;p&gt;Evaluating all of the residuals in a single step using the &lt;code&gt;plot&lt;/code&gt; function can be useful initially to explore model quality. However, eventually it is useful to explore residuals for specific values to explore why these are large.&lt;/p&gt;
&lt;p&gt;There are a few options to do this, one uses the broom package, the other uses the modelr package. I show both below.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;aug_afqt &amp;lt;- augment(afqt_alt)
aug_afqt&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 6,645 × 13
##    .rownames  afqt marital_comb height2 education2 log_income weight2 .fitted
##    &amp;lt;chr&amp;gt;     &amp;lt;dbl&amp;gt; &amp;lt;fct&amp;gt;          &amp;lt;dbl&amp;gt;      &amp;lt;dbl&amp;gt;      &amp;lt;dbl&amp;gt;   &amp;lt;dbl&amp;gt;   &amp;lt;dbl&amp;gt;
##  1 1          6.84 married       -7.10      -0.218       9.85  -33.3     39.9
##  2 2         49.4  married        2.90      -3.22       10.5   -32.3     30.2
##  3 3         99.4  married       -2.10       2.78       11.6     6.70    61.1
##  4 4         44.0  married       -4.10       0.782      10.6     8.70    47.3
##  5 5         59.7  married       -1.10       0.782      11.2     1.70    50.1
##  6 6         98.8  divorced       0.896      4.78       11.5    11.7     70.6
##  7 7         82.3  married        6.90       2.78       -6.91   36.7     60.0
##  8 8         50.3  divorced      -3.10      -1.22       11.2   -28.3     33.0
##  9 9         89.7  divorced       1.90      -1.22       11.0   -26.3     36.8
## 10 10        96.0  divorced       1.90      -0.218      11.9     5.70    42.2
## # … with 6,635 more rows, and 5 more variables: .resid &amp;lt;dbl&amp;gt;, .hat &amp;lt;dbl&amp;gt;,
## #   .sigma &amp;lt;dbl&amp;gt;, .cooksd &amp;lt;dbl&amp;gt;, .std.resid &amp;lt;dbl&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;height_resid &amp;lt;- heights2 %&amp;gt;%
  add_residuals(afqt_alt) %&amp;gt;%
  add_predictions(afqt_alt)
height_resid&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 7,006 × 16
##    income height weight   age marital sex   education  afqt marital_comb income2
##     &amp;lt;int&amp;gt;  &amp;lt;dbl&amp;gt;  &amp;lt;int&amp;gt; &amp;lt;int&amp;gt; &amp;lt;fct&amp;gt;   &amp;lt;fct&amp;gt;     &amp;lt;int&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;fct&amp;gt;          &amp;lt;dbl&amp;gt;
##  1  19000     60    155    53 married fema…        13  6.84 married      1.9 e+4
##  2  35000     70    156    51 married fema…        10 49.4  married      3.5 e+4
##  3 105000     65    195    52 married male         16 99.4  married      1.05e+5
##  4  40000     63    197    54 married fema…        14 44.0  married      4   e+4
##  5  75000     66    190    49 married male         14 59.7  married      7.5 e+4
##  6 102000     68    200    49 divorc… fema…        18 98.8  divorced     1.02e+5
##  7      0     74    225    48 married male         16 82.3  married      1   e-3
##  8  70000     64    160    54 divorc… fema…        12 50.3  divorced     7   e+4
##  9  60000     69    162    55 divorc… male         12 89.7  divorced     6   e+4
## 10 150000     69    194    54 divorc… male         13 96.0  divorced     1.5 e+5
## # … with 6,996 more rows, and 6 more variables: height2 &amp;lt;dbl&amp;gt;,
## #   education2 &amp;lt;dbl&amp;gt;, weight2 &amp;lt;dbl&amp;gt;, log_income &amp;lt;dbl&amp;gt;, resid &amp;lt;dbl&amp;gt;, pred &amp;lt;dbl&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The benefit to the &lt;code&gt;augment&lt;/code&gt; function from the broom package is that it includes more information. The main benefit fo the &lt;code&gt;add_residuals&lt;/code&gt; function from the modelr pacakge is that it includes all of the original data, not just those variables included in the final model. Therefore if you are fitting a model and want to explore trends in residuals based on other data characteristics not currently in the model, using the &lt;code&gt;add_residuals&lt;/code&gt; function would likely be better for this use.&lt;/p&gt;
&lt;div id=&#34;filtering-and-plotting-residuals&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Filtering and Plotting Residuals&lt;/h3&gt;
&lt;p&gt;Now that we have these in a data frame, we could easily plot or filter residuals to explore cases in which the model is not adequatly fitting the dependent variable. For example, maybe we want to explore residuals greater than 50 in absolute value. This can easily be done with dplyr and the &lt;code&gt;filter&lt;/code&gt; function.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;filter(height_resid, abs(resid) &amp;gt; 50)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 113 × 16
##    income height weight   age marital sex   education  afqt marital_comb income2
##     &amp;lt;int&amp;gt;  &amp;lt;dbl&amp;gt;  &amp;lt;int&amp;gt; &amp;lt;int&amp;gt; &amp;lt;fct&amp;gt;   &amp;lt;fct&amp;gt;     &amp;lt;int&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;fct&amp;gt;          &amp;lt;dbl&amp;gt;
##  1  60000     69    162    55 divorc… male         12  89.7 divorced      6  e+4
##  2 150000     69    194    54 divorc… male         13  96.0 divorced      1.5e+5
##  3  45000     69    240    53 married male         12  98.8 married       4.5e+4
##  4      0     66    195    50 married fema…        14  99.2 married       1  e-3
##  5  93000     68    182    48 divorc… male         12  86.9 divorced      9.3e+4
##  6  43000     64    145    51 divorc… fema…        12  94.8 divorced      4.3e+4
##  7  52000     72    230    52 married male         12  93.1 married       5.2e+4
##  8  35000     59    165    49 divorc… fema…        12  80.0 divorced      3.5e+4
##  9  85000     61    140    55 married fema…        18  15.7 married       8.5e+4
## 10      0     69    186    55 separa… fema…        12  88.8 Other         1  e-3
## # … with 103 more rows, and 6 more variables: height2 &amp;lt;dbl&amp;gt;, education2 &amp;lt;dbl&amp;gt;,
## #   weight2 &amp;lt;dbl&amp;gt;, log_income &amp;lt;dbl&amp;gt;, resid &amp;lt;dbl&amp;gt;, pred &amp;lt;dbl&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;You can also plot residuals directly or compared to other predictors.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(height_resid, aes(resid)) + 
  geom_histogram() + 
  theme_bw() + 
  xlab(&amp;quot;Residuals&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning: Removed 361 rows containing non-finite values (stat_bin).&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://psqf6250.brandonlebeau.org/rcode/model-assumptions_files/figure-html/hist_resid-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(height_resid, aes(resid, education2)) + 
  geom_point(size = 3) + 
  geom_smooth(size = 1, se = FALSE) + 
  xlab(&amp;quot;Residuals&amp;quot;) + 
  ylab(&amp;quot;Education (mean centered)&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## `geom_smooth()` using method = &amp;#39;gam&amp;#39; and formula &amp;#39;y ~ s(x, bs = &amp;quot;cs&amp;quot;)&amp;#39;&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning: Removed 361 rows containing non-finite values (stat_smooth).&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning: Removed 361 rows containing missing values (geom_point).&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://psqf6250.brandonlebeau.org/rcode/model-assumptions_files/figure-html/residual_predictor-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Miscellaneous Modeling Topics</title>
      <link>https://psqf6250.brandonlebeau.org/rcode/misc-model/</link>
      <pubDate>Wed, 17 Mar 2021 00:00:00 +0000</pubDate>
      <guid>https://psqf6250.brandonlebeau.org/rcode/misc-model/</guid>
      <description>
&lt;script src=&#34;https://psqf6250.brandonlebeau.org/rmarkdown-libs/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;

&lt;div id=&#34;TOC&#34;&gt;

&lt;/div&gt;

&lt;p&gt;I want to spend a little bit of time talking about ways to model non-linear trends within a linear model as well as show an example of conducting a logistic regression within R using the &lt;code&gt;glm&lt;/code&gt; function. This set of notes will use the following packages:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(modelr)
library(broom)
library(forcats)
library(tidyverse)&lt;/code&gt;&lt;/pre&gt;
&lt;div id=&#34;modeling-non-linear-trends&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Modeling non-linear trends&lt;/h2&gt;
&lt;p&gt;Modeling non-linear trends can be important and a great way to increase variance explained. There are many ways to model non-linear trends, including non-linear models, but I am going to focus on a linear modeling framework to include non-linear trends by adding quadratic terms.&lt;/p&gt;
&lt;p&gt;These types of models are flexible and relatively easy to interpret, however have the drawback that prediction outside of the data at hand (extrapolation) can be problematic. Using the final model from the model assumptions lecture, lets see if we can improve model fit and the trend in the residuals by adding some non-linearity in the form of quadratic terms.&lt;/p&gt;
&lt;p&gt;If you recall, here is the model that was used last time.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;heights2 &amp;lt;- heights %&amp;gt;%
  mutate(
    marital_comb = fct_recode(marital,
                              &amp;#39;Other&amp;#39; = &amp;#39;separated&amp;#39;,
                              &amp;#39;Other&amp;#39; = &amp;#39;widowed&amp;#39;
    ),
    income2 = ifelse(income == 0, .001, income),
    height2 = height - mean(height, na.rm = TRUE),
    education2 = education - mean(education, na.rm = TRUE),
    weight2 = weight - mean(weight, na.rm = TRUE),
    log_income = log(income2)
  )
afqt_alt &amp;lt;- lm(afqt ~ marital_comb + height2 + education2 + 
                 log_income + weight2, data = heights2)
summary(afqt_alt)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Call:
## lm(formula = afqt ~ marital_comb + height2 + education2 + log_income + 
##     weight2, data = heights2)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -80.466 -16.515  -2.036  16.088 101.730 
## 
## Coefficients:
##                       Estimate Std. Error t value Pr(&amp;gt;|t|)    
## (Intercept)          32.645765   0.717463  45.502  &amp;lt; 2e-16 ***
## marital_combmarried   9.312248   0.802952  11.598  &amp;lt; 2e-16 ***
## marital_combOther    -2.537031   1.231340  -2.060   0.0394 *  
## marital_combdivorced  4.790976   0.913836   5.243 1.63e-07 ***
## height2               0.781474   0.077526  10.080  &amp;lt; 2e-16 ***
## education2            5.911616   0.111848  52.854  &amp;lt; 2e-16 ***
## log_income            0.395176   0.038720  10.206  &amp;lt; 2e-16 ***
## weight2              -0.027669   0.007074  -3.911 9.27e-05 ***
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1
## 
## Residual standard error: 22.57 on 6637 degrees of freedom
##   (361 observations deleted due to missingness)
## Multiple R-squared:  0.3969, Adjusted R-squared:  0.3963 
## F-statistic:   624 on 7 and 6637 DF,  p-value: &amp;lt; 2.2e-16&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Let’s see if there are non-linear trends in the height, weight, or income variables. I am going to add these by specifically creating additional variables and using these as new predictors. You could also create these by using the insulate function &lt;code&gt;I()&lt;/code&gt; to do the operation within the model syntax.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;heights2 &amp;lt;- heights2 %&amp;gt;%
  mutate(
    height2_quad = height2 ^ 2,
    weight2_quad = weight2 ^ 2, 
    log_income_quad = log_income ^ 2,
    education2_quad = education2 ^ 2
  )
afqt_alt &amp;lt;- lm(afqt ~ marital_comb + height2 + education2 + 
                 log_income + weight2 + education2_quad +
                 height2_quad + weight2_quad + log_income_quad, 
               data = heights2)
summary(afqt_alt)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Call:
## lm(formula = afqt ~ marital_comb + height2 + education2 + log_income + 
##     weight2 + education2_quad + height2_quad + weight2_quad + 
##     log_income_quad, data = heights2)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -77.098 -16.265  -2.331  15.587  91.339 
## 
## Coefficients:
##                        Estimate Std. Error t value Pr(&amp;gt;|t|)    
## (Intercept)           1.665e+01  1.598e+00  10.419  &amp;lt; 2e-16 ***
## marital_combmarried   8.340e+00  7.993e-01  10.434  &amp;lt; 2e-16 ***
## marital_combOther    -2.604e+00  1.218e+00  -2.137   0.0326 *  
## marital_combdivorced  4.262e+00  9.061e-01   4.703 2.61e-06 ***
## height2               7.488e-01  7.967e-02   9.399  &amp;lt; 2e-16 ***
## education2            5.467e+00  1.173e-01  46.609  &amp;lt; 2e-16 ***
## log_income           -3.828e-01  8.307e-02  -4.609 4.12e-06 ***
## weight2              -4.652e-02  8.046e-03  -5.782 7.72e-09 ***
## education2_quad       5.535e-02  2.488e-02   2.224   0.0262 *  
## height2_quad         -3.018e-02  1.392e-02  -2.169   0.0302 *  
## weight2_quad          4.135e-04  8.359e-05   4.947 7.73e-07 ***
## log_income_quad       2.177e-01  2.018e-02  10.791  &amp;lt; 2e-16 ***
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1
## 
## Residual standard error: 22.33 on 6633 degrees of freedom
##   (361 observations deleted due to missingness)
## Multiple R-squared:  0.4102, Adjusted R-squared:  0.4092 
## F-statistic: 419.3 on 11 and 6633 DF,  p-value: &amp;lt; 2.2e-16&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Alternatively, this model could look like:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;afqt_alt &amp;lt;- lm(afqt ~ marital_comb + height2 + education2 + 
                 log_income + weight2 + I(education2^2) +
                 I(height2^2) + I(weight2^2) + I(log_income^2), 
               data = heights2)
summary(afqt_alt)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Call:
## lm(formula = afqt ~ marital_comb + height2 + education2 + log_income + 
##     weight2 + I(education2^2) + I(height2^2) + I(weight2^2) + 
##     I(log_income^2), data = heights2)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -77.098 -16.265  -2.331  15.587  91.339 
## 
## Coefficients:
##                        Estimate Std. Error t value Pr(&amp;gt;|t|)    
## (Intercept)           1.665e+01  1.598e+00  10.419  &amp;lt; 2e-16 ***
## marital_combmarried   8.340e+00  7.993e-01  10.434  &amp;lt; 2e-16 ***
## marital_combOther    -2.604e+00  1.218e+00  -2.137   0.0326 *  
## marital_combdivorced  4.262e+00  9.061e-01   4.703 2.61e-06 ***
## height2               7.488e-01  7.967e-02   9.399  &amp;lt; 2e-16 ***
## education2            5.467e+00  1.173e-01  46.609  &amp;lt; 2e-16 ***
## log_income           -3.828e-01  8.307e-02  -4.609 4.12e-06 ***
## weight2              -4.652e-02  8.046e-03  -5.782 7.72e-09 ***
## I(education2^2)       5.535e-02  2.488e-02   2.224   0.0262 *  
## I(height2^2)         -3.018e-02  1.392e-02  -2.169   0.0302 *  
## I(weight2^2)          4.135e-04  8.359e-05   4.947 7.73e-07 ***
## I(log_income^2)       2.177e-01  2.018e-02  10.791  &amp;lt; 2e-16 ***
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1
## 
## Residual standard error: 22.33 on 6633 degrees of freedom
##   (361 observations deleted due to missingness)
## Multiple R-squared:  0.4102, Adjusted R-squared:  0.4092 
## F-statistic: 419.3 on 11 and 6633 DF,  p-value: &amp;lt; 2.2e-16&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Let’s see if this improved our model fit.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;plot(afqt_alt)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://psqf6250.brandonlebeau.org/rcode/misc-model_files/figure-html/assumpt-1.png&#34; width=&#34;672&#34; /&gt;&lt;img src=&#34;https://psqf6250.brandonlebeau.org/rcode/misc-model_files/figure-html/assumpt-2.png&#34; width=&#34;672&#34; /&gt;&lt;img src=&#34;https://psqf6250.brandonlebeau.org/rcode/misc-model_files/figure-html/assumpt-3.png&#34; width=&#34;672&#34; /&gt;&lt;img src=&#34;https://psqf6250.brandonlebeau.org/rcode/misc-model_files/figure-html/assumpt-4.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;We could also attempt to convert the dependent variable (in a percentile metric) to a z-score.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;heights2 &amp;lt;- heights2 %&amp;gt;%
  mutate(
    afqt2 = ifelse(afqt == 0, .00001, ifelse(afqt == 100, 99.9999999, afqt)),
    afqt3 = ifelse(afqt %in% c(0, 100), NA, afqt),
    afqt_z = qnorm(afqt2/100),
    afqt_z3 = qnorm(afqt3/100)
  )
afqt_alt2 &amp;lt;- lm(afqt_z3 ~ marital_comb + height2 + education2 + 
                 log_income + weight2 + education2_quad +
                 height2_quad + weight2_quad + log_income_quad, 
               data = heights2)
summary(afqt_alt2)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Call:
## lm(formula = afqt_z3 ~ marital_comb + height2 + education2 + 
##     log_income + weight2 + education2_quad + height2_quad + weight2_quad + 
##     log_income_quad, data = heights2)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -2.8910 -0.5105 -0.0064  0.4966  3.2479 
## 
## Coefficients:
##                        Estimate Std. Error t value Pr(&amp;gt;|t|)    
## (Intercept)          -1.119e+00  5.576e-02 -20.069  &amp;lt; 2e-16 ***
## marital_combmarried   2.942e-01  2.782e-02  10.576  &amp;lt; 2e-16 ***
## marital_combOther    -9.070e-02  4.242e-02  -2.138 0.032536 *  
## marital_combdivorced  1.701e-01  3.152e-02   5.395 7.09e-08 ***
## height2               2.506e-02  2.769e-03   9.051  &amp;lt; 2e-16 ***
## education2            1.933e-01  4.133e-03  46.769  &amp;lt; 2e-16 ***
## log_income           -1.075e-02  2.897e-03  -3.710 0.000209 ***
## weight2              -1.640e-03  2.800e-04  -5.859 4.88e-09 ***
## education2_quad      -5.433e-04  8.880e-04  -0.612 0.540682    
## height2_quad         -1.316e-03  4.838e-04  -2.720 0.006545 ** 
## weight2_quad          1.508e-05  2.906e-06   5.192 2.15e-07 ***
## log_income_quad       7.100e-03  7.042e-04  10.083  &amp;lt; 2e-16 ***
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1
## 
## Residual standard error: 0.7745 on 6588 degrees of freedom
##   (406 observations deleted due to missingness)
## Multiple R-squared:  0.4088, Adjusted R-squared:  0.4078 
## F-statistic: 414.1 on 11 and 6588 DF,  p-value: &amp;lt; 2.2e-16&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;plot(afqt_alt2)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://psqf6250.brandonlebeau.org/rcode/misc-model_files/figure-html/asumpt2-1.png&#34; width=&#34;672&#34; /&gt;&lt;img src=&#34;https://psqf6250.brandonlebeau.org/rcode/misc-model_files/figure-html/asumpt2-2.png&#34; width=&#34;672&#34; /&gt;&lt;img src=&#34;https://psqf6250.brandonlebeau.org/rcode/misc-model_files/figure-html/asumpt2-3.png&#34; width=&#34;672&#34; /&gt;&lt;img src=&#34;https://psqf6250.brandonlebeau.org/rcode/misc-model_files/figure-html/asumpt2-4.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;glm-function&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;&lt;code&gt;glm&lt;/code&gt; function&lt;/h2&gt;
&lt;p&gt;The &lt;code&gt;glm&lt;/code&gt; function behaves much like the &lt;code&gt;lm&lt;/code&gt; function. The only major difference in model logistics is that we will now need to specify a family argument. This family argument will depend on the type of model being fitted. We are going to perform a logistic regression, therefore this family will be binomial.&lt;/p&gt;
&lt;p&gt;The data we will use is from Kaggle and is data from Titanic, more specifically the data has characteristics on the passengers and whether they survived the shipwreck or not. You can get a sense of the variables from this website: &lt;a href=&#34;https://www.kaggle.com/c/titanic/data&#34; class=&#34;uri&#34;&gt;https://www.kaggle.com/c/titanic/data&lt;/a&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(titanic)

titanic &amp;lt;- bind_rows(titanic_test,
                     titanic_train)
head(titanic)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##   PassengerId Pclass                                         Name    Sex  Age
## 1         892      3                             Kelly, Mr. James   male 34.5
## 2         893      3             Wilkes, Mrs. James (Ellen Needs) female 47.0
## 3         894      2                    Myles, Mr. Thomas Francis   male 62.0
## 4         895      3                             Wirz, Mr. Albert   male 27.0
## 5         896      3 Hirvonen, Mrs. Alexander (Helga E Lindqvist) female 22.0
## 6         897      3                   Svensson, Mr. Johan Cervin   male 14.0
##   SibSp Parch  Ticket    Fare Cabin Embarked Survived
## 1     0     0  330911  7.8292              Q       NA
## 2     1     0  363272  7.0000              S       NA
## 3     0     0  240276  9.6875              Q       NA
## 4     0     0  315154  8.6625              S       NA
## 5     1     1 3101298 12.2875              S       NA
## 6     0     0    7538  9.2250              S       NA&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Suppose we were interested in fitting a model that predicted whether a passenger survived or not. Using &lt;code&gt;lm&lt;/code&gt; is not appropriate as the dependent variable is not continuous, rather it is dichotomous. Using logistic regression is more appropriate here.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;surv_mod &amp;lt;- glm(Survived ~ factor(Pclass) + Fare + Sex + Age, 
                data = titanic, 
                family = binomial)
summary(surv_mod)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Call:
## glm(formula = Survived ~ factor(Pclass) + Fare + Sex + Age, family = binomial, 
##     data = titanic)
## 
## Deviance Residuals: 
##     Min       1Q   Median       3Q      Max  
## -2.7393  -0.6788  -0.3956   0.6486   2.4639  
## 
## Coefficients:
##                   Estimate Std. Error z value Pr(&amp;gt;|z|)    
## (Intercept)      3.7225052  0.4645113   8.014 1.11e-15 ***
## factor(Pclass)2 -1.2765903  0.3126370  -4.083 4.44e-05 ***
## factor(Pclass)3 -2.5415762  0.3277677  -7.754 8.89e-15 ***
## Fare             0.0005226  0.0022579   0.231    0.817    
## Sexmale         -2.5185052  0.2082017 -12.096  &amp;lt; 2e-16 ***
## Age             -0.0367302  0.0077325  -4.750 2.03e-06 ***
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 964.52  on 713  degrees of freedom
## Residual deviance: 647.23  on 708  degrees of freedom
##   (595 observations deleted due to missingness)
## AIC: 659.23
## 
## Number of Fisher Scoring iterations: 5&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;It is common to interpret these in terms of probability, we can do this with the following bit of code:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;prob_mod &amp;lt;- titanic %&amp;gt;%
  select(Survived, Pclass, Fare, Sex, Age) %&amp;gt;%
  na.omit() %&amp;gt;%
  mutate(
    probability = predict(surv_mod, type = &amp;#39;response&amp;#39;)
  )

head(prob_mod, n = 15)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##     Survived Pclass    Fare    Sex Age probability
## 419        0      3  7.2500   male  22  0.10509514
## 420        1      1 71.2833 female  38  0.91404126
## 421        1      3  7.9250 female  26  0.55726903
## 422        1      1 53.1000 female  35  0.92162960
## 423        0      3  8.0500   male  35  0.06793029
## 425        0      1 51.8625   male  54  0.32031425
## 426        0      3 21.0750   male   2  0.19781236
## 427        1      3 11.1333 female  27  0.54860408
## 428        1      2 30.0708 female  14  0.87516354
## 429        1      3 16.7000 female   4  0.73937738
## 430        1      1 26.5500 female  58  0.83285937
## 431        0      3  8.0500   male  20  0.11224887
## 432        0      3 31.2750   male  39  0.05987747
## 433        0      3  7.8542 female  14  0.66168470
## 434        1      2 16.0000 female  55  0.60685621&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We could now plot these probabilities to explore the effects.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(prob_mod, aes(Age, probability, color = Sex, linetype = Sex)) + 
  geom_line(size = 1) + 
  facet_grid(. ~ Pclass) + 
  theme_bw() + 
  xlab(&amp;quot;Age&amp;quot;) + 
  ylab(&amp;quot;Probability of Survival&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://psqf6250.brandonlebeau.org/rcode/misc-model_files/figure-html/prob_plot-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
  </channel>
</rss>
