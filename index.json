[{"authors":["admin"],"categories":null,"content":"\nThis course aims to give students an in depth exploration of using R for data science and statistical analysis. The course is hands on where students will spend time practicing what they learn with real data to explore real problems. Students will gain experience cleaning, manipulating, visualizing, describing, exploring, and analyzing data from various perspectives. Students will also explore the benefits of reproducible analyses using R markdown documents to weave statistical code with text. Additional topics such as version control, markdown, and bootstrap will be discussed. This course will not teach you exactly what to do for every analysis, rather will attempt to give you tools to accomplish general data tasks and practice answering questions with data.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"https://psqf6250.brandonlebeau.org/authors/admin/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/admin/","section":"authors","summary":"This course aims to give students an in depth exploration of using R for data science and statistical analysis. The course is hands on where students will spend time practicing what they learn with real data to explore real problems.","tags":null,"title":"","type":"authors"},{"authors":["brandon"],"categories":null,"content":"\nI\u0026rsquo;m interested in computational methods, longitudinal data, and statistical software development with R. You can see more about my interests on my website: https://brandonlebeau.org/.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"a6b366d06474d85d9f788b8d18e8310d","permalink":"https://psqf6250.brandonlebeau.org/authors/brandon/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/brandon/","section":"authors","summary":"I\u0026rsquo;m interested in computational methods, longitudinal data, and statistical software development with R. You can see more about my interests on my website: https://brandonlebeau.org/.","tags":null,"title":"","type":"authors"},{"authors":null,"categories":null,"content":"A list of the various R syntax for the semester are collected in this page.\n","date":1612137600,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1612137600,"objectID":"2b0562cceadd5b9e8843464c13310145","permalink":"https://psqf6250.brandonlebeau.org/rcode/","publishdate":"2021-02-01T00:00:00Z","relpermalink":"/rcode/","section":"rcode","summary":"R Course Syntax","tags":null,"title":"R Syntax","type":"book"},{"authors":null,"categories":null,"content":"The course content will be organized by weeks. Each week will contain some text to:\n discuss the goals of the week the content to be covered relevant R syntax/notebook files pre-recorded videos.  Each week may also contain some information about assignments and links directly to those.\n","date":1611532800,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1611532800,"objectID":"d5be68294f12f9cfecf81ad87009adc6","permalink":"https://psqf6250.brandonlebeau.org/content/","publishdate":"2021-01-25T00:00:00Z","relpermalink":"/content/","section":"content","summary":"Course Content","tags":null,"title":"Content","type":"book"},{"authors":null,"categories":null,"content":"Here you can view all of the course assignments for the semester. This will include the hands on assignments and the quizzes. The quizzes will provide a link to ICON to complete.\n","date":1610064000,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1610064000,"objectID":"5d370553e45c580541e007200292c8d8","permalink":"https://psqf6250.brandonlebeau.org/assignments/","publishdate":"2021-01-08T00:00:00Z","relpermalink":"/assignments/","section":"assignments","summary":"Course Requirements","tags":null,"title":"Course Requirements","type":"book"},{"authors":null,"categories":null,"content":"The course schedule for the semester. There will be a single page for each week of the course. These weeks will include all materials, highlight the course objectives for that week, include pre-recorded video lectures, include links to any assignments/quizzes that can be completed, lecture notes, and other external readings.\n","date":1610064000,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1610064000,"objectID":"ee8dfa775d2ca48042bf50fe0819e70c","permalink":"https://psqf6250.brandonlebeau.org/schedule/","publishdate":"2021-01-08T00:00:00Z","relpermalink":"/schedule/","section":"schedule","summary":"Course schedule","tags":null,"title":"Schedule","type":"book"},{"authors":null,"categories":null,"content":"","date":1610064000,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1610064000,"objectID":"5538b9800f06ab7b29edaa22ab7e63cb","permalink":"https://psqf6250.brandonlebeau.org/syllabus/","publishdate":"2021-01-08T00:00:00Z","relpermalink":"/syllabus/","section":"syllabus","summary":"Course syllabus","tags":null,"title":"Syllabus","type":"book"},{"authors":null,"categories":null,"content":"","date":1610064000,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1610064000,"objectID":"148b0563112c2a9006e85ec08153b0ce","permalink":"https://psqf6250.brandonlebeau.org/assignments/assignment/","publishdate":"2021-01-08T00:00:00Z","relpermalink":"/assignments/assignment/","section":"assignments","summary":"Course Assignments","tags":null,"title":"Assignments","type":"book"},{"authors":null,"categories":null,"content":"Below are the course quizzes.\n","date":1610064000,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1610064000,"objectID":"9ee2f1578158bc73334dba690602f1a2","permalink":"https://psqf6250.brandonlebeau.org/assignments/quizzes/","publishdate":"2021-01-08T00:00:00Z","relpermalink":"/assignments/quizzes/","section":"assignments","summary":"Course Quizzes","tags":null,"title":"Quizzes","type":"book"},{"authors":null,"categories":null,"content":"","date":1610064000,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1610064000,"objectID":"99f302b9e9cee92740f853ade9eda986","permalink":"https://psqf6250.brandonlebeau.org/assignments/project/","publishdate":"2021-01-08T00:00:00Z","relpermalink":"/assignments/project/","section":"assignments","summary":"Course Project","tags":null,"title":"Project","type":"book"},{"authors":null,"categories":null,"content":"   We are going to start by exploring graphics with R using the midwest data. To access this data, run the following commands:\ninstall.packages(\u0026quot;tidyverse\u0026quot;) library(tidyverse) Suppose we were interested in exploring the question: How does population density influence the percentage of the population with at least a college degree? Let’s explore these data closer.\nmidwest ## # A tibble: 437 x 28 ## PID county state area poptotal popdensity popwhite popblack popamerindian ## \u0026lt;int\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;int\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;int\u0026gt; \u0026lt;int\u0026gt; \u0026lt;int\u0026gt; ## 1 561 ADAMS IL 0.052 66090 1271. 63917 1702 98 ## 2 562 ALEXA… IL 0.014 10626 759 7054 3496 19 ## 3 563 BOND IL 0.022 14991 681. 14477 429 35 ## 4 564 BOONE IL 0.017 30806 1812. 29344 127 46 ## 5 565 BROWN IL 0.018 5836 324. 5264 547 14 ## 6 566 BUREAU IL 0.05 35688 714. 35157 50 65 ## 7 567 CALHO… IL 0.017 5322 313. 5298 1 8 ## 8 568 CARRO… IL 0.027 16805 622. 16519 111 30 ## 9 569 CASS IL 0.024 13437 560. 13384 16 8 ## 10 570 CHAMP… IL 0.058 173025 2983. 146506 16559 331 ## # … with 427 more rows, and 19 more variables: popasian \u0026lt;int\u0026gt;, popother \u0026lt;int\u0026gt;, ## # percwhite \u0026lt;dbl\u0026gt;, percblack \u0026lt;dbl\u0026gt;, percamerindan \u0026lt;dbl\u0026gt;, percasian \u0026lt;dbl\u0026gt;, ## # percother \u0026lt;dbl\u0026gt;, popadults \u0026lt;int\u0026gt;, perchsd \u0026lt;dbl\u0026gt;, percollege \u0026lt;dbl\u0026gt;, ## # percprof \u0026lt;dbl\u0026gt;, poppovertyknown \u0026lt;int\u0026gt;, percpovertyknown \u0026lt;dbl\u0026gt;, ## # percbelowpoverty \u0026lt;dbl\u0026gt;, percchildbelowpovert \u0026lt;dbl\u0026gt;, percadultpoverty \u0026lt;dbl\u0026gt;, ## # percelderlypoverty \u0026lt;dbl\u0026gt;, inmetro \u0026lt;int\u0026gt;, category \u0026lt;chr\u0026gt; This will bring up the first 10 rows of the data (hiding the additional 8,592) rows. A first common step to explore our research question is to plot the data. To do this we are going to use the R package, ggplot2, which was installed when running the install.packages command above. You can explore the midwest data by calling up the help file as well with ?midwest.\nCreate a ggplot To plot these two variables from the midwest data, we will use the function ggplot and geom_point to add a layer of points. We will treat popdensity as the x variable and percollege as the y variable.\nggplot(data = midwest) + geom_point(mapping = aes(x = popdensity, y = percollege)) Examples Try plotting popdensity by state. Try plotting county by state. Does this plot work? Bonus: Try just using the ggplot(data = midwest) from above. What do you get? Does this make sense?  Note: You should be able to modify the structure of the code above to do this.\n  Add Aesthetics Aesthetics are a way to explore more complex interactions within the data. Particularly, from the above example, lets add in the state variable to the plot via an aesthetic.\nggplot(data = midwest) + geom_point(mapping = aes(x = popdensity, y = percollege, color = state)) As you can see, we simply colored the points by the state they belong in. Does there appear to be a trend?\nExamples Using the same aesthetic structure as above, instead of using colors, make the shape of the points different for each state. Instead of color, use alpha instead. What does this do to the plot?    Global Aesthetics Above, we specified a variable to an aesthetic, which is a common use of aesthetics. However, the aesthetics can also be assigned globally. Here are two examples using the first scatterplot created.\nggplot(data = midwest) + geom_point(mapping = aes(x = popdensity, y = percollege), color = \u0026#39;pink\u0026#39;) ggplot(data = midwest) + geom_point(mapping = aes(x = popdensity, y = percollege), shape = 15) These two plots changed the aesthetics for all of the points. Notice, the suttle difference between the code for these plots and that for the plot above. The placement of the aesthetic is crucial, if it is within the parentheses for aes() then it should be assigned a variable. If it is outside, as in the last two examples, it will define the aesthetic for all the data.\nExamples Try the following command: colors(). This will print a vector of all the color names within R, try a few to find your favorites. What happens if you use the following code:  ggplot(data = midwest) + geom_point(mapping = aes(x = popdensity, y = percollege, color = \u0026#39;green\u0026#39;)) What is the problem?\n  Facets Instead of defining an aesthetic to change the color or shape of points by a third variable, we can also plot each groups data in a single plot and combine them. The process is easy with ggplot2 by using facets.\nggplot(data = midwest) + geom_point(mapping = aes(x = popdensity, y = percollege)) + facet_grid(. ~ state) You can also use facet_wrap.\nggplot(data = midwest) + geom_point(mapping = aes(x = popdensity, y = percollege)) + facet_wrap(~ state) Examples Can you facet with a continuous variable? Try it!    Geoms ggplot2 uses a grammar of graphics which makes it easy to switch different plot types (called geoms) once you are comfortable with the basic syntax. For example, how does the following plot differ from the scatterplot first generated above? What is similar?\nggplot(data = midwest) + geom_smooth(mapping = aes(x = popdensity, y = percollege)) We can also do this plot by states\nggplot(data = midwest) + geom_smooth(mapping = aes(x = popdensity, y = percollege, linetype = state), se = FALSE) What about the code above gave me the different lines for each state? Note, I also removed the standard error shading from the plot as well.\nExamples It is possible to combine geoms, which we will do next, but try it first. Try to recreate this plot.     Combining multiple geoms Combining more than one geom into a single plot is relatively straightforward, but a few considerations are important. Essentially to do the task, we just simply need to combine the two geoms we have used:\nggplot(data = midwest) + geom_point(aes(x = popdensity, y = percollege, color = state)) + geom_smooth(mapping = aes(x = popdensity, y = percollege, color = state), se = FALSE) A couple points about combining geoms, first, the order matters. In the above example, we called geom_point first, then geom_smooth. When plotting these data, the points will then be plotted first followed by the lines. Try flipping the order of the two geoms to see how the plot differs.\nWe can also simplify this code to not duplicate typing:\nggplot(data = midwest, mapping = aes(x = popdensity, y = percollege, color = state)) + geom_point() + geom_smooth(se = FALSE) Examples Can you recreate the following figure?     Other geom examples There are many other geoms available to use. To see them all, visit http://docs.ggplot2.org/current/index.html which gives examples of all the possibilities. This is a handy resource that I keep going back to.\nGeoms for single variables The introduction to plotting has been with two variables, but lets take a step back and focus on one variable with a bar chart.\nggplot(data = midwest, mapping = aes(x = state)) + geom_bar() You can also easily add aesthetics this base plot as shown before.\nggplot(data = midwest, mapping = aes(x = state)) + geom_bar(aes(fill = factor(inmetro))) A few additions can help interpretation of this plot:\nggplot(data = midwest, mapping = aes(x = state)) + geom_bar(aes(fill = factor(inmetro)), position = \u0026#39;fill\u0026#39;) ggplot(data = midwest, mapping = aes(x = state)) + geom_bar(aes(fill = factor(inmetro)), position = \u0026#39;dodge\u0026#39;) It is also possible to do a histrogram of a quantitative variable:\nggplot(data = midwest, mapping = aes(x = popdensity)) + geom_histogram() ## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`. You can adjust the binwidth directly:\nggplot(data = midwest, mapping = aes(x = popdensity)) + geom_histogram(binwidth = 1000)  Examples With more than two groups, histograms are difficult to interpret due to overlap. Instead, use the geom_density to create a density plot for popdensity for each state. The final plot should look similar to this:  Using geom_boxplot, create boxplots with popdensity as the y variable and state as the x variable. Bonus: facet this plot by the variable inmetro.     Plot Customization There are many many ways to adjust the look of the plot, I will discuss a few that are common.\nChange axes Axes are something that are commonly altered, particularly to give them a good name and also to alter the values shown on the axes. These are generally done with scale_x_* and scale_y_* where * is a filler based on the type of variable on the axes.\nFor example:\nggplot(data = midwest, mapping = aes(x = popdensity, y = percollege, color = state)) + geom_point() + scale_x_continuous(\u0026quot;Population Density\u0026quot;) + scale_y_continuous(\u0026quot;Percent College Graduates\u0026quot;) To change the legend title, the scale_color_discrete command can be used to adjust the color aesthetic and the variable is discrete.\nggplot(data = midwest, mapping = aes(x = popdensity, y = percollege, color = state)) + geom_point() + scale_x_continuous(\u0026quot;Population Density\u0026quot;) + scale_y_continuous(\u0026quot;Percent College Graduates\u0026quot;) + scale_color_discrete(\u0026quot;State\u0026quot;) we can also alter the breaks showing on the x-axis.\nggplot(data = midwest, mapping = aes(x = popdensity, y = percollege, color = state)) + geom_point() + scale_x_continuous(\u0026quot;Population Density\u0026quot;, breaks = seq(0, 80000, 20000)) + scale_y_continuous(\u0026quot;Percent College Graduates\u0026quot;) + scale_color_discrete(\u0026quot;State\u0026quot;)   Zoom in on plot You’ll notice that there are outliers in this scatterplot due to larger population density values for some counties. It may be of interest to zoom in on the plot. The plot can be zoomed in by using the coord_cartesian command as follows.\nggplot(data = midwest, mapping = aes(x = popdensity, y = percollege, color = state)) + geom_point() + scale_x_continuous(\u0026quot;Population Density\u0026quot;) + scale_y_continuous(\u0026quot;Percent College Graduates\u0026quot;) + scale_color_discrete(\u0026quot;State\u0026quot;) + coord_cartesian(xlim = c(0, 15000)) Note: This can also be achieved using the xlim argument to scale_x_continuous above, however this will cause some points to not be plotted. In this case it would not be a huge deal, however, if we plotted the smooth lines from before you can see the difference.\nggplot(data = midwest, mapping = aes(x = popdensity, y = percollege, color = state)) + geom_point() + geom_smooth(se = FALSE) + scale_x_continuous(\u0026quot;Population Density\u0026quot;) + scale_y_continuous(\u0026quot;Percent College Graduates\u0026quot;) + scale_color_discrete(\u0026quot;State\u0026quot;) + coord_cartesian(xlim = c(0, 15000)) ggplot(data = midwest, mapping = aes(x = popdensity, y = percollege, color = state)) + geom_point() + geom_smooth(se = FALSE) + scale_x_continuous(\u0026quot;Population Density\u0026quot;, limits = c(0, 15000)) + scale_y_continuous(\u0026quot;Percent College Graduates\u0026quot;) + scale_color_discrete(\u0026quot;State\u0026quot;) ## Warning: Removed 16 rows containing non-finite values (stat_smooth). ## Warning: Removed 16 rows containing missing values (geom_point).  ","date":1612137600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1612137600,"objectID":"5cd35ce41d8b7dd43e2b3a7c1a480ee0","permalink":"https://psqf6250.brandonlebeau.org/rcode/graphics/","publishdate":"2021-02-01T00:00:00Z","relpermalink":"/rcode/graphics/","section":"rcode","summary":"using ggplot2","tags":null,"title":"Graphics","type":"book"},{"authors":null,"categories":null,"content":"   In an attempt to get you “doing things” in R quickly, I’ve omitted a lot of discussion surrounding internal R workings. R is an object oriented language, this is much different than many other software languages.\nR works as a calculator R can be used as a calculator to do any type of addition, subtraction, multiplication, or division (among other things).\n1 + 2 - 3 ## [1] 0 5 * 7 ## [1] 35 2/1 ## [1] 2 sqrt(4) ## [1] 2 2^2 ## [1] 4 Being an object oriented system, values can directly saved within an object to be used later. As an example:\nx \u0026lt;- 1 + 3 x ## [1] 4 This can then be used later in other calculations:\nx * 3 ## [1] 12 This simplistic example is a bit too simple to show all the benefits of this approach, but will become more apparent when we start reading in data and doing more complicated data munging type tasks.\nNaming conventions This is a topic in which you will not get a single answer, but rather a different answer for everyone you ask. I prefer something called snake_case using underscores to separate words in an object. Others use titleCase as a way to distinguish words others yet use period.to.separate words in object names.\nThe most important thing is to be consistent. Pick a convention that works for you and stick with it through out. Avoiding this Mixed.TypeOf_conventions at all costs.\n  R is case sensitive This can cause problems and make debugging a bit more difficult. Be careful with typos and with case. Here is an example:\ncase_sensitive \u0026lt;- 10 Case_sensitive ## Error in eval(expr, envir, enclos) : object \u0026#39;Case_sensitive\u0026#39; not found  Functions We have already been using functions when working through creating graphics with R. A function consists of at least two parts, the function name and the arguments as follows: function_name(arg1 = num, arg2 = num). The arguments are always inside of parentheses, take on some value, and are always named. To call a function, use the function_name followed by parentheses with the arguments inside the parentheses. For example, using the rnorm function to generate values from a random normal distribution:\nset.seed(1) rnorm(n = 10, mean = 0, sd = 1) ## [1] -0.6264538 0.1836433 -0.8356286 1.5952808 0.3295078 -0.8204684 ## [7] 0.4874291 0.7383247 0.5757814 -0.3053884 Notice I called the arguments by name directly, this is good practice, however, this code will generate the same values (the values are the same because I’m using set.seed here):\nset.seed(1) rnorm(10, 0, 1) ## [1] -0.6264538 0.1836433 -0.8356286 1.5952808 0.3295078 -0.8204684 ## [7] 0.4874291 0.7383247 0.5757814 -0.3053884 The key when arguments are not called via their names is the order of the arguments. Look at ?rnorm to see that the first three arguments are indeed n, mean, and sd. When you name arguments, they can be specified in any order (generally bad practice).\nset.seed(1) rnorm(sd = 1, n = 10, mean = 0) ## [1] -0.6264538 0.1836433 -0.8356286 1.5952808 0.3295078 -0.8204684 ## [7] 0.4874291 0.7383247 0.5757814 -0.3053884 You can save this result to an object to be used later.\nset.seed(1) norm_values \u0026lt;- rnorm(n = 10, mean = 0, sd = 1) Notice the result is no longer printed to the screen, but rather is saved to the object norm_values. To see the result, you could just type norm_values in the console.\n Errors Lastly, I want to discuss errors. Errors are going to happen. Even the best programmers encounter errors that they did not anticipate and debugging needs to happen. If you encounter an error I recommend doing the following few things first:\nUse ?function_name to explore the details of the function. The examples at the bottom of every R help page can be especially helpful.\n If this does not help, copy and paste the error and search on the internet. Chances are someone else has had this error and has asked how to fix it. This is how I fix most errors I am unable to figure out with the R help.\n If these two steps still do not help, feel free to email me, but take the time to do steps 1 and 2. If you do email me, please include the following things:\n The error message directly given from R A reproducible example of the code. The reproducible example is one in which I can run the code directly with no modifications. Without this, it is much more difficult if not impossible for me to help without asking for more information.    ","date":1612137600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1612137600,"objectID":"98d43ea826bd8e4faa445fd73e95bb1b","permalink":"https://psqf6250.brandonlebeau.org/rcode/r-basics/","publishdate":"2021-02-01T00:00:00Z","relpermalink":"/rcode/r-basics/","section":"rcode","summary":"R Basics","tags":null,"title":"R Basics","type":"book"},{"authors":null,"categories":null,"content":"   Getting Started  Review the syllabus Review the schedule Install R (or use the RStudio Cloud link) - RStudio Cloud Optionally, install RSTudio Optionally, complete the course survey   Weekly Videos  Course Overview \n Course Logistics \n   ","date":1611532800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1611532800,"objectID":"89558f99477b751e4e91eb6cc7e0dd9c","permalink":"https://psqf6250.brandonlebeau.org/content/00-getting-started/","publishdate":"2021-01-25T00:00:00Z","relpermalink":"/content/00-getting-started/","section":"content","summary":"Getting Started","tags":null,"title":"Welcome","type":"book"},{"authors":null,"categories":null,"content":"   Introduction This week will introduce you to Rmarkdown documents, markdown syntax, and discussion of installing R/RStudio.\n Objectives After completing this module, students will be able to:\n Define reproducible research Demonstrate code and markdown chunks Create a reproducible document template   Activities  Read R for Data Science Textbook - chapter 27 Optional reading, Reproducible Research in Education - LeBeau, Ellison \u0026amp; Aloe, in press   Weekly Videos  Introduction to Reproducible Research \n Dynamic Documents (part 1) \n Dynamic Documents (part 2) \n   Assignments None this week.\n ","date":1611532800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1611532800,"objectID":"1773d98851c0bab754bfb87807c55c10","permalink":"https://psqf6250.brandonlebeau.org/content/01-week1/","publishdate":"2021-01-25T00:00:00Z","relpermalink":"/content/01-week1/","section":"content","summary":"Reproducible Research","tags":null,"title":"Week 1","type":"book"},{"authors":null,"categories":null,"content":"   The ggplot2 package has a robust ecosystem of many other packages that extend the functionality of ggplot2. This week, we are going to explore some of these packages in more detail, highlighting a few packages that give you additional ways to create stunning visualizations. You can see all of the extensions packages in the following ggplot2 extension website.\nWe are going to spend some time with the following packages:\n ggrepel ggforce patchwork  I also plan to discuss, gganimate, but we are going to come back to this later in the course when talking about interactive graphics.\nAll of these packages are on CRAN and you can install with the following command:\ninstall.packages(c(\u0026quot;ggrepel\u0026quot;, \u0026quot;ggforce\u0026quot;, \u0026quot;patchwork\u0026quot;)) ggrepel Let’s start by exploring the ggrepel package. This package is particularly useful when working with text labels and provides some algorithms to help with text label placement automatically. One challenge when placing text labels in a figure is that they often overlap and they also often are placed on top of the data too. ggrepel helps to solve this problem.\nTo show a motivating example, we are going to use data in this section based on penguins. To do this, we first need to install this data package.\ninstall.packages(\u0026quot;palmerpenguins\u0026quot;) The data include three different species of penguins originally collected by Dr. Kristen Gorman at the Palmer Station in Antarctica. There are a total of 344 penguins collected from 3 islands in Antarctica and include information about the species, which island, penguin measurements, and the sex of the penguin. More information about the data including artwork about the species and penguin measurements are on this page.\nHere are the penguin species and what the measurements mean, “artwork by @allison_horst”.\nlibrary(palmerpenguins) library(ggplot2) penguins ## # A tibble: 344 x 8 ## species island bill_length_mm bill_depth_mm flipper_length_… body_mass_g ## \u0026lt;fct\u0026gt; \u0026lt;fct\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;int\u0026gt; \u0026lt;int\u0026gt; ## 1 Adelie Torge… 39.1 18.7 181 3750 ## 2 Adelie Torge… 39.5 17.4 186 3800 ## 3 Adelie Torge… 40.3 18 195 3250 ## 4 Adelie Torge… NA NA NA NA ## 5 Adelie Torge… 36.7 19.3 193 3450 ## 6 Adelie Torge… 39.3 20.6 190 3650 ## 7 Adelie Torge… 38.9 17.8 181 3625 ## 8 Adelie Torge… 39.2 19.6 195 4675 ## 9 Adelie Torge… 34.1 18.1 193 3475 ## 10 Adelie Torge… 42 20.2 190 4250 ## # … with 334 more rows, and 2 more variables: sex \u0026lt;fct\u0026gt;, year \u0026lt;int\u0026gt; Suppose we wanted to explore the bill length and flipper length with a scatter plot. We can do that with ggplot2 using the geom_point() function. I’m also using the theme_set() function to set the theme to be theme_bw() for the remainder of the notebook. I’ve also altered the theme settings by increasing the base font size from 12 to 16 so hopefully it is a bit easier to read the figure.\ntheme_set(theme_bw(base_size = 16)) ggplot(penguins, aes(x = flipper_length_mm, y = bill_length_mm)) + geom_point(size = 4) + xlab(\u0026quot;Penguin Flipper Length (in mm)\u0026quot;) + ylab(\u0026quot;Penguin Bill Length (in mm)\u0026quot;) Suppose we wished to add the species to this figure. More specifically, we want to add the species information to the points in the figure to label which points below to each penguin species. There are a few ways we could do this, we could do this by color, shape, or both.\nggplot(penguins, aes(x = flipper_length_mm, y = bill_length_mm)) + geom_point(size = 4, aes(color = species, shape = species)) + xlab(\u0026quot;Penguin Flipper Length (in mm)\u0026quot;) + ylab(\u0026quot;Penguin Bill Length (in mm)\u0026quot;) Another potential option would be to add the text labels directly to the figure and not use color. Adding text to a figure is typically done with the geom_text() function.\nggplot(penguins, aes(x = flipper_length_mm, y = bill_length_mm)) + geom_point(size = 4, aes(shape = species)) + geom_text(aes(label = species)) + xlab(\u0026quot;Penguin Flipper Length (in mm)\u0026quot;) + ylab(\u0026quot;Penguin Bill Length (in mm)\u0026quot;) Notice how the text labels overlap and the word is centered with the data point? This makes the plot unusable. We could fiddle with some settings to the geom_text() function, but the ggrepel package helps to fix this issue for us without having to guess and test. The primary difference in the code below is to use geom_text_repel() instead of geom_text(). Note, I shrunk the data point slightly in the following figure.\nlibrary(ggrepel) ggplot(penguins, aes(x = flipper_length_mm, y = bill_length_mm)) + geom_point(size = 3, aes(shape = species)) + geom_text_repel(aes(label = species)) + xlab(\u0026quot;Penguin Flipper Length (in mm)\u0026quot;) + ylab(\u0026quot;Penguin Bill Length (in mm)\u0026quot;) This isn’t actually better, but you can see the points were moved away. The issue here is that there are too many text labels to show in a single plot. I’m going to plot only 30 points, 10 from each species.\nlibrary(dplyr) set.seed(100) penguins %\u0026gt;% group_by(species) %\u0026gt;% sample_n(10) %\u0026gt;% ggplot(., aes(x = flipper_length_mm, y = bill_length_mm)) + geom_point(size = 3, aes(shape = species)) + geom_text_repel(aes(label = species)) + xlab(\u0026quot;Penguin Flipper Length (in mm)\u0026quot;) + ylab(\u0026quot;Penguin Bill Length (in mm)\u0026quot;) To see exactly what was done, I’m going to generate the same figure using geom_text().\nset.seed(100) penguins %\u0026gt;% group_by(species) %\u0026gt;% sample_n(10) %\u0026gt;% ggplot(., aes(x = flipper_length_mm, y = bill_length_mm)) + geom_point(size = 3, aes(shape = species)) + geom_text(aes(label = species)) + xlab(\u0026quot;Penguin Flipper Length (in mm)\u0026quot;) + ylab(\u0026quot;Penguin Bill Length (in mm)\u0026quot;) geom_label_repel() The ggrepel package only has two functions, the first we saw, geom_text_repel(). The second is geom_label_repel(). This works the same as geom_text_repel(), but creates a box around the text attribute.\nset.seed(100) penguins %\u0026gt;% group_by(species) %\u0026gt;% sample_n(10) %\u0026gt;% ggplot(., aes(x = flipper_length_mm, y = bill_length_mm)) + geom_point(size = 3, aes(shape = species)) + geom_label_repel(aes(label = species)) + xlab(\u0026quot;Penguin Flipper Length (in mm)\u0026quot;) + ylab(\u0026quot;Penguin Bill Length (in mm)\u0026quot;)  ggforce The ggforce package has a few powerful additions. One of these helps to solve the problem of too many text labels when using the entire penguin data and is the problem I’d like to start with.\nggplot(penguins, aes(x = flipper_length_mm, y = bill_length_mm)) + geom_point(size = 3, aes(shape = species)) + geom_text_repel(aes(label = species)) + xlab(\u0026quot;Penguin Flipper Length (in mm)\u0026quot;) + ylab(\u0026quot;Penguin Bill Length (in mm)\u0026quot;) Way too many text labels and for this example, there would be too many duplicate text labels. Since there are only three species, other ways of showing the text and groups would be helpful. ggforce helps with this problem using a series of functions that enclose data within different shapes. These functions are geom_mark_rect(), geom_mark_circle(), geom_mark_ellipse(), and geom_mark_hull() for rectangle, circle, ellipse, and hulls respectively. For an example, let’s try geom_mark_ellipse() instead of the text labels.\nlibrary(ggforce) library(tidyr) penguins %\u0026gt;% drop_na(flipper_length_mm, bill_length_mm) %\u0026gt;% ggplot(., aes(x = flipper_length_mm, y = bill_length_mm)) + geom_mark_ellipse(aes(fill = species)) + geom_point(size = 3, aes(shape = species)) + xlab(\u0026quot;Penguin Flipper Length (in mm)\u0026quot;) + ylab(\u0026quot;Penguin Bill Length (in mm)\u0026quot;) To take this one step further, we can add a text label to this figure by setting a label aesthetic to geom_mark_ellipse().\npenguins %\u0026gt;% drop_na(flipper_length_mm, bill_length_mm) %\u0026gt;% ggplot(., aes(x = flipper_length_mm, y = bill_length_mm)) + geom_mark_ellipse(aes(fill = species, label = species)) + geom_point(size = 3, aes(shape = species)) + scale_x_continuous(\u0026quot;Penguin Flipper Length (in mm)\u0026quot;) + scale_y_continuous(\u0026quot;Penguin Bill Length (in mm)\u0026quot;, limits = c(25, 70)) Another cool feature of ggforce is the ability to use something called facet zoom. Essentially, this will create a zoomed in element of a portion of your figure. For example, suppose we wanted to zoom in on the Gentoo penguins to explore their relationship between bill length and flipper length. This creates a picture in picture plotting effect.\nggplot(penguins, aes(x = flipper_length_mm, y = bill_length_mm)) + geom_point(size = 3, aes(shape = species, color = species)) + xlab(\u0026quot;Penguin Flipper Length (in mm)\u0026quot;) + ylab(\u0026quot;Penguin Bill Length (in mm)\u0026quot;) + facet_zoom(x = species == \u0026#39;Gentoo\u0026#39;)   patchwork The patchwork package is particularly helpful to combine multiple ggplot2 figures into a single figure, but you don’t want to facet. This can be useful to show multiple different relationships of attributes and combine these into a single figure element to include in a document to share.\nTo combine figure elements, basic math notation is used, including +, /, or |. There are other operators as well, but these are the primary ones we will explore and will also use parentheses to group plots together.\nFirst, let’s create a few plots that we may want to combine.\np1 \u0026lt;- ggplot(penguins, aes(x = flipper_length_mm, y = bill_length_mm)) + geom_point(size = 4, aes(color = species, shape = species)) + xlab(\u0026quot;Penguin Flipper Length (in mm)\u0026quot;) + ylab(\u0026quot;Penguin Bill Length (in mm)\u0026quot;) p1  p2 \u0026lt;- ggplot(penguins, aes(x = flipper_length_mm, y = bill_depth_mm)) + geom_point(size = 4, aes(color = species, shape = species)) + xlab(\u0026quot;Penguin Flipper Length (in mm)\u0026quot;) + ylab(\u0026quot;Penguin Bill Depth (in mm)\u0026quot;) p2 Now, we will start by using the + operator to combine plots.\nlibrary(patchwork) p1 + p2 As you can see, the plots are combined directly as generated. In the above example, we’d likely want to only have one legend instead of two. We can do this by modifying the first figure to remove the legend.\np1 \u0026lt;- ggplot(penguins, aes(x = flipper_length_mm, y = bill_length_mm)) + geom_point(size = 4, aes(color = species, shape = species)) + xlab(\u0026quot;Penguin Flipper Length (in mm)\u0026quot;) + ylab(\u0026quot;Penguin Bill Length (in mm)\u0026quot;) + theme(legend.position = \u0026#39;none\u0026#39;) p1  p1 + p2 We can use the / operator to stack plots into multiple rows.\np1 / p2 The + operator has one issue with it, it tries to keep things in a square grid, similar to how facet_wrap() works. For more advanced layout, the | operator separates columns whereas we saw above that the / operator will stack plots. Combined with parentheses, you can get more advanced layouts. First, let’s add one more figure.\np3 \u0026lt;- ggplot(drop_na(penguins, sex), aes(x = sex, y = body_mass_g)) + geom_violin(aes(fill = species), draw_quantiles = c(0.1, .5, 0.9)) + xlab(\u0026quot;Penguin Sex\u0026quot;) + ylab(\u0026quot;Penguin Body Mass (in g)\u0026quot;) + theme(legend.position = \u0026#39;none\u0026#39;) p3 p3 | (p1 / p2) Note, without parentheses, the figures may not turn out as you want.\np1 | p2 / p3 (p1 + p2) / p3  ","date":1612310400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1612310400,"objectID":"6ca2e667791f64c28f5edf60988df181","permalink":"https://psqf6250.brandonlebeau.org/rcode/ggplot2_extensions/","publishdate":"2021-02-03T00:00:00Z","relpermalink":"/rcode/ggplot2_extensions/","section":"rcode","summary":"ggplot2 extensions","tags":null,"title":"ggplot2 extensions","type":"book"},{"authors":null,"categories":null,"content":"   Introduction This week will explore data visualization using ggplot2 in R.\n Objectives After completing this module, students will be able to:\n Classify different figure types by their usage Interpret different figure types Evaluate if the figure is appropriate for a given research question Create new figures   Activities  Read R for Data Science Textbook - chapters 1 – 4   Weekly Videos  Introduction to Graphics with R \n Adding Aesthetics \n More geoms \n Plot Customization \n R Basics \n Installing and Loading R Packages \n   R Syntax  Graphics Syntax R Basics   Assignments  Quiz 1 - Due February 7th, 2021   ","date":1612137600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1612137600,"objectID":"5f6df7af478d8d68bf48d6c7cb96efd6","permalink":"https://psqf6250.brandonlebeau.org/content/02-week2/","publishdate":"2021-02-01T00:00:00Z","relpermalink":"/content/02-week2/","section":"content","summary":"Graphics with R","tags":null,"title":"Week 2","type":"book"},{"authors":null,"categories":null,"content":"   Graphics Basics What is the story you want to tell? Is the figure misleading? Could other figure types be more effective? Does the figure show variation? Is the figure self-contained?   Misleading Graphs Data visualization is hard and it is easy to mislead, intentionally or unintentionally.\n Better Approach  Axis Labels  Axis labels are often placed on the x-axis, but for long labels this can be less effective.   Axis Labels 2  Often, the labels are rotated. Works, but is ugly and difficult to read in my opinion.   Axis Labels 3  The solution, flip x and y axis using coord_flip()!   Showing Variation  Figures depicting statistics, should show variation.   Showing Variation 2  There are multiple values for each major category, the mean is useful, but simplifies too much and could mislead.   ","date":1612310400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1612310400,"objectID":"dc1a0cf78c6a546bd632853fc62d4f3a","permalink":"https://psqf6250.brandonlebeau.org/rcode/graphics-tips/","publishdate":"2021-02-03T00:00:00Z","relpermalink":"/rcode/graphics-tips/","section":"rcode","summary":"Graphics Tips","tags":null,"title":"Graphics Tips","type":"book"},{"authors":null,"categories":null,"content":"   Introduction The following week the course will continue discussing data visualization using ggplot2 by exploring a handful of useful extension packages that allows new functionality to be implemented. In addition to the new extension packages, some graphical creation tips will be shared.\n Objectives After completing this module, students will be able to:\n Engage with the ggplot2 extension packages Create new figures using the ggplot2 extension packages Evaluate and implement appropriate data visualization standards   Activities  Fundamentals of Data Visualization - chapters 17 – 26   Weekly Videos  ggrepel \n ggforce \n patchwork \n Graphics Tips \n   R Syntax  ggplot2 extensions R Basics   Assignments  Quiz 2 - Due February 14th, 2021   ","date":1612310400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1612310400,"objectID":"f875f45cf8608967d14ba527654da4d3","permalink":"https://psqf6250.brandonlebeau.org/content/03-week3/","publishdate":"2021-02-03T00:00:00Z","relpermalink":"/content/03-week3/","section":"content","summary":"ggplot2 Extension Packages","tags":null,"title":"Week 3","type":"book"},{"authors":null,"categories":null,"content":"   Data munging (i.e. data transformations, variable creation, filtering) is a common task that is often overlooked in traditional statistics textbooks and courses. Even though it is omitted, the task of cleaning and organizing the data (coming in week 5 of the course)\nData from the fivethirtyeight package is used in this set of notes to show the use of the dplyr verbs for data munging. This package can be installed with the following command:\ninstall.packages(\u0026quot;fivethirtyeight\u0026quot;) To get started with this set of notes, you will need the following packages loaded:\nlibrary(fivethirtyeight) library(tidyverse) We are going to explore the congress_age data set in more detail. Take a few minutes to familiarize yourself with the data.\nView(congress_age) ?congress_age congress_age ## # A tibble: 18,635 x 13 ## congress chamber bioguide firstname middlename lastname suffix birthday ## \u0026lt;int\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;date\u0026gt; ## 1 80 house M000112 Joseph Jefferson Mansfie… \u0026lt;NA\u0026gt; 1861-02-09 ## 2 80 house D000448 Robert Lee Doughton \u0026lt;NA\u0026gt; 1863-11-07 ## 3 80 house S000001 Adolph Joachim Sabath \u0026lt;NA\u0026gt; 1866-04-04 ## 4 80 house E000023 Charles Aubrey Eaton \u0026lt;NA\u0026gt; 1868-03-29 ## 5 80 house L000296 William \u0026lt;NA\u0026gt; Lewis \u0026lt;NA\u0026gt; 1868-09-22 ## 6 80 house G000017 James A. Gallagh… \u0026lt;NA\u0026gt; 1869-01-16 ## 7 80 house W000265 Richard Joseph Welch \u0026lt;NA\u0026gt; 1869-02-13 ## 8 80 house B000565 Sol \u0026lt;NA\u0026gt; Bloom \u0026lt;NA\u0026gt; 1870-03-09 ## 9 80 house H000943 Merlin \u0026lt;NA\u0026gt; Hull \u0026lt;NA\u0026gt; 1870-12-18 ## 10 80 house G000169 Charles Laceille Gifford \u0026lt;NA\u0026gt; 1871-03-15 ## # … with 18,625 more rows, and 5 more variables: state \u0026lt;chr\u0026gt;, party \u0026lt;chr\u0026gt;, ## # incumbent \u0026lt;lgl\u0026gt;, termstart \u0026lt;date\u0026gt;, age \u0026lt;dbl\u0026gt; Using dplyr for data munging The dplyr package uses verbs for common data manipulation tasks. These include:\n filter() arrange() select() mutate() summarise()  The great aspect of these verbs are that they all take a similar data structure, the first argument is always the data, the other arguments are unquoted column names. These functions also always return a data frame in which the rows are observations and the columns are variables.\n Examples with filter() The filter function selects rows that match a specified condition(s). For example, suppose we wanted to select only the rows in the data that are a part of the 80th congress. The following code will do this action:\nfilter(congress_age, congress == 80) ## # A tibble: 555 x 13 ## congress chamber bioguide firstname middlename lastname suffix birthday ## \u0026lt;int\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;date\u0026gt; ## 1 80 house M000112 Joseph Jefferson Mansfie… \u0026lt;NA\u0026gt; 1861-02-09 ## 2 80 house D000448 Robert Lee Doughton \u0026lt;NA\u0026gt; 1863-11-07 ## 3 80 house S000001 Adolph Joachim Sabath \u0026lt;NA\u0026gt; 1866-04-04 ## 4 80 house E000023 Charles Aubrey Eaton \u0026lt;NA\u0026gt; 1868-03-29 ## 5 80 house L000296 William \u0026lt;NA\u0026gt; Lewis \u0026lt;NA\u0026gt; 1868-09-22 ## 6 80 house G000017 James A. Gallagh… \u0026lt;NA\u0026gt; 1869-01-16 ## 7 80 house W000265 Richard Joseph Welch \u0026lt;NA\u0026gt; 1869-02-13 ## 8 80 house B000565 Sol \u0026lt;NA\u0026gt; Bloom \u0026lt;NA\u0026gt; 1870-03-09 ## 9 80 house H000943 Merlin \u0026lt;NA\u0026gt; Hull \u0026lt;NA\u0026gt; 1870-12-18 ## 10 80 house G000169 Charles Laceille Gifford \u0026lt;NA\u0026gt; 1871-03-15 ## # … with 545 more rows, and 5 more variables: state \u0026lt;chr\u0026gt;, party \u0026lt;chr\u0026gt;, ## # incumbent \u0026lt;lgl\u0026gt;, termstart \u0026lt;date\u0026gt;, age \u0026lt;dbl\u0026gt; Notice from above two things, first, the function returned a new data frame. Therefore, if this subsetted data is to be saved, we need to save it to an object, for example, as follows:\ncongress_80 \u0026lt;- filter(congress_age, congress == 80) Notice now that the data were not automatically printed, instead it was saved into the object called congress_80. If you wish to preview the data and save it to an object in a single step, you need to wrap the command above in parentheses. Take a second to try this yourself.\nSecondly, notice from the above commands that equality in R is done with == not just a single =. The single = is used for named arguments, therefore when testing for equality you need to be sure to use ==, this is a common frustration and source of bugs when getting started with R.\nSelecting values based on a character vector are similar to numeric values. For example, suppose we wanted to select only those rows pertaining to those from the senate. The following code will do that:\nsenate \u0026lt;- filter(congress_age, chamber == \u0026#39;senate\u0026#39;) Combining Logical Operations The filter function becomes much more useful with more complex operations. For example, suppose we were interested in selecting the rows that belong to the 80th senate.\nfilter(congress_age, congress == 80, chamber == \u0026#39;senate\u0026#39;) ## # A tibble: 102 x 13 ## congress chamber bioguide firstname middlename lastname suffix birthday ## \u0026lt;int\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;date\u0026gt; ## 1 80 senate C000133 Arthur \u0026lt;NA\u0026gt; Capper \u0026lt;NA\u0026gt; 1865-07-14 ## 2 80 senate G000418 Theodore Francis Green \u0026lt;NA\u0026gt; 1867-10-02 ## 3 80 senate M000499 Kenneth Douglas McKellar \u0026lt;NA\u0026gt; 1869-01-29 ## 4 80 senate R000112 Clyde Martin Reed \u0026lt;NA\u0026gt; 1871-10-19 ## 5 80 senate M000895 Edward Hall Moore \u0026lt;NA\u0026gt; 1871-11-19 ## 6 80 senate O000146 John Holmes Overton \u0026lt;NA\u0026gt; 1875-09-17 ## 7 80 senate M001108 James Edward Murray \u0026lt;NA\u0026gt; 1876-05-03 ## 8 80 senate M000308 Patrick Anthony McCarran \u0026lt;NA\u0026gt; 1876-08-08 ## 9 80 senate T000165 Elmer \u0026lt;NA\u0026gt; Thomas \u0026lt;NA\u0026gt; 1876-09-08 ## 10 80 senate W000021 Robert Ferdinand Wagner \u0026lt;NA\u0026gt; 1877-06-08 ## # … with 92 more rows, and 5 more variables: state \u0026lt;chr\u0026gt;, party \u0026lt;chr\u0026gt;, ## # incumbent \u0026lt;lgl\u0026gt;, termstart \u0026lt;date\u0026gt;, age \u0026lt;dbl\u0026gt; By default, the filter function uses AND when combining multiple arguments. Therefore, the above command returned only the 102 rows belonging to senators from the 80th congress. The figure on section 5.2.2 of R for Data Science shows all the possible boolean operators.\nUsing an example of the OR operator using | to select the 80th and 81st congress:\nfilter(congress_age, congress == 80 | congress == 81) ## # A tibble: 1,112 x 13 ## congress chamber bioguide firstname middlename lastname suffix birthday ## \u0026lt;int\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;date\u0026gt; ## 1 80 house M000112 Joseph Jefferson Mansfie… \u0026lt;NA\u0026gt; 1861-02-09 ## 2 80 house D000448 Robert Lee Doughton \u0026lt;NA\u0026gt; 1863-11-07 ## 3 80 house S000001 Adolph Joachim Sabath \u0026lt;NA\u0026gt; 1866-04-04 ## 4 80 house E000023 Charles Aubrey Eaton \u0026lt;NA\u0026gt; 1868-03-29 ## 5 80 house L000296 William \u0026lt;NA\u0026gt; Lewis \u0026lt;NA\u0026gt; 1868-09-22 ## 6 80 house G000017 James A. Gallagh… \u0026lt;NA\u0026gt; 1869-01-16 ## 7 80 house W000265 Richard Joseph Welch \u0026lt;NA\u0026gt; 1869-02-13 ## 8 80 house B000565 Sol \u0026lt;NA\u0026gt; Bloom \u0026lt;NA\u0026gt; 1870-03-09 ## 9 80 house H000943 Merlin \u0026lt;NA\u0026gt; Hull \u0026lt;NA\u0026gt; 1870-12-18 ## 10 80 house G000169 Charles Laceille Gifford \u0026lt;NA\u0026gt; 1871-03-15 ## # … with 1,102 more rows, and 5 more variables: state \u0026lt;chr\u0026gt;, party \u0026lt;chr\u0026gt;, ## # incumbent \u0026lt;lgl\u0026gt;, termstart \u0026lt;date\u0026gt;, age \u0026lt;dbl\u0026gt; Note that to do the OR operator, you need to name the variable twice. When selecting multiple values in the same variable, a handy shortcut is %in%. The same command can be run with the following shorthand: handy shortcut is %in%. The same command can be run with the following shorthard\nfilter(congress_age, congress %in% c(80, 81)) ## # A tibble: 1,112 x 13 ## congress chamber bioguide firstname middlename lastname suffix birthday ## \u0026lt;int\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;date\u0026gt; ## 1 80 house M000112 Joseph Jefferson Mansfie… \u0026lt;NA\u0026gt; 1861-02-09 ## 2 80 house D000448 Robert Lee Doughton \u0026lt;NA\u0026gt; 1863-11-07 ## 3 80 house S000001 Adolph Joachim Sabath \u0026lt;NA\u0026gt; 1866-04-04 ## 4 80 house E000023 Charles Aubrey Eaton \u0026lt;NA\u0026gt; 1868-03-29 ## 5 80 house L000296 William \u0026lt;NA\u0026gt; Lewis \u0026lt;NA\u0026gt; 1868-09-22 ## 6 80 house G000017 James A. Gallagh… \u0026lt;NA\u0026gt; 1869-01-16 ## 7 80 house W000265 Richard Joseph Welch \u0026lt;NA\u0026gt; 1869-02-13 ## 8 80 house B000565 Sol \u0026lt;NA\u0026gt; Bloom \u0026lt;NA\u0026gt; 1870-03-09 ## 9 80 house H000943 Merlin \u0026lt;NA\u0026gt; Hull \u0026lt;NA\u0026gt; 1870-12-18 ## 10 80 house G000169 Charles Laceille Gifford \u0026lt;NA\u0026gt; 1871-03-15 ## # … with 1,102 more rows, and 5 more variables: state \u0026lt;chr\u0026gt;, party \u0026lt;chr\u0026gt;, ## # incumbent \u0026lt;lgl\u0026gt;, termstart \u0026lt;date\u0026gt;, age \u0026lt;dbl\u0026gt;  Not Operator Another useful operator that deserves a bit more discussion is the not operator, !. For example, suppose we wanted to omit the 80th congress:\nfilter(congress_age, congress != 80) ## # A tibble: 18,080 x 13 ## congress chamber bioguide firstname middlename lastname suffix birthday ## \u0026lt;int\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;date\u0026gt; ## 1 81 house D000448 Robert Lee Doughton \u0026lt;NA\u0026gt; 1863-11-07 ## 2 81 house S000001 Adolph Joachim Sabath \u0026lt;NA\u0026gt; 1866-04-04 ## 3 81 house E000023 Charles Aubrey Eaton \u0026lt;NA\u0026gt; 1868-03-29 ## 4 81 house W000265 Richard Joseph Welch \u0026lt;NA\u0026gt; 1869-02-13 ## 5 81 house B000565 Sol \u0026lt;NA\u0026gt; Bloom \u0026lt;NA\u0026gt; 1870-03-09 ## 6 81 house H000943 Merlin \u0026lt;NA\u0026gt; Hull \u0026lt;NA\u0026gt; 1870-12-18 ## 7 81 house B000545 Schuyler Otis Bland \u0026lt;NA\u0026gt; 1872-05-04 ## 8 81 house K000138 John Hosea Kerr \u0026lt;NA\u0026gt; 1873-12-31 ## 9 81 house C000932 Robert \u0026lt;NA\u0026gt; Crosser \u0026lt;NA\u0026gt; 1874-06-07 ## 10 81 house K000039 John \u0026lt;NA\u0026gt; Kee \u0026lt;NA\u0026gt; 1874-08-22 ## # … with 18,070 more rows, and 5 more variables: state \u0026lt;chr\u0026gt;, party \u0026lt;chr\u0026gt;, ## # incumbent \u0026lt;lgl\u0026gt;, termstart \u0026lt;date\u0026gt;, age \u0026lt;dbl\u0026gt; It is also possible to do not with an AND operator as follows:\nfilter(congress_age, congress == 80 \u0026amp; !chamber == \u0026#39;senate\u0026#39;) ## # A tibble: 453 x 13 ## congress chamber bioguide firstname middlename lastname suffix birthday ## \u0026lt;int\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;date\u0026gt; ## 1 80 house M000112 Joseph Jefferson Mansfie… \u0026lt;NA\u0026gt; 1861-02-09 ## 2 80 house D000448 Robert Lee Doughton \u0026lt;NA\u0026gt; 1863-11-07 ## 3 80 house S000001 Adolph Joachim Sabath \u0026lt;NA\u0026gt; 1866-04-04 ## 4 80 house E000023 Charles Aubrey Eaton \u0026lt;NA\u0026gt; 1868-03-29 ## 5 80 house L000296 William \u0026lt;NA\u0026gt; Lewis \u0026lt;NA\u0026gt; 1868-09-22 ## 6 80 house G000017 James A. Gallagh… \u0026lt;NA\u0026gt; 1869-01-16 ## 7 80 house W000265 Richard Joseph Welch \u0026lt;NA\u0026gt; 1869-02-13 ## 8 80 house B000565 Sol \u0026lt;NA\u0026gt; Bloom \u0026lt;NA\u0026gt; 1870-03-09 ## 9 80 house H000943 Merlin \u0026lt;NA\u0026gt; Hull \u0026lt;NA\u0026gt; 1870-12-18 ## 10 80 house G000169 Charles Laceille Gifford \u0026lt;NA\u0026gt; 1871-03-15 ## # … with 443 more rows, and 5 more variables: state \u0026lt;chr\u0026gt;, party \u0026lt;chr\u0026gt;, ## # incumbent \u0026lt;lgl\u0026gt;, termstart \u0026lt;date\u0026gt;, age \u0026lt;dbl\u0026gt; Exercises Using the congress data, select the rows belonging to the democrats (party = D) from the senate of the 100th congress. Select all congress members who are older than 80 years old.    Note on Missing Data Missing data within R are represented with NA which stands for not available.\nThere are no missing data in the congress data, however, by default the filter function will not return any missing values. In order to select missing data, you need to use the is.na function.\nExercise Given the following simple vector, run one filter that selects all values greater than 100. Write a second filter command that selects all the rows greater than 100 and also the NA value.  df \u0026lt;- tibble(x = c(200, 30, NA, 45, 212))    Examples with arrange() The arrange function is used for ordering rows in the data. For example, suppose we wanted to order the rows in the congress data by the state the members of congress lived in. This can be done using the arrange function as follows:\narrange(congress_age, state) ## # A tibble: 18,635 x 13 ## congress chamber bioguide firstname middlename lastname suffix birthday ## \u0026lt;int\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;date\u0026gt; ## 1 80 house B000201 Edward Lewis Bartlett \u0026lt;NA\u0026gt; 1904-04-20 ## 2 81 house B000201 Edward Lewis Bartlett \u0026lt;NA\u0026gt; 1904-04-20 ## 3 82 house B000201 Edward Lewis Bartlett \u0026lt;NA\u0026gt; 1904-04-20 ## 4 83 house B000201 Edward Lewis Bartlett \u0026lt;NA\u0026gt; 1904-04-20 ## 5 84 house B000201 Edward Lewis Bartlett \u0026lt;NA\u0026gt; 1904-04-20 ## 6 85 house B000201 Edward Lewis Bartlett \u0026lt;NA\u0026gt; 1904-04-20 ## 7 86 house R000282 Ralph Julian Rivers \u0026lt;NA\u0026gt; 1903-05-23 ## 8 86 senate G000508 Ernest \u0026lt;NA\u0026gt; Gruening \u0026lt;NA\u0026gt; 1887-02-06 ## 9 86 senate B000201 Edward Lewis Bartlett \u0026lt;NA\u0026gt; 1904-04-20 ## 10 87 house R000282 Ralph Julian Rivers \u0026lt;NA\u0026gt; 1903-05-23 ## # … with 18,625 more rows, and 5 more variables: state \u0026lt;chr\u0026gt;, party \u0026lt;chr\u0026gt;, ## # incumbent \u0026lt;lgl\u0026gt;, termstart \u0026lt;date\u0026gt;, age \u0026lt;dbl\u0026gt; Similar to the filter function, additional arguments can be added to add more layers to the ordering. For example, if we were interested in ordering the rows by state and then by party affiliation.\narrange(congress_age, state, party) ## # A tibble: 18,635 x 13 ## congress chamber bioguide firstname middlename lastname suffix birthday ## \u0026lt;int\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;date\u0026gt; ## 1 80 house B000201 Edward Lewis Bartlett \u0026lt;NA\u0026gt; 1904-04-20 ## 2 81 house B000201 Edward Lewis Bartlett \u0026lt;NA\u0026gt; 1904-04-20 ## 3 82 house B000201 Edward Lewis Bartlett \u0026lt;NA\u0026gt; 1904-04-20 ## 4 83 house B000201 Edward Lewis Bartlett \u0026lt;NA\u0026gt; 1904-04-20 ## 5 84 house B000201 Edward Lewis Bartlett \u0026lt;NA\u0026gt; 1904-04-20 ## 6 85 house B000201 Edward Lewis Bartlett \u0026lt;NA\u0026gt; 1904-04-20 ## 7 86 house R000282 Ralph Julian Rivers \u0026lt;NA\u0026gt; 1903-05-23 ## 8 86 senate G000508 Ernest \u0026lt;NA\u0026gt; Gruening \u0026lt;NA\u0026gt; 1887-02-06 ## 9 86 senate B000201 Edward Lewis Bartlett \u0026lt;NA\u0026gt; 1904-04-20 ## 10 87 house R000282 Ralph Julian Rivers \u0026lt;NA\u0026gt; 1903-05-23 ## # … with 18,625 more rows, and 5 more variables: state \u0026lt;chr\u0026gt;, party \u0026lt;chr\u0026gt;, ## # incumbent \u0026lt;lgl\u0026gt;, termstart \u0026lt;date\u0026gt;, age \u0026lt;dbl\u0026gt; More variables can easily be added to the arrange function. Notice from the above two commands that the ordering of the rows is in ascending order, if descending order is desired, the desc function. For example, to order the data starting with the latest congress first:\narrange(congress_age, desc(congress)) ## # A tibble: 18,635 x 13 ## congress chamber bioguide firstname middlename lastname suffix birthday ## \u0026lt;int\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;date\u0026gt; ## 1 113 house H000067 Ralph M. Hall \u0026lt;NA\u0026gt; 1923-05-03 ## 2 113 house D000355 John D. Dingell \u0026lt;NA\u0026gt; 1926-07-08 ## 3 113 house C000714 John \u0026lt;NA\u0026gt; Conyers Jr. 1929-05-16 ## 4 113 house S000480 Louise McIntosh Slaught… \u0026lt;NA\u0026gt; 1929-08-14 ## 5 113 house R000053 Charles B. Rangel \u0026lt;NA\u0026gt; 1930-06-11 ## 6 113 house J000174 Sam Robert Johnson \u0026lt;NA\u0026gt; 1930-10-11 ## 7 113 house Y000031 C. W. Bill Young \u0026lt;NA\u0026gt; 1930-12-16 ## 8 113 house C000556 Howard \u0026lt;NA\u0026gt; Coble \u0026lt;NA\u0026gt; 1931-03-18 ## 9 113 house L000263 Sander M. Levin \u0026lt;NA\u0026gt; 1931-09-06 ## 10 113 house Y000033 Don E. Young \u0026lt;NA\u0026gt; 1933-06-09 ## # … with 18,625 more rows, and 5 more variables: state \u0026lt;chr\u0026gt;, party \u0026lt;chr\u0026gt;, ## # incumbent \u0026lt;lgl\u0026gt;, termstart \u0026lt;date\u0026gt;, age \u0026lt;dbl\u0026gt;  Examples with select() The select function is used to select columns (i.e. variables) from the data but keep all the rows. For example, maybe we only needed the congress number, the chamber, the party affiliation, and the age of the members of congress. We can reduce the data to just these variables using select.\nselect(congress_age, congress, chamber, party, age) ## # A tibble: 18,635 x 4 ## congress chamber party age ## \u0026lt;int\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;dbl\u0026gt; ## 1 80 house D 85.9 ## 2 80 house D 83.2 ## 3 80 house D 80.7 ## 4 80 house R 78.8 ## 5 80 house R 78.3 ## 6 80 house R 78 ## 7 80 house R 77.9 ## 8 80 house D 76.8 ## 9 80 house R 76 ## 10 80 house R 75.8 ## # … with 18,625 more rows Similar to the arrange functions, the variables that you wish to keep are separated by commas and come after the data argument.\nFor more complex selection, the dplyr package has additional functions that are helpful for variable selection. These include: - starts_with() - ends_with() - contains() - matches() - num_range()\nThese helper functions can be useful for selecting many variables that match a specific pattern. For example, suppose we were interested in selecting all the name variables, this can be accomplished using the contains function as follows:\nselect(congress_age, contains(\u0026#39;name\u0026#39;)) ## # A tibble: 18,635 x 3 ## firstname middlename lastname ## \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; ## 1 Joseph Jefferson Mansfield ## 2 Robert Lee Doughton ## 3 Adolph Joachim Sabath ## 4 Charles Aubrey Eaton ## 5 William \u0026lt;NA\u0026gt; Lewis ## 6 James A. Gallagher ## 7 Richard Joseph Welch ## 8 Sol \u0026lt;NA\u0026gt; Bloom ## 9 Merlin \u0026lt;NA\u0026gt; Hull ## 10 Charles Laceille Gifford ## # … with 18,625 more rows Another useful shorthand to select multiple columns in succession is the : operator. For example, suppose we wanted to select all the variables between congress and bithday.\nselect(congress_age, congress:birthday) ## # A tibble: 18,635 x 8 ## congress chamber bioguide firstname middlename lastname suffix birthday ## \u0026lt;int\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;date\u0026gt; ## 1 80 house M000112 Joseph Jefferson Mansfield \u0026lt;NA\u0026gt; 1861-02-09 ## 2 80 house D000448 Robert Lee Doughton \u0026lt;NA\u0026gt; 1863-11-07 ## 3 80 house S000001 Adolph Joachim Sabath \u0026lt;NA\u0026gt; 1866-04-04 ## 4 80 house E000023 Charles Aubrey Eaton \u0026lt;NA\u0026gt; 1868-03-29 ## 5 80 house L000296 William \u0026lt;NA\u0026gt; Lewis \u0026lt;NA\u0026gt; 1868-09-22 ## 6 80 house G000017 James A. Gallagher \u0026lt;NA\u0026gt; 1869-01-16 ## 7 80 house W000265 Richard Joseph Welch \u0026lt;NA\u0026gt; 1869-02-13 ## 8 80 house B000565 Sol \u0026lt;NA\u0026gt; Bloom \u0026lt;NA\u0026gt; 1870-03-09 ## 9 80 house H000943 Merlin \u0026lt;NA\u0026gt; Hull \u0026lt;NA\u0026gt; 1870-12-18 ## 10 80 house G000169 Charles Laceille Gifford \u0026lt;NA\u0026gt; 1871-03-15 ## # … with 18,625 more rows Rename variables The select function does allow you to rename variables, however, using the select function to rename variables is not usually advised as you may end up missing a variable that you wish to keep during the renaming operation. Instead, using the rename function is better practice.\nrename(congress_age, first_name = firstname, last_name = lastname) ## # A tibble: 18,635 x 13 ## congress chamber bioguide first_name middlename last_name suffix birthday ## \u0026lt;int\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;date\u0026gt; ## 1 80 house M000112 Joseph Jefferson Mansfield \u0026lt;NA\u0026gt; 1861-02-09 ## 2 80 house D000448 Robert Lee Doughton \u0026lt;NA\u0026gt; 1863-11-07 ## 3 80 house S000001 Adolph Joachim Sabath \u0026lt;NA\u0026gt; 1866-04-04 ## 4 80 house E000023 Charles Aubrey Eaton \u0026lt;NA\u0026gt; 1868-03-29 ## 5 80 house L000296 William \u0026lt;NA\u0026gt; Lewis \u0026lt;NA\u0026gt; 1868-09-22 ## 6 80 house G000017 James A. Gallagher \u0026lt;NA\u0026gt; 1869-01-16 ## 7 80 house W000265 Richard Joseph Welch \u0026lt;NA\u0026gt; 1869-02-13 ## 8 80 house B000565 Sol \u0026lt;NA\u0026gt; Bloom \u0026lt;NA\u0026gt; 1870-03-09 ## 9 80 house H000943 Merlin \u0026lt;NA\u0026gt; Hull \u0026lt;NA\u0026gt; 1870-12-18 ## 10 80 house G000169 Charles Laceille Gifford \u0026lt;NA\u0026gt; 1871-03-15 ## # … with 18,625 more rows, and 5 more variables: state \u0026lt;chr\u0026gt;, party \u0026lt;chr\u0026gt;, ## # incumbent \u0026lt;lgl\u0026gt;, termstart \u0026lt;date\u0026gt;, age \u0026lt;dbl\u0026gt; By default, the rename function will not save changes to the object, if you wish to save the name differences (very likely), be sure to save this new step to an object.\nExercises Using the dplyr helper functions, select all the variables that start with the letter ‘c’. Rename the first three variables in the congress data to ‘x1’, ‘x2’, ‘x3’. After renaming the first three variables, use this new data (ensure you saved the previous step to an object) to select these three variables with the num_range function.     Examples with mutate() mutate is a useful verb that allows you to add new columns to the existing data set. Actions done with mutate include adding a column of means, counts, or other transformations of existing variables. Suppose for example, we wished to convert the party affiliation of the members of congress into a dummy (indicator) variable. This may be useful to more easily compute a proportion or count for instance.\nThis can be done with the mutate function. Below, I’m first going to use select to reduce the number of columns to make it easier to see the operation.\ncongress_red \u0026lt;- select(congress_age, congress, chamber, state, party) mutate(congress_red, democrat = ifelse(party == \u0026#39;D\u0026#39;, 1, 0), num_democrat = sum(democrat) ) ## # A tibble: 18,635 x 6 ## congress chamber state party democrat num_democrat ## \u0026lt;int\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; ## 1 80 house TX D 1 10290 ## 2 80 house NC D 1 10290 ## 3 80 house IL D 1 10290 ## 4 80 house NJ R 0 10290 ## 5 80 house KY R 0 10290 ## 6 80 house PA R 0 10290 ## 7 80 house CA R 0 10290 ## 8 80 house NY D 1 10290 ## 9 80 house WI R 0 10290 ## 10 80 house MA R 0 10290 ## # … with 18,625 more rows You’ll notice that the number of rows in the data are the same (18635) as it was previously, but now the two new columns have been added to the data. One converted the party affiliation to a series of 0/1 values and the other variable counted up the number of democrats elected since the 80th congress. Notice how this last variable is simply repeated for all values in the data. The operation done here is not too exciting, however, we will learn another utility later that allows us to group the data to calculate different values for each group.\nLastly, from the output above, notice that I was able to reference a variable that I created previously in the mutate command. This is unique to the dplyr package and allows you to create a single mutate command to add many variables, even those that depend on prior calculations. Obviously, if you need to reference a calculation in another calculation, they need to be done in the proper order.\nCreation Functions There are many useful operators to use when creating additional variables. The R for Data Science text has many examples shown in section 5.5.1. In general useful operators include addition, subtraction, multiplication, division, descriptive statistics (we will talk more about these in week 4), ranks, logical comparisons, and many more. The exercises will have you explore some of these operations in more detail.\nExercises Using the diamonds data, use ?diamonds for more information on the data, use the mutate function to calculate the price per carat. Hint, this operation would involve standardizing the price variable so that all are comparable at 1 carat. Calculate the rank of the original price variable and the new price variable calculated above using the min_rank function. Are there differences in the ranking of the prices? Hint, it may be useful to test if the two ranks are equal to explore this.     Examples with summarise() summarise is very similar to the mutate function, except instead of adding additional columns to the data, it collapses data down to a single row. For instance, doing the same operation as the example with mutate above:\ncongress_2 \u0026lt;- mutate(congress_age, democrat = ifelse(party == \u0026#39;D\u0026#39;, 1, 0) ) summarise(congress_2, num_democrat = sum(democrat) ) ## # A tibble: 1 x 1 ## num_democrat ## \u0026lt;dbl\u0026gt; ## 1 10290 Notice now, instead of repeating the same value for all the rows as with mutate, summarise collapsed the data into a single numeric summary. Normally this is not a very interesting data activity, however, used in tandem with another function, group_by, interesting summary statistics can be calculated.\nSuppose we were interested in calculating the number of democrats in each congress. This can be achieved with similar code to above, but first by grouping the data as follows:\ncongress_grp \u0026lt;- group_by(congress_2, congress) summarise(congress_grp, num_democrat = sum(democrat), total = n(), prop_democrat = num_democrat / total ) ## # A tibble: 34 x 4 ## congress num_democrat total prop_democrat ## * \u0026lt;int\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;int\u0026gt; \u0026lt;dbl\u0026gt; ## 1 80 247 555 0.445 ## 2 81 330 557 0.592 ## 3 82 292 555 0.526 ## 4 83 274 557 0.492 ## 5 84 288 544 0.529 ## 6 85 295 547 0.539 ## 7 86 356 554 0.643 ## 8 87 339 559 0.606 ## 9 88 332 552 0.601 ## 10 89 371 548 0.677 ## # … with 24 more rows Notice above, the use of the group_by function to group the data first by congress. Then this new grouped data is passed to the summarise command. As you can see from the output, the operations performed with the summarise function are done for each unique level of the congress variable. You could now easily plot these to see the trend in proportion of democrats has changed over time.\nlibrary(ggplot2) num_dem \u0026lt;- summarise(congress_grp, num_democrat = sum(democrat), total = n(), prop_democrat = num_democrat / total ) ggplot(num_dem, aes(x = congress, y = prop_democrat)) + geom_line() Exercises Suppose we wanted to calculate the number and proportion of republicans instead of democrats, assuming these are the only two parties, edit the summarise command above to calculate these values. Suppose instead of using sum(democrat) above, we used mean(democrat), what does this value return? Why does it return this value?   Extending group_by() in other places The group_by function is also useful with the mutate function and works in a similar way as summarise above. For example, if we wanted to keep the values calculated above in the original data, we could use mutate instead of summarise. This would look like the following:\nmutate(congress_grp, num_democrat = sum(democrat), total = n(), prop_democrat = num_democrat / total ) ## # A tibble: 18,635 x 17 ## # Groups: congress [34] ## congress chamber bioguide firstname middlename lastname suffix birthday ## \u0026lt;int\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;date\u0026gt; ## 1 80 house M000112 Joseph Jefferson Mansfie… \u0026lt;NA\u0026gt; 1861-02-09 ## 2 80 house D000448 Robert Lee Doughton \u0026lt;NA\u0026gt; 1863-11-07 ## 3 80 house S000001 Adolph Joachim Sabath \u0026lt;NA\u0026gt; 1866-04-04 ## 4 80 house E000023 Charles Aubrey Eaton \u0026lt;NA\u0026gt; 1868-03-29 ## 5 80 house L000296 William \u0026lt;NA\u0026gt; Lewis \u0026lt;NA\u0026gt; 1868-09-22 ## 6 80 house G000017 James A. Gallagh… \u0026lt;NA\u0026gt; 1869-01-16 ## 7 80 house W000265 Richard Joseph Welch \u0026lt;NA\u0026gt; 1869-02-13 ## 8 80 house B000565 Sol \u0026lt;NA\u0026gt; Bloom \u0026lt;NA\u0026gt; 1870-03-09 ## 9 80 house H000943 Merlin \u0026lt;NA\u0026gt; Hull \u0026lt;NA\u0026gt; 1870-12-18 ## 10 80 house G000169 Charles Laceille Gifford \u0026lt;NA\u0026gt; 1871-03-15 ## # … with 18,625 more rows, and 9 more variables: state \u0026lt;chr\u0026gt;, party \u0026lt;chr\u0026gt;, ## # incumbent \u0026lt;lgl\u0026gt;, termstart \u0026lt;date\u0026gt;, age \u0026lt;dbl\u0026gt;, democrat \u0026lt;dbl\u0026gt;, ## # num_democrat \u0026lt;dbl\u0026gt;, total \u0026lt;int\u0026gt;, prop_democrat \u0026lt;dbl\u0026gt;  Useful summary functions There are many useful summary functions, many of which we will explore in more detail in week 4 of the course during exploratory data analysis (EDA). However, I want to show a few here with the summarise function to ease you in. Suppose for instance we were interested in the knowing the youngest and oldest member of congress for each congress. There are actually two ways of doing this, one is using the min and max functions on the grouped data.\nsummarise(congress_grp, youngest = min(age), oldest = max(age) ) ## # A tibble: 34 x 3 ## congress youngest oldest ## * \u0026lt;int\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; ## 1 80 25.9 85.9 ## 2 81 27.2 85.2 ## 3 82 27.9 87.2 ## 4 83 26.7 85.3 ## 5 84 28.5 87.3 ## 6 85 30.5 89.3 ## 7 86 31 91.3 ## 8 87 28.9 86 ## 9 88 29 85.3 ## 10 89 25 87.3 ## # … with 24 more rows This could also be done by using the first and last functions after arranging the data:\nsummarise(arrange(congress_grp, age), youngest = first(age), oldest = last(age) ) ## # A tibble: 34 x 3 ## congress youngest oldest ## \u0026lt;int\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; ## 1 80 25.9 85.9 ## 2 81 27.2 85.2 ## 3 82 27.9 87.2 ## 4 83 26.7 85.3 ## 5 84 28.5 87.3 ## 6 85 30.5 89.3 ## 7 86 31 91.3 ## 8 87 28.9 86 ## 9 88 29 85.3 ## 10 89 25 87.3 ## # … with 24 more rows This goes to show that there are commonly many different ways to calculate descriptive statistics. I would argue two strong virtues when writing code is to make it as clear, expressive, and ensure accuracy. Speed and grace in writing code can come later.\nExercises For each congress, calculate a summary using the following command: n_distinct(state). What does this value return? What happens when you use a logical expression within a sum function call? For example, what do you get in a summarise when you do: sum(age \u0026gt; 75)? What happens when you try to use sum or mean on the variable incumbent?     Chaining together multiple operations Now that you have seen all of the basic dplyr data manipulation verbs, it is useful to chain these together to create more complex operations. So far, I have shown you how to do it by saving intermediate steps, for example, saving the grouped data after using the group_by function. In many instances, these intermediate steps are not useful to us. In these cases you can chain operations together.\nSuppose we are interested in calculating the proportion of democrats for each chamber of congress, but only since the 100th congress? There are two ways to do this, the difficult to read and the easier to read. I first shown the difficult to read.\nsummarise( group_by( mutate( filter( congress_age, congress \u0026gt;= 100 ), democrat = ifelse(party == \u0026#39;D\u0026#39;, 1, 0) ), congress, chamber ), num_democrat = sum(democrat), total = n(), prop_democrat = num_democrat / total ) ## `summarise()` has grouped output by \u0026#39;congress\u0026#39;. You can override using the `.groups` argument. ## # A tibble: 28 x 5 ## # Groups: congress [14] ## congress chamber num_democrat total prop_democrat ## \u0026lt;int\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;int\u0026gt; \u0026lt;dbl\u0026gt; ## 1 100 house 263 443 0.594 ## 2 100 senate 55 101 0.545 ## 3 101 house 266 445 0.598 ## 4 101 senate 56 101 0.554 ## 5 102 house 272 443 0.614 ## 6 102 senate 59 104 0.567 ## 7 103 house 261 443 0.589 ## 8 103 senate 58 105 0.552 ## 9 104 house 206 441 0.467 ## 10 104 senate 47 103 0.456 ## # … with 18 more rows How difficult do you find the code above to read? This is valid R code, but the first operation done is nested in the middle (it is the filter function that is run first). This makes for difficult code to debug and write in my opinion. In my opinion, the better way to write code is through the pipe operator, %\u0026gt;%. The same code above can be achieved with the following much easier to read code:\ncongress_age %\u0026gt;% filter(congress \u0026gt;= 100) %\u0026gt;% mutate(democrat = ifelse(party == \u0026#39;D\u0026#39;, 1, 0)) %\u0026gt;% group_by(congress, chamber) %\u0026gt;% summarise( num_democrat = sum(democrat), total = n(), prop_democrat = num_democrat / total ) ## `summarise()` has grouped output by \u0026#39;congress\u0026#39;. You can override using the `.groups` argument. ## # A tibble: 28 x 5 ## # Groups: congress [14] ## congress chamber num_democrat total prop_democrat ## \u0026lt;int\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;int\u0026gt; \u0026lt;dbl\u0026gt; ## 1 100 house 263 443 0.594 ## 2 100 senate 55 101 0.545 ## 3 101 house 266 445 0.598 ## 4 101 senate 56 101 0.554 ## 5 102 house 272 443 0.614 ## 6 102 senate 59 104 0.567 ## 7 103 house 261 443 0.589 ## 8 103 senate 58 105 0.552 ## 9 104 house 206 441 0.467 ## 10 104 senate 47 103 0.456 ## # … with 18 more rows The pipe allows for more readable code by humans and progresses from top to bottom, left to right. The best word to substitute when translating the %\u0026gt;% code above is ‘then’. So the code above says, using the congress_age data, then filter, then mutate, then group_by, then summarise.\nThis is much easier to read and follow the chain of commands. I highly recommend using the pipe in your code. For more details on what is actually happening, the R for Data Science book has a good explanation in Section 5.6.1.\nExercises Look at the following nested code and determine what is being done. Then translate this code to use the pipe operator.  summarise( group_by( mutate( filter( diamonds, color %in% c(\u0026#39;D\u0026#39;, \u0026#39;E\u0026#39;, \u0026#39;F\u0026#39;) \u0026amp; cut %in% c(\u0026#39;Fair\u0026#39;, \u0026#39;Good\u0026#39;, \u0026#39;Very Good\u0026#39;) ), f_color = ifelse(color == \u0026#39;F\u0026#39;, 1, 0), vg_cut = ifelse(cut == \u0026#39;Very Good\u0026#39;, 1, 0) ), clarity ), avg = mean(carat), sd = sd(carat), avg_p = mean(price), num = n(), summary_f_color = mean(f_color), summary_vg_cut = mean(vg_cut) )   ","date":1612742400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1612742400,"objectID":"b0f659bcc0129e01ff2cba6181b735c0","permalink":"https://psqf6250.brandonlebeau.org/rcode/data_munging/","publishdate":"2021-02-08T00:00:00Z","relpermalink":"/rcode/data_munging/","section":"rcode","summary":"Data Manipulation","tags":null,"title":"Data Manipulation","type":"book"},{"authors":null,"categories":null,"content":"   Introduction This week the course will turn to skills that are often not covered much in a statistics course, working with data to create new variables, arrange data, select columns, or filter data. These will make use of the dplyr package from the tidyverse to explore verbs to manipulate data.\n Objectives After completing this module, students will be able to:\n Explore benefits of script based analyses Create new data attributes Evaluate dplyr code for data manipulation   Activities  R for Data Science - chapters 5 – 6   Weekly Videos  Data Munging Introduction \n Arranging Data \n Selecting Columns of Data \n Add Variables to Data \n Summarise Data \n Chaining Commands Together \n R Scripts \n   R Syntax  ggplot2 extensions R Basics   Assignments To come …\n ","date":1612742400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1612742400,"objectID":"52949a52eda82f22a5f6bc5723cc4841","permalink":"https://psqf6250.brandonlebeau.org/content/04-week4/","publishdate":"2021-02-08T00:00:00Z","relpermalink":"/content/04-week4/","section":"content","summary":"Data Munging/Manipulation","tags":null,"title":"Week 4","type":"book"},{"authors":null,"categories":null,"content":"   Introduction This module will give some tools to use when performing exploratory data analysis, a framework that helps you to better understand your data prior to doing any more formal analysis.\n Objectives After completing this module, students will be able to:\n Evaluate exploratory figures Define exploratory data analysis Interpret exploratory data analysis output Create exploratory data analysis code   Activities  R for Data Science - chapter 7   Weekly Videos  EDA - Missing Data \n EDA - Variation \n EDA - Covariation \n EDA - Rare/Common Cases \n R Projects \n   R Syntax  Exploratory Data Analysis R Projects - RStudio   Assignments To come …\n ","date":1613347200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1613347200,"objectID":"08992b6d0f86c7c5ec79bee223a038d3","permalink":"https://psqf6250.brandonlebeau.org/content/05-week5/","publishdate":"2021-02-15T00:00:00Z","relpermalink":"/content/05-week5/","section":"content","summary":"Exploratory Data Analysis","tags":null,"title":"Week 5","type":"book"},{"authors":null,"categories":null,"content":"   I want to talk very briefly about R scripts. You may have been using these already within your workflow for this course, but these are best practice instead of simply running code in the console. Creating R scripts are a crucial step to ensure the data analyses are reproducible, the script will act as a log of all the things that are done to the data to go from data import to any outputs (model results, tables, figures, etc.).\nTo create an R script with RStudio, the short cut is CTRL/CMD + SHIFT + N. You can also create a new script by going to File \u0026gt; New File \u0026gt; R Script. Both of these commands will open up a blank script window.\nIn this script window, I would recommend loading any R packages first at the top of the file. Then proceed with the analysis. Commands can be sent to the console using CRTL/CMD + ENTER. By default RStudio will run any commands that span more than one line with a single CRTL/CMD + ENTER call.\nFor more details about R Scripts, the R for Data Science text has detail with screenshots in Chapter 6. I recommend trying to create a simple script and sending these commands from the script to the console to be run with R.\n","date":1612742400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1612742400,"objectID":"4a1498dfe51443e4f8fbba8d0304ae58","permalink":"https://psqf6250.brandonlebeau.org/rcode/r_scripts/","publishdate":"2021-02-08T00:00:00Z","relpermalink":"/rcode/r_scripts/","section":"rcode","summary":"R Scripts","tags":null,"title":"R Scripts","type":"book"},{"authors":null,"categories":null,"content":"   Exploratory data analysis (EDA) is an important step in exploring and understanding your data. In addition, EDA does not suffer from problems with inferential statistics related to multiple (correlated) models on the same data. Instead, EDA is a great way to visualize, summarize, and prod your data without any consequences.\nFor this set of notes, we are going to use the following packages:\nlibrary(nycflights13) library(tidyverse) We will use a few different data sets, but the one we are going to start with is the flights data from the nycflights13 package. Below is the first 10 rows of the data.\nflights ## # A tibble: 336,776 x 19 ## year month day dep_time sched_dep_time dep_delay arr_time sched_arr_time ## \u0026lt;int\u0026gt; \u0026lt;int\u0026gt; \u0026lt;int\u0026gt; \u0026lt;int\u0026gt; \u0026lt;int\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;int\u0026gt; \u0026lt;int\u0026gt; ## 1 2013 1 1 517 515 2 830 819 ## 2 2013 1 1 533 529 4 850 830 ## 3 2013 1 1 542 540 2 923 850 ## 4 2013 1 1 544 545 -1 1004 1022 ## 5 2013 1 1 554 600 -6 812 837 ## 6 2013 1 1 554 558 -4 740 728 ## 7 2013 1 1 555 600 -5 913 854 ## 8 2013 1 1 557 600 -3 709 723 ## 9 2013 1 1 557 600 -3 838 846 ## 10 2013 1 1 558 600 -2 753 745 ## # … with 336,766 more rows, and 11 more variables: arr_delay \u0026lt;dbl\u0026gt;, ## # carrier \u0026lt;chr\u0026gt;, flight \u0026lt;int\u0026gt;, tailnum \u0026lt;chr\u0026gt;, origin \u0026lt;chr\u0026gt;, dest \u0026lt;chr\u0026gt;, ## # air_time \u0026lt;dbl\u0026gt;, distance \u0026lt;dbl\u0026gt;, hour \u0026lt;dbl\u0026gt;, minute \u0026lt;dbl\u0026gt;, time_hour \u0026lt;dttm\u0026gt; This data contains information on all flights that departed from the three airports in NYC in 2013. As you can see, the data has a total of 336776 rows and 19. For additional information use ?flights.\nExploratory Data Analysis The general process for proceeding with exploratory data analysis as summarized in the R for Data Science text are:\nAsk questions about your data Search for answers Refine or ask new questions about the data.  There are no bad questions when performing EDA, but some common questions worth exploring are:\n Missing Data Variation Covariation Rare cases Common cases Distributions  Missing Data A first step in exploring the data is to explore if there are any missing data present in the data (likely). This is not an easy step, but determining the amount of missing data and, if possible, why these values are missing are important first steps. One quick way to get a view of this information for the entire data is to use the summary command. An example is given with the flights data below.\nsummary(flights) ## year month day dep_time sched_dep_time ## Min. :2013 Min. : 1.000 Min. : 1.00 Min. : 1 Min. : 106 ## 1st Qu.:2013 1st Qu.: 4.000 1st Qu.: 8.00 1st Qu.: 907 1st Qu.: 906 ## Median :2013 Median : 7.000 Median :16.00 Median :1401 Median :1359 ## Mean :2013 Mean : 6.549 Mean :15.71 Mean :1349 Mean :1344 ## 3rd Qu.:2013 3rd Qu.:10.000 3rd Qu.:23.00 3rd Qu.:1744 3rd Qu.:1729 ## Max. :2013 Max. :12.000 Max. :31.00 Max. :2400 Max. :2359 ## NA\u0026#39;s :8255 ## dep_delay arr_time sched_arr_time arr_delay ## Min. : -43.00 Min. : 1 Min. : 1 Min. : -86.000 ## 1st Qu.: -5.00 1st Qu.:1104 1st Qu.:1124 1st Qu.: -17.000 ## Median : -2.00 Median :1535 Median :1556 Median : -5.000 ## Mean : 12.64 Mean :1502 Mean :1536 Mean : 6.895 ## 3rd Qu.: 11.00 3rd Qu.:1940 3rd Qu.:1945 3rd Qu.: 14.000 ## Max. :1301.00 Max. :2400 Max. :2359 Max. :1272.000 ## NA\u0026#39;s :8255 NA\u0026#39;s :8713 NA\u0026#39;s :9430 ## carrier flight tailnum origin ## Length:336776 Min. : 1 Length:336776 Length:336776 ## Class :character 1st Qu.: 553 Class :character Class :character ## Mode :character Median :1496 Mode :character Mode :character ## Mean :1972 ## 3rd Qu.:3465 ## Max. :8500 ## ## dest air_time distance hour ## Length:336776 Min. : 20.0 Min. : 17 Min. : 1.00 ## Class :character 1st Qu.: 82.0 1st Qu.: 502 1st Qu.: 9.00 ## Mode :character Median :129.0 Median : 872 Median :13.00 ## Mean :150.7 Mean :1040 Mean :13.18 ## 3rd Qu.:192.0 3rd Qu.:1389 3rd Qu.:17.00 ## Max. :695.0 Max. :4983 Max. :23.00 ## NA\u0026#39;s :9430 ## minute time_hour ## Min. : 0.00 Min. :2013-01-01 05:00:00 ## 1st Qu.: 8.00 1st Qu.:2013-04-04 13:00:00 ## Median :29.00 Median :2013-07-03 10:00:00 ## Mean :26.23 Mean :2013-07-03 05:22:54 ## 3rd Qu.:44.00 3rd Qu.:2013-10-01 07:00:00 ## Max. :59.00 Max. :2013-12-31 23:00:00 ##  This summary can be a bit difficult to digest at first, but can give some useful insight into the variables, including the amount of missing data for each variable.\nYou can dive into looking at specific rows that are missing with the filter command and the is.na function. An example pulling out rows with a missing dep_time values is illustrated:\nfilter(flights, is.na(dep_time)) ## # A tibble: 8,255 x 19 ## year month day dep_time sched_dep_time dep_delay arr_time sched_arr_time ## \u0026lt;int\u0026gt; \u0026lt;int\u0026gt; \u0026lt;int\u0026gt; \u0026lt;int\u0026gt; \u0026lt;int\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;int\u0026gt; \u0026lt;int\u0026gt; ## 1 2013 1 1 NA 1630 NA NA 1815 ## 2 2013 1 1 NA 1935 NA NA 2240 ## 3 2013 1 1 NA 1500 NA NA 1825 ## 4 2013 1 1 NA 600 NA NA 901 ## 5 2013 1 2 NA 1540 NA NA 1747 ## 6 2013 1 2 NA 1620 NA NA 1746 ## 7 2013 1 2 NA 1355 NA NA 1459 ## 8 2013 1 2 NA 1420 NA NA 1644 ## 9 2013 1 2 NA 1321 NA NA 1536 ## 10 2013 1 2 NA 1545 NA NA 1910 ## # … with 8,245 more rows, and 11 more variables: arr_delay \u0026lt;dbl\u0026gt;, ## # carrier \u0026lt;chr\u0026gt;, flight \u0026lt;int\u0026gt;, tailnum \u0026lt;chr\u0026gt;, origin \u0026lt;chr\u0026gt;, dest \u0026lt;chr\u0026gt;, ## # air_time \u0026lt;dbl\u0026gt;, distance \u0026lt;dbl\u0026gt;, hour \u0026lt;dbl\u0026gt;, minute \u0026lt;dbl\u0026gt;, time_hour \u0026lt;dttm\u0026gt; We can also build more complex operations to look at data that is missing for one variable, but not another. For instance, if you look at the summary information above, you may notice there are more missing values for the arr_delay variable compared to the arr_time variable. To look at these values you can use the following command:\nfilter(flights, is.na(arr_delay) \u0026amp; !is.na(arr_time)) ## # A tibble: 717 x 19 ## year month day dep_time sched_dep_time dep_delay arr_time sched_arr_time ## \u0026lt;int\u0026gt; \u0026lt;int\u0026gt; \u0026lt;int\u0026gt; \u0026lt;int\u0026gt; \u0026lt;int\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;int\u0026gt; \u0026lt;int\u0026gt; ## 1 2013 1 1 1525 1530 -5 1934 1805 ## 2 2013 1 1 1528 1459 29 2002 1647 ## 3 2013 1 1 1740 1745 -5 2158 2020 ## 4 2013 1 1 1807 1738 29 2251 2103 ## 5 2013 1 1 1939 1840 59 29 2151 ## 6 2013 1 1 1952 1930 22 2358 2207 ## 7 2013 1 2 905 822 43 1313 1045 ## 8 2013 1 2 1125 925 120 1445 1146 ## 9 2013 1 2 1848 1840 8 2333 2151 ## 10 2013 1 2 1849 1724 85 2235 1938 ## # … with 707 more rows, and 11 more variables: arr_delay \u0026lt;dbl\u0026gt;, carrier \u0026lt;chr\u0026gt;, ## # flight \u0026lt;int\u0026gt;, tailnum \u0026lt;chr\u0026gt;, origin \u0026lt;chr\u0026gt;, dest \u0026lt;chr\u0026gt;, air_time \u0026lt;dbl\u0026gt;, ## # distance \u0026lt;dbl\u0026gt;, hour \u0026lt;dbl\u0026gt;, minute \u0026lt;dbl\u0026gt;, time_hour \u0026lt;dttm\u0026gt; This may actually be a data error, as there is an arr_time value, a scheduled_arr_time value, but no arr_delay value. This could then be calculated manually to reduce the number of missing values with this variable.\nViewing missing data graphically It may be useful to view missing data graphically. This may be useful to see if there are specific trends in the data in relation to the missing values. A few ways to plot these data may be useful.\nFirst, it is always a good rule to explore missing data in relation to other variables in the data. If there is evidence that another variable is influencing whether a value is missing, additional statistical controls are needed to adjust for these concerns.\nFor example, we could explore if the scheduled arrival time is related to whether the actual arrival flight time is missing.\nflights %\u0026gt;% mutate( miss_arrival = is.na(arr_time) ) %\u0026gt;% ggplot(mapping = aes(sched_arr_time)) + geom_freqpoly(aes(color = miss_arrival)) + theme_bw() Notice that the count metric masks much of what is being visualized here as there are many more flights that arrived compared to those with missing times. To adjust this, we simply need to change the y-axis from counts to density.\nflights %\u0026gt;% mutate( miss_arrival = is.na(arr_time) ) %\u0026gt;% ggplot(mapping = aes(x = sched_arr_time, y = ..density..)) + geom_freqpoly(aes(color = miss_arrival)) + theme_bw() The two curves are now standardized so that the area under each curve equals 1, which in turn makes comparison between the two groups easier.\nOne other special note, for EDA internally, there is no need to spend much time worrying about formatting of the graphics. However, if this plot above would be included in a report or manuscript, this figure would need additional polish to be included.\n  Variation Another common EDA question is related to variation. Variation is important for statistics, without variation there is no need to do statistics. The best way to explore variation of any type of variable is through visulization. This section will be broken into two sub areas, one that explores qualitative and another that explores quantitative.\nQualitative Variables Bar graphs (frequency tables) are commonly used to explore variation in qualitative variables. For example, if we wished to explore the number of flights that took off for each month of the year from NYC:\nggplot(flights, aes(factor(month))) + geom_bar() + theme_bw() One special note about the above code, I used the factor() function so that ggplot specifically added all the values of the variable to the x-axis. By default since the month variable is being treated as an integer (a number), it would not show all the values for month.\nThese counts could be calculated manually with the use of dplyr using the count function. The count function basically creates a frequency table. More complex tables can be created by passing additional variables to the count function.\nflights %\u0026gt;% count(month) ## # A tibble: 12 x 2 ## month n ## * \u0026lt;int\u0026gt; \u0026lt;int\u0026gt; ## 1 1 27004 ## 2 2 24951 ## 3 3 28834 ## 4 4 28330 ## 5 5 28796 ## 6 6 28243 ## 7 7 29425 ## 8 8 29327 ## 9 9 27574 ## 10 10 28889 ## 11 11 27268 ## 12 12 28135  Exercises Copy the code from the bar graph above, but instead of wrapping the month variable in factor, try it without it. What is different? Extra, using the scale_x_continuous function, can you manually add each of the 12 numeric month values to the plot? Using dplyr, manually calculate the number of flights that took off for every day of every month. In other words, how many flights took off everyday of the year. Which day had the most flights?   Quantitative Variables Histrograms, frequency polygons, or density curves are three common options to explore variation with quantitative variables. Within the flights data, suppose we were interested in exploring the variation in the distance traveled, this could easily be done with a histrogram.\nggplot(flights, aes(distance)) + geom_histogram() + theme_bw() We could also use a frequency polygon:\nggplot(flights, aes(distance)) + geom_freqpoly() + theme_bw() We could also use a density curve:\nggplot(flights, aes(distance)) + geom_density() + theme_bw() When exploring the variation for a single variable overall, I tend to use histograms. However, when attempting to see if the variation changes across values of a categorical variable, histograms are difficult as the groups likely overlap. These are instances when using the frequency polygon or density curves are useful. Here are examples of both when exploring variation differences by month.\nggplot(flights, aes(distance)) + geom_freqpoly(aes(color = factor(month))) + theme_bw() ggplot(flights, aes(distance)) + geom_density(aes(color = factor(month))) + theme_bw() You can also calculate the counts plotted in the histograms and frequency polygons using the count as with qualitative variables. We just now need to use the cut_width function to specify bins.\nflights %\u0026gt;% count(cut_width(distance, 100)) ## # A tibble: 28 x 2 ## `cut_width(distance, 100)` n ## * \u0026lt;fct\u0026gt; \u0026lt;int\u0026gt; ## 1 [-50,50] 1 ## 2 (50,150] 2514 ## 3 (150,250] 36839 ## 4 (250,350] 18442 ## 5 (350,450] 15233 ## 6 (450,550] 29149 ## 7 (550,650] 11688 ## 8 (650,750] 33482 ## 9 (750,850] 19482 ## 10 (850,950] 19644 ## # … with 18 more rows Note, these counts may differ from above as the binwidth was not specifically stated when creating the histrogram or frequency polygon.\nIt may also be useful to calculate the variance, standard deviation, or the range. These can be calculated using the summarize function.\nflights %\u0026gt;% summarize( var_dist = var(distance, na.rm = TRUE), sd_dist = sd(distance, na.rm = TRUE), min_dist = min(distance, na.rm = TRUE), max_dist = max(distance, na.rm = TRUE) ) ## # A tibble: 1 x 4 ## var_dist sd_dist min_dist max_dist ## \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; ## 1 537631. 733. 17 4983 You could pair this with the group_by function to calculate these values for different groups (e.g. by month).\n Exercises Explore variation in the air_time variable. Does the variation in the air_time variable differ by month?    Distributions Exploring distributions for variables is a very similar process to exploring the variation, the question is just different. Most often we are interested in exploring if the shape of the distribution is approximately normal. This will become more interesting when we start fitting models to explore potential assumption violations in the residuals. We leave these discussions until then.\n Covariation Covariation is the process of comparing how two (or more) variables are related. The most common method for exploring covariation is through scatterplots. However, these are most natural for two continuous variables. Other plots are useful for a mixture of variable types or for two qualitative variables. We will explore each in turn.\nTwo Qualitative Variables Covariation in two qualitative variables is more difficult to view visually due to the restricted possible values in each variable. Suppose for example, we wished to explore covariation in the origin of the flight and the carrier.\nggplot(flights, aes(origin, carrier)) + geom_count() This plot is okay, however, I think a more useful plot is to use a tile plot to explore these differences with color.\nflights %\u0026gt;% count(origin, carrier) %\u0026gt;% ggplot(aes(origin, carrier)) + geom_tile(aes(fill = n)) + theme_bw() Note, that holes mean missing values (i.e. no flights from that airport from that carrier).\n Exercises Explore the covariation between the month and day variables. Note, these are treated as continuous in the data, but in reality they are likely best represented as qualitative.   Two Quantitative Variables Scatterplots are useful for two quantitative variables. Suppose for example that we wish to explore the relationship between the air_time variable and the arr_delay variable. This could be done with a scatterplot.\nggplot(flights, aes(air_time, arr_delay)) + geom_point() + theme_bw() ## Warning: Removed 9430 rows containing missing values (geom_point). One problem with the plot above, is overplotting. There are two fixes for this, one is to use transparent points using the alpha argument to the geom_point function.\nggplot(flights, aes(air_time, arr_delay)) + geom_point(alpha = .05) + theme_bw() ## Warning: Removed 9430 rows containing missing values (geom_point). Another approach that will simplify the exploration is to use boxplots. This will involve grouping the air_time variable into “bins.”\nggplot(flights, aes(x = air_time, y = arr_delay)) + geom_boxplot(aes(group = cut_width(air_time, 50))) + theme_bw() ## Warning: Removed 9430 rows containing missing values (stat_boxplot). Even another more sophisticated graphic is to do the quantitative alternative to geom_tile. Note, the code below uses the hexbin package, but a similar function is geom_bin2d.\n# install.packages(\u0026quot;hexbin\u0026quot;) library(hexbin) ggplot(flights, aes(x = air_time, y = arr_delay)) + geom_hex() ## Warning: Removed 9430 rows containing non-finite values (stat_binhex).  Adding a Third Variable Adding a third variable is often useful, but can be difficult to think about procedurally. The type of plot that is useful depends on the type the third variable is. For example, if the third variable is also quantitative, the visualization is more difficult, however, if the third variable is qualitative, there are two main options. These will be explored in more detail below.\nThe main two approaches for adding a third variable when it is qualitative is to use a different color/shape for the values of this variable or to facet the plot. Suppose we wished to explore the covariation between the following three variables: air_time, arr_delay, and origin. The two different options are shown below.\nggplot(flights, aes(air_time, arr_delay)) + geom_hex() + facet_grid(. ~ origin) + theme_bw() ## Warning: Removed 9430 rows containing non-finite values (stat_binhex). ggplot(flights, aes(air_time, arr_delay)) + geom_point(aes(color = origin), alpha = .05) + theme_bw() ## Warning: Removed 9430 rows containing missing values (geom_point). Plotting three quantitative variables commonly involves binning one one the variables to turn it into an ordinal variable with different levels. For example, see the example with two variables and the boxplot, a similar approach could be used to facet by this third variable. Below is a simple example:\nggplot(flights, aes(x = air_time, y = arr_delay)) + geom_hex() + theme_bw() + facet_wrap(~ cut_width(dep_time, 250)) ## Warning: Removed 9430 rows containing non-finite values (stat_binhex).  One Quantitative, One Qualitative This was actually already discussed in the discussion of variation by exploring differences in variation for different levels of a qualitative variable (see above). If the variation differs by groups, there is then evidence of covariation.\n Correlations It is also useful to calculate and visualize raw correlations. To calculate raw correlations (assuming only quantitative variables), the cor function is useful.\nflights %\u0026gt;% select(air_time, arr_delay, dep_time) %\u0026gt;% cor(use = \u0026#39;pairwise.complete.obs\u0026#39;) ## air_time arr_delay dep_time ## air_time 1.00000000 -0.03529709 -0.01461948 ## arr_delay -0.03529709 1.00000000 0.23230573 ## dep_time -0.01461948 0.23230573 1.00000000 To visualize a correlation matrix, the GGally package is useful. Note, the ggpairs function can take some time to run.\n# install.package(\u0026quot;GGally\u0026quot;) library(GGally) flights %\u0026gt;% select(air_time, arr_delay, dep_time) %\u0026gt;% na.omit() %\u0026gt;% sample_n(1000) %\u0026gt;% ggpairs()  Exercises Explore covariation in the dep_delay and arr_delay variables. What type of relationship, if any, appears to be present? Explore the relationship between dep_delay, arr_delay, and origin. What type of relationship is present. Does the relationship between dep_delay and arr_delay differ by origin? Finally, calculate the correlation matrix for dep_delay, arr_delay, and dep_time.    Rare/Common Cases The last question of use to explore when performing EDA is looking for the presence of rare or common cases. In other words, an exploration of any outliers and the central tendency of the distribution.\nWhen we explored variation in the distance variable earlier, there may have been extreme values we’d want to explore in more detail.\nggplot(flights, aes(distance)) + geom_histogram() + theme_bw() Notice the large distance value, to get a better view of how many there are here, we can use coord_cartesian to zoom in.\nggplot(flights, aes(distance)) + geom_histogram() + theme_bw() + coord_cartesian(ylim = c(0, 5000)) Note, that in the above plot, coord_cartesian does not remove any points, simply changes the coordinates that are plotted. We could also pull these out using filter as well.\nflights %\u0026gt;% filter(distance \u0026gt; 3000) %\u0026gt;% arrange(distance) ## # A tibble: 715 x 19 ## year month day dep_time sched_dep_time dep_delay arr_time sched_arr_time ## \u0026lt;int\u0026gt; \u0026lt;int\u0026gt; \u0026lt;int\u0026gt; \u0026lt;int\u0026gt; \u0026lt;int\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;int\u0026gt; \u0026lt;int\u0026gt; ## 1 2013 7 6 1629 1615 14 1954 1953 ## 2 2013 7 13 1618 1615 3 1955 1953 ## 3 2013 7 20 1618 1615 3 2003 1953 ## 4 2013 7 27 1617 1615 2 1906 1953 ## 5 2013 8 3 1615 1615 0 2003 1953 ## 6 2013 8 10 1613 1615 -2 1922 1953 ## 7 2013 8 17 1740 1625 75 2042 2003 ## 8 2013 8 24 1633 1625 8 1959 2003 ## 9 2013 1 1 1344 1344 0 2005 1944 ## 10 2013 1 2 1344 1344 0 1940 1944 ## # … with 705 more rows, and 11 more variables: arr_delay \u0026lt;dbl\u0026gt;, carrier \u0026lt;chr\u0026gt;, ## # flight \u0026lt;int\u0026gt;, tailnum \u0026lt;chr\u0026gt;, origin \u0026lt;chr\u0026gt;, dest \u0026lt;chr\u0026gt;, air_time \u0026lt;dbl\u0026gt;, ## # distance \u0026lt;dbl\u0026gt;, hour \u0026lt;dbl\u0026gt;, minute \u0026lt;dbl\u0026gt;, time_hour \u0026lt;dttm\u0026gt; Measures of Central Tendency Exploring measures of central tendency or simply common values/repeated of common values can also be important.\nggplot(flights, aes(arr_time)) + geom_histogram(binwidth = 50) + theme_bw() ## Warning: Removed 8713 rows containing non-finite values (stat_bin). Measures of central tendency can be directly calculated using the summarise function. For example, exploring central tendency of the arr_delay variable.\nflights %\u0026gt;% summarise( avg_arrdelay = mean(arr_delay, na.rm = TRUE), med_arrdelay = median(arr_delay, na.rm = TRUE) ) ## # A tibble: 1 x 2 ## avg_arrdelay med_arrdelay ## \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; ## 1 6.90 -5 More interesting computations can be performed by using adding in the group_by function.\n Exercises Using the txhousing data, explore rare/common cases in the median sale price for the following 3 cities: Austin, Dallas, and Houston. Using the data from #1, explore measures of central tendency in the median sale price of these three cities. How have these changed over time (year)? Create an effective visualization that explores differences in the median sale price over time for these three cities.     ","date":1613347200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1613347200,"objectID":"d51221318d1ce5961433027d6b37a824","permalink":"https://psqf6250.brandonlebeau.org/rcode/eda/","publishdate":"2021-02-15T00:00:00Z","relpermalink":"/rcode/eda/","section":"rcode","summary":"Exploratory Data Analysis","tags":null,"title":"Exploratory Data Analysis","type":"book"},{"authors":null,"categories":null,"content":"   I want to talk briefly about RStudio projects. These are a great way to structure each individual project. Chapter 8 in the R for Data Science text will provide a more thorough discussion of RStudio projects: http://r4ds.had.co.nz/workflow-projects.html\nWorking Directory As we move into reading in data files, the idea of a working directory will become even more important. RStudio projects makes this discussion much easier as the root of the project directory is treated as the working directory. The nice aspect of this is that all paths to data files are in reference to this root project directory (more on this coming soon).\n Project Structure The last aspect I want to share is a common project directory structure. Everyone can have slightly different versions, but I want to share what I have come to commonly use. The following structure is how I tend to structure most or my projects.\nProject Structure\n Another way to visualize this structure is as follows:\n Project Root:  Data example paper R    ","date":1613347200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1613347200,"objectID":"ad26be1d8c7fb8b89ce5463a40d8d96d","permalink":"https://psqf6250.brandonlebeau.org/rcode/projects/","publishdate":"2021-02-15T00:00:00Z","relpermalink":"/rcode/projects/","section":"rcode","summary":"R Projects -  RStudio","tags":null,"title":"R Projects -  RStudio","type":"book"},{"authors":null,"categories":null,"content":"   Reproducible Rmarkdown Document: 20 pts\nDue: February 14th, 2021 - No penalty for late submissions, but due no later than May 7th.\nFor this assignment, you will create your first reproducible R Markdown document. The source file (the .Rmd) file will be turned in as well as the compiled version (html). The general form of the R code to be included in the document will be given to you. You may be asked to manipulate simple R commands. Submit completed assignment, including Rmd and html to ICON.\nR Markdown Setup Using RStudio, open up a new template for an R Markdown file. To do this, go to File \u0026gt; New File \u0026gt; R Markdown. A new window should open up, type in the details, and ensure that HTML Output is clicked. When finished entering in details, click the ‘okay’ button. Upon hitting the ‘okay’ button, a document template should show up. Read the elements in the template, then once comfortable with its contents, you can delete it and continue to the questions below.   Questions Using Markdown syntax, create a header that says Question 1. Note, you can pick any level of header you wish. Create subsequent headers for each question below. 1 pt\n Create an unordered list that lists your research interests (please list at least 2 interests here). 1 pt\n Create a hyperlink (link to a webpage) that links to the main R project website. Add the link in two ways, one that show the actual link and two, one that has the link embedded within text. You can pick whatever you wish for the link text. 2 pts\n Add a R code chunk to the document. Within this code chunk add the following R code: summary(iris). Ensure to give the chunk a unique name. 2 pts\n Add a line break/horizontal line here now. 1 pt\n Using output from the R command used in the code chunk above, create a table that summarizes the first four variables from the output. 2 pts\n Add a new R code chunk. Inside this code chunk add the following R code: hist(iris$Sepal.Length). Ensure to give the chunk a unique name and also add the chunk option to omit the code from being shown in the output. 2 pts\n Create an ordered list with Markdown that ranks your top vacations you have taken. Within each of your top vacations, add a nested item (e.g. https://commonmark.org/help/tutorial/10-nestedLists.html) to each of your vacations that states the top activities you did while on vaction. 2 pts\n Write some text that specifies the correlation between the continuous variables from the iris data. Place the following two bits of code inline in their relavent positions. The two correlations can be calculated with the following bit of code: round(cor(iris$Sepal.Length, iris$Sepal.Width), 2) and round(cor(iris$Petal.Length, iris$Petal.Width), 2) 2 pts\n Let’s now create another figure with the following R code, plot(iris$Sepal.Length, iris$Sepal.Width). Similar to above, give the chunk a unique name and also add the chunk option to omit the code from being shown in the output. For this figure, explore the knitr chunk options (https://yihui.name/knitr/options/) to add a figure caption to the figure. 2 pts\n Add one last code chunk (ensure this chunk has a unique name). Ensure through chunk options that the code is not evaluated, but the code is returned. 3 pts\n  x \u0026lt;- rnorm(100) y \u0026lt;- runif(100, min = 3, max = 8) mean(x) mean(y)  ","date":1609977600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1609977600,"objectID":"0125028e0a0739cc5b3cae5982c0f491","permalink":"https://psqf6250.brandonlebeau.org/assignments/assignment/assignment1/","publishdate":"2021-01-07T00:00:00Z","relpermalink":"/assignments/assignment/assignment1/","section":"assignments","summary":"Reproducible Rmarkdown Document: 20 pts\nDue: February 14th, 2021 - No penalty for late submissions, but due no later than May 7th.\nFor this assignment, you will create your first reproducible R Markdown document.","tags":null,"title":"Assignment 1","type":"book"},{"authors":null,"categories":null,"content":"   Graphics and Data Munging Practice: 20 pts\nDue: March 7th, 2021 - No penalty for late submissions, but due no later than May 7th.\nFor this assignment, you will build upon the skills you learned in the first reproducible R Markdown document created in the first assignment. In this assignment, you will explore some data graphically to inform a few research questions using data from the fivethirtyeight package. The source file (the .Rmd) file will be turned in as well as the compiled version (html). Note, please create a new Rmd document for this assignment rather than continue the one from the first assignment.\nAll graphics should be of high quality, this includes formatting of axes, axes labels, etc. If none of the graphics are of high quality, a 2 pt penalty will apply over and above any item-specific reductions.\nResearch Questions The following research questions will be used to guide the assignment, but you do not need to answer these directly. The questions below will reference these questions.\nUsing the college_recent_grads data from the fivethirtyeight package, which majors are the most popular? Using the college_recent_grads data from the fivethirtyeight package, which major categories (not individual majors, but bigger major categories, major_category) are most unisex (i.e., have an equal number of males/females in them.)? Related to #2, which major categories have the most disproportionate number of males or females with that major category? Is there any evidence of a relationship between unemployment rate and the popularity of a major? What about median salary (shown by median) and the popularity of a major?   Questions Using an appropriate verb from dplyr, which majors are the most popular? Don’t print all the data in the output file to answer this question, keep this summary concise. 1 pt\n Which majors are the least popular? Don’t print all the data in the output file to answer this question, keep this summary concise. 1 pt\n Explore the distribution of the variable/attribute sharewomen visually. Summarize characteristics of this variable in a few sentences. Be sure to include any figure(s) or statistics as evidence to support your description. 3 pts\n Which major categories are the most unisex and which major categories are the most disproportionate? Similar to #1 and #2, please don’t print all of the majors, just highlight a few in each category. 2 pts\n Create a figure that effectively shows which major categories are the most unisex and disproportionate in a single figure. Discuss briefly why this figure is effective at answering research question 2 and 3. 3 pts\n Create a figure that explores if there is a relationship between the popularity of a major and the unemployment rate. Discuss how you defined popularity and why this figure helps to show the relationship between the two attributes. Be sure in your discussion to also state your interpretation of the figure. 2 pts\n Building off of #6, create a figure that explores if there is a relationship between the popularity of a major and the median salary (shown with the median attribute). Discuss how you defined popularity and why this figure helps to show the relationship between the two attributes. Be sure in your discussion to also state your interpretation of the figure. 2 pts\n Create a figure that explores if there is a relationship between the popularity of a major category and the unemployment rate. Discuss why this figure helps to show the relationship between the two attributes and also discuss how this figure may differ from the one created in #6. What additional features did you need to consider to make an effective visualization of this relationship given the data structure. Be sure in your discussion to also state your interpretation of the figure. Note, you may wish to use dplyr and ggplot2 to help with this question. 3 pts\n Create a figure that explores if there is a relationship between the popularity of a major category and the median salary (shown with the median attribute). Discuss why this figure helps to show the relationship between the two attributes and also discuss how this figure may differ from the one created in #6. What additional features did you need to consider to make an effective visualization of this relationship given the data structure. Be sure in your discussion to also state your interpretation of the figure. Note, you may wish to use dplyr and ggplot2 to help with this question. 3 pts\n   ","date":1613520000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1613520000,"objectID":"9a379d77e6562030f2ffc376339cf992","permalink":"https://psqf6250.brandonlebeau.org/assignments/assignment/assignment2/","publishdate":"2021-02-17T00:00:00Z","relpermalink":"/assignments/assignment/assignment2/","section":"assignments","summary":"Graphics and Data Munging Practice: 20 pts\nDue: March 7th, 2021 - No penalty for late submissions, but due no later than May 7th.\nFor this assignment, you will build upon the skills you learned in the first reproducible R Markdown document created in the first assignment.","tags":null,"title":"Assignment 2","type":"book"},{"authors":null,"categories":null,"content":"Quiz 1 can be taken on ICON, due February 7th, 2021. The quiz covers content from Week 1.\nQuiz 1 Link\n","date":1609977600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1609977600,"objectID":"ac83706d5690d70e2da1268514b156a4","permalink":"https://psqf6250.brandonlebeau.org/assignments/quizzes/quiz1/","publishdate":"2021-01-07T00:00:00Z","relpermalink":"/assignments/quizzes/quiz1/","section":"assignments","summary":"Quiz 1 can be taken on ICON, due February 7th, 2021. The quiz covers content from Week 1.\nQuiz 1 Link","tags":null,"title":"Quiz 1","type":"book"},{"authors":null,"categories":null,"content":"Quiz 2 can be taken on ICON, due February 14th, 2021. The quiz covers content from Week 2.\nQuiz 2 Link\n","date":1612742400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1612742400,"objectID":"89e911fba74fe6a1dc69de07ae2db619","permalink":"https://psqf6250.brandonlebeau.org/assignments/quizzes/quiz2/","publishdate":"2021-02-08T00:00:00Z","relpermalink":"/assignments/quizzes/quiz2/","section":"assignments","summary":"Quiz 2 can be taken on ICON, due February 14th, 2021. The quiz covers content from Week 2.\nQuiz 2 Link","tags":null,"title":"Quiz 2","type":"book"},{"authors":null,"categories":null,"content":"Quiz 3 can be taken on ICON, due February 28th, 2021. The quiz covers content from Week 4.\nQuiz 3 Link\n","date":1613347200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1613347200,"objectID":"ffe02f7f4b85dd056013551821b59d03","permalink":"https://psqf6250.brandonlebeau.org/assignments/quizzes/quiz3/","publishdate":"2021-02-15T00:00:00Z","relpermalink":"/assignments/quizzes/quiz3/","section":"assignments","summary":"Quiz 3 can be taken on ICON, due February 28th, 2021. The quiz covers content from Week 4.\nQuiz 3 Link","tags":null,"title":"Quiz 3","type":"book"},{"authors":null,"categories":null,"content":"  Course Project - 25 pts Details to come …\n ","date":1611532800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1611532800,"objectID":"9fba476f25e9d5d0c164b57b4091225a","permalink":"https://psqf6250.brandonlebeau.org/assignments/project/project/","publishdate":"2021-01-25T00:00:00Z","relpermalink":"/assignments/project/project/","section":"assignments","summary":"  Course Project - 25 pts Details to come …\n ","tags":null,"title":"Course Project","type":"book"}]